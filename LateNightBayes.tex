% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[
]{book}
\usepackage{amsmath,amssymb}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math} % this also loads fontspec
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
\usepackage{lmodern}
\ifPDFTeX\else
  % xetex/luatex font selection
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{248,248,248}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.94,0.16,0.16}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\BuiltInTok}[1]{#1}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.64,0.00,0.00}{\textbf{#1}}}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\ImportTok}[1]{#1}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{5}
\usepackage{booktabs}
\usepackage{amsthm}
\makeatletter
\def\thm@space@setup{%
  \thm@preskip=8pt plus 2pt minus 4pt
  \thm@postskip=\thm@preskip
}
\makeatother
\ifLuaTeX
  \usepackage{selnolig}  % disable illegal ligatures
\fi
\usepackage[]{natbib}
\bibliographystyle{apalike}
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same}
\hypersetup{
  pdftitle={Late Night Bayes ☾},
  pdfauthor={Brenden Eum},
  hidelinks,
  pdfcreator={LaTeX via pandoc}}

\title{Late Night Bayes ☾}
\author{Brenden Eum}
\date{2024-02-14}

\begin{document}
\maketitle

{
\setcounter{tocdepth}{1}
\tableofcontents
}
\hypertarget{welcome}{%
\chapter{Welcome}\label{welcome}}

My name is Brenden, and I am a Social \& Decision Neuroscience PhD student at Caltech.

This is a compilation of some reports that I write out of curiosity. My goal is to share these projects with others to speed up the spread of new methods or to answer simple questions. So far, all the data used on this site is available at www.rnl.caltech.edu or various other sites (e.g.~OSF). Given how much I write / comment, it should be fairly easy to find the datasets :). I'll try to include a link to the data in each chapter.

Feel free to reach out to me if you have any questions or if you just want to chat (\href{mailto:beum@caltech.edu}{\nolinkurl{beum@caltech.edu}})!

\hypertarget{dcb}{%
\chapter{Decision Classification Boundaries}\label{dcb}}

(TL;DR) Glickman, Moran, and Usher's (2022) Decision Classification Boundaries perform (1) outstandingly well with simulated, perceptual data; (2) decently well with impatient subjects in perceptual tasks; and (3) unsurprisingly poor with subjects in value-based tasks.

\includegraphics[width=0.6\textwidth,height=\textheight]{images/dcb-collapsingbounds.gif}

This notebook is a test of the methods from \citep{glickman2022}. I would like to see if their algorithm that dynamically estimates collapsing bounds (Decision Classification Boundary, DCB) works with perceptual data from an upcoming belief tracking project and value-based data from \citep{eum2022}.

\hypertarget{simulated-perceptual-data}{%
\subsubsection*{Simulated, perceptual data}\label{simulated-perceptual-data}}
\addcontentsline{toc}{subsubsection}{Simulated, perceptual data}

First, I will simulate data for two cyborgs using a DDM. Their task will be to select from two streams of rectangles whichever stream has the taller average height (see \citep{tsetsos2016} or \citep{glickman2022}). The first cyborg will utilize fixed decision boundaries; the second cyborg will utilize collapsing boundaries (Weibull function, per tradition). I will test if the DCB algorithm can recover the decision boundaries for both cyborgs.

\hypertarget{real-perceptual-data}{%
\subsubsection*{Real, perceptual data}\label{real-perceptual-data}}
\addcontentsline{toc}{subsubsection}{Real, perceptual data}

Second, I will use preliminary data collected for my upcoming slider task. The task is again for subjects to select from two streams of rectangles which stream has the taller average height. I think it would be interesting to see if DCB works with both (1) accumulated evidence and (2) location of the slider.

\hypertarget{real-value-based-data}{%
\subsubsection*{Real, value-based data}\label{real-value-based-data}}
\addcontentsline{toc}{subsubsection}{Real, value-based data}

Third, I will read in the data from \citep{eum2022}. I will only use trials from the visible condition. This will be interesting since there isn't a stream of varying evidence. It's just a single value comparison that accumulates over time. If we use an aDDM, then there will be some variation in evidence over time based on fixation data.

\hypertarget{heres-a-quick-summary-of-what-dcb-does}{%
\subsubsection*{Here's a quick summary of what DCB does:}\label{heres-a-quick-summary-of-what-dcb-does}}
\addcontentsline{toc}{subsubsection}{Here's a quick summary of what DCB does:}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Discretize your time-dimension.
\item
  Consider a single trial. At any time during that trial, the sequence of stimuli has provided a stream of evidence in favor of one of the actions. In the case of perceptual tasks, we can take the sum of evidence over time and come up with a metric for ``accumulated evidence'' at any given time point. This might be a bit trickier in value-based decision tasks.
\item
  At any given point in time, agents have three potential actions (continue sampling, choose left, choose right). If we consider one point in time, then we can look at the distributions of actions along a single dimension, accumulated evidence.
\item
  Each trial yields one point along this accumulated evidence dimension. The points are labeled by the action taken at that time during that trial. This allows for supervised separation by linear discriminant analysis (LDA).
\item
  The boundary separation curves approximate decision boundaries over time.
\end{enumerate}

\includegraphics[width=0.3\textwidth,height=\textheight]{images/dcb-example.PNG}

\hypertarget{simulated-perceptual-data-1}{%
\section{Simulated, perceptual data}\label{simulated-perceptual-data-1}}

\hypertarget{simulate-data}{%
\subsection{Simulate data}\label{simulate-data}}

The task is to select from two streams of rectangles the stream with the taller average height. We will generate two DDM cyborgs, the first with fixed decision bounds, the second with collapsing decision bounds.

\hypertarget{ddm-function}{%
\subsubsection*{DDM function}\label{ddm-function}}
\addcontentsline{toc}{subsubsection}{DDM function}

Simulate behavior for a single trial using a DDM with symmetric bounds about 0.\\
\emph{Input}: Two equal-length streams of evidence, DDM parameters.\\
\emph{Output}: A time-series of choice (0=R, 1=L, 2=continue) and accumulated evidence (scaled by drift since we are working with the DDM).

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{DDM }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(}\AttributeTok{L=}\FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{0}\NormalTok{,}\DecValTok{0}\NormalTok{), }\AttributeTok{R=}\FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{0}\NormalTok{,}\DecValTok{0}\NormalTok{), }\AttributeTok{b=}\DecValTok{0}\NormalTok{, }\AttributeTok{d=}\NormalTok{.}\DecValTok{002}\NormalTok{, }\AttributeTok{sig=}\NormalTok{.}\DecValTok{03}\NormalTok{, }\AttributeTok{bound=}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{1}\NormalTok{)) \{}
  \ControlFlowTok{if}\NormalTok{ (}\FunctionTok{length}\NormalTok{(L)}\SpecialCharTok{!=}\FunctionTok{length}\NormalTok{(R)) \{}\FunctionTok{stop}\NormalTok{(}\StringTok{"L and R differ in length."}\NormalTok{)\}}
  \ControlFlowTok{if}\NormalTok{ (}\FunctionTok{length}\NormalTok{(b)}\SpecialCharTok{!=}\DecValTok{1} \SpecialCharTok{|} \FunctionTok{length}\NormalTok{(d)}\SpecialCharTok{!=}\DecValTok{1} \SpecialCharTok{|} \FunctionTok{length}\NormalTok{(sig)}\SpecialCharTok{!=}\DecValTok{1}\NormalTok{) \{}\FunctionTok{stop}\NormalTok{(}\StringTok{"Invalid DDM parameters."}\NormalTok{)\}}
  \ControlFlowTok{if}\NormalTok{ (}\FunctionTok{length}\NormalTok{(bound)}\SpecialCharTok{!=}\FunctionTok{length}\NormalTok{(L) }\SpecialCharTok{\&} \FunctionTok{length}\NormalTok{(bound)}\SpecialCharTok{!=}\DecValTok{1}\NormalTok{) \{}\FunctionTok{stop}\NormalTok{(}\StringTok{"Invalid bound. Must be defined at every time point or fixed."}\NormalTok{)\}}
  \ControlFlowTok{if}\NormalTok{ (}\FunctionTok{length}\NormalTok{(bound)}\SpecialCharTok{==}\DecValTok{1}\NormalTok{) \{ub }\OtherTok{\textless{}{-}} \FunctionTok{rep}\NormalTok{(bound, }\FunctionTok{length}\NormalTok{(L))\} }\ControlFlowTok{else}\NormalTok{ \{ub }\OtherTok{\textless{}{-}}\NormalTok{ bound\}}
\NormalTok{  df }\OtherTok{\textless{}{-}} \FunctionTok{data.frame}\NormalTok{(}
    \AttributeTok{sample =} \FunctionTok{rep}\NormalTok{(}\ConstantTok{NA}\NormalTok{, }\FunctionTok{length}\NormalTok{(L)),}
    \AttributeTok{choice =} \FunctionTok{rep}\NormalTok{(}\ConstantTok{NA}\NormalTok{, }\FunctionTok{length}\NormalTok{(L)),}
    \AttributeTok{ae =} \FunctionTok{rep}\NormalTok{(}\ConstantTok{NA}\NormalTok{, }\FunctionTok{length}\NormalTok{(L))}
\NormalTok{  )}
\NormalTok{  RDV }\OtherTok{\textless{}{-}}\NormalTok{ b}
\NormalTok{  accumEvid }\OtherTok{\textless{}{-}} \DecValTok{0}
\NormalTok{  boundaryHit }\OtherTok{\textless{}{-}}\NormalTok{ F}
  \ControlFlowTok{for}\NormalTok{ (t }\ControlFlowTok{in} \DecValTok{1}\SpecialCharTok{:}\FunctionTok{length}\NormalTok{(L)) \{}
\NormalTok{    df}\SpecialCharTok{$}\NormalTok{sample[t] }\OtherTok{\textless{}{-}}\NormalTok{ t}
\NormalTok{    RDV }\OtherTok{\textless{}{-}}\NormalTok{ RDV }\SpecialCharTok{+}\NormalTok{ d}\SpecialCharTok{*}\NormalTok{(L[t]}\SpecialCharTok{{-}}\NormalTok{R[t]) }\SpecialCharTok{+} \FunctionTok{rnorm}\NormalTok{(}\DecValTok{1}\NormalTok{, }\AttributeTok{mean=}\DecValTok{0}\NormalTok{, }\AttributeTok{sd=}\NormalTok{sig)}
\NormalTok{    accumEvid }\OtherTok{\textless{}{-}}\NormalTok{ accumEvid }\SpecialCharTok{+}\NormalTok{ d}\SpecialCharTok{*}\NormalTok{(L[t]}\SpecialCharTok{{-}}\NormalTok{R[t]) }\CommentTok{\# Accumulated evidence depends on the model you\textquotesingle{}re using.}
\NormalTok{    df}\SpecialCharTok{$}\NormalTok{ae[t] }\OtherTok{\textless{}{-}}\NormalTok{ accumEvid}
\NormalTok{    df}\SpecialCharTok{$}\NormalTok{choice[t] }\OtherTok{\textless{}{-}} \DecValTok{2}
    \ControlFlowTok{if}\NormalTok{ (RDV}\SpecialCharTok{\textgreater{}=}\NormalTok{ub[t] }\SpecialCharTok{|}\NormalTok{ RDV}\SpecialCharTok{\textless{}={-}}\NormalTok{ub[t]) \{}
      \ControlFlowTok{if}\NormalTok{ (RDV}\SpecialCharTok{\textgreater{}=}\NormalTok{ub[t]) \{df}\SpecialCharTok{$}\NormalTok{choice[t] }\OtherTok{\textless{}{-}} \DecValTok{1}\NormalTok{\}}
      \ControlFlowTok{if}\NormalTok{ (RDV}\SpecialCharTok{\textless{}={-}}\NormalTok{ub[t]) \{df}\SpecialCharTok{$}\NormalTok{choice[t] }\OtherTok{\textless{}{-}} \DecValTok{0}\NormalTok{\}}
\NormalTok{      boundaryHit }\OtherTok{\textless{}{-}}\NormalTok{ T}
      \ControlFlowTok{break}
\NormalTok{    \}}
\NormalTok{  \}}
  \CommentTok{\# if (boundaryHit==F) \{ \#Use this to figure out which trials didn\textquotesingle{}t reach a decision.}
  \CommentTok{\#   print("Decision was not reached within allotted number of samples.")}
  \CommentTok{\# \} }
  \FunctionTok{return}\NormalTok{(df)}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\hypertarget{trial-data}{%
\subsubsection*{Trial Data}\label{trial-data}}
\addcontentsline{toc}{subsubsection}{Trial Data}

This will be exactly the same for both the fixed and collapsing cyborgs. Heights will vary around 50, bounded within (0,100). All trials will favor either L or R, but the degree of difficulty may vary.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{set.seed}\NormalTok{(seed)}
\NormalTok{nSamples }\OtherTok{=} \DecValTok{50}
\NormalTok{nTrials }\OtherTok{=} \DecValTok{1000}
\NormalTok{byTrial.mean }\OtherTok{=} \DecValTok{50}
\NormalTok{byTrial.sd }\OtherTok{=} \DecValTok{20}
\NormalTok{bySample.sd }\OtherTok{=} \DecValTok{20}
\NormalTok{lb }\OtherTok{\textless{}{-}} \DecValTok{0}
\NormalTok{ub }\OtherTok{\textless{}{-}} \DecValTok{100}

\NormalTok{simulateData }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(nSamples,nTrials,byTrial.mean,byTrial.sd,bySample.sd,lb,ub) \{}
\NormalTok{  simData }\OtherTok{\textless{}{-}} \FunctionTok{data.frame}\NormalTok{(}
    \AttributeTok{trial =} \DecValTok{1}\NormalTok{,}
    \AttributeTok{L =} \FunctionTok{rtruncnorm}\NormalTok{(}
\NormalTok{      nSamples,}
      \AttributeTok{mean =} \FunctionTok{rnorm}\NormalTok{(}\DecValTok{1}\NormalTok{, }\AttributeTok{mean =}\NormalTok{ byTrial.mean, }\AttributeTok{sd =}\NormalTok{ byTrial.sd),}
      \AttributeTok{sd =}\NormalTok{ bySample.sd,}
      \AttributeTok{a =}\NormalTok{ lb,}
      \AttributeTok{b =}\NormalTok{ ub}
\NormalTok{    ),}
    \AttributeTok{R =} \FunctionTok{rtruncnorm}\NormalTok{(}
\NormalTok{      nSamples,}
      \AttributeTok{mean =} \FunctionTok{rnorm}\NormalTok{(}\DecValTok{1}\NormalTok{, }\AttributeTok{mean =}\NormalTok{ byTrial.mean, }\AttributeTok{sd =}\NormalTok{ byTrial.sd),}
      \AttributeTok{sd =}\NormalTok{ bySample.sd,}
      \AttributeTok{a =}\NormalTok{ lb,}
      \AttributeTok{b =}\NormalTok{ ub}
\NormalTok{    )}
\NormalTok{  )}
  
  \ControlFlowTok{for}\NormalTok{ (n }\ControlFlowTok{in} \DecValTok{2}\SpecialCharTok{:}\NormalTok{nTrials) \{}
  \CommentTok{\#progress(n, nTrials) \#progress tracker}
\NormalTok{  tempData }\OtherTok{\textless{}{-}} \FunctionTok{data.frame}\NormalTok{(}
    \AttributeTok{trial =}\NormalTok{ n,}
    \AttributeTok{L =} \FunctionTok{rtruncnorm}\NormalTok{(}
\NormalTok{      nSamples,}
      \AttributeTok{mean =} \FunctionTok{rnorm}\NormalTok{(}\DecValTok{1}\NormalTok{, }\AttributeTok{mean =}\NormalTok{ byTrial.mean, }\AttributeTok{sd =}\NormalTok{ byTrial.sd),}
      \AttributeTok{sd =}\NormalTok{ bySample.sd,}
      \AttributeTok{a =}\NormalTok{ lb,}
      \AttributeTok{b =}\NormalTok{ ub}
\NormalTok{    ),}
    \AttributeTok{R =} \FunctionTok{rtruncnorm}\NormalTok{(}
\NormalTok{      nSamples,}
      \AttributeTok{mean =} \FunctionTok{rnorm}\NormalTok{(}\DecValTok{1}\NormalTok{, }\AttributeTok{mean =}\NormalTok{ byTrial.mean, }\AttributeTok{sd =}\NormalTok{ byTrial.sd),}
      \AttributeTok{sd =}\NormalTok{ bySample.sd,}
      \AttributeTok{a =}\NormalTok{ lb,}
      \AttributeTok{b =}\NormalTok{ ub}
\NormalTok{    )}
\NormalTok{  )}
\NormalTok{  simData }\OtherTok{\textless{}{-}} \FunctionTok{rbind}\NormalTok{(simData, tempData)}
\NormalTok{  \}}
  \FunctionTok{return}\NormalTok{(simData)}
\NormalTok{\}}

\NormalTok{simData }\OtherTok{\textless{}{-}} \FunctionTok{simulateData}\NormalTok{(}
\NormalTok{  nSamples,}
\NormalTok{  nTrials,}
\NormalTok{  byTrial.mean,}
\NormalTok{  byTrial.sd,}
\NormalTok{  bySample.sd,}
\NormalTok{  lb,}
\NormalTok{  ub)}
\end{Highlighting}
\end{Shaded}

\hypertarget{fixed-bounds-cyborg}{%
\subsubsection*{Fixed bounds cyborg}\label{fixed-bounds-cyborg}}
\addcontentsline{toc}{subsubsection}{Fixed bounds cyborg}

Bounds are fixed to 50 and -50 via the `bound' attribute of the fixedCyborg.ddm object.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{set.seed}\NormalTok{(seed)}

\NormalTok{fixedCyborg.ddm }\OtherTok{\textless{}{-}} \FunctionTok{list}\NormalTok{(}
  \AttributeTok{b =} \DecValTok{0}\NormalTok{,}
  \AttributeTok{d =}\NormalTok{ .}\DecValTok{9}\NormalTok{,}
  \AttributeTok{sig =} \DecValTok{4}\NormalTok{,}
  \AttributeTok{bound =} \DecValTok{50}
\NormalTok{)}

\NormalTok{trialData }\OtherTok{\textless{}{-}} \FunctionTok{list}\NormalTok{(}
    \AttributeTok{L =}\NormalTok{ simData}\SpecialCharTok{$}\NormalTok{L[simData}\SpecialCharTok{$}\NormalTok{trial}\SpecialCharTok{==}\DecValTok{1}\NormalTok{],}
    \AttributeTok{R =}\NormalTok{ simData}\SpecialCharTok{$}\NormalTok{R[simData}\SpecialCharTok{$}\NormalTok{trial}\SpecialCharTok{==}\DecValTok{1}\NormalTok{]}
\NormalTok{  )  }
\NormalTok{fixedCyborg.data }\OtherTok{\textless{}{-}} \FunctionTok{do.call}\NormalTok{(DDM, }\FunctionTok{c}\NormalTok{(trialData,fixedCyborg.ddm))}
\NormalTok{fixedCyborg.data}\SpecialCharTok{$}\NormalTok{trial }\OtherTok{\textless{}{-}} \DecValTok{1}

\ControlFlowTok{for}\NormalTok{ (trial }\ControlFlowTok{in} \DecValTok{2}\SpecialCharTok{:}\NormalTok{nTrials) \{}
  \CommentTok{\#progress(trial,nTrials) \#progress tracker}
\NormalTok{  trialData }\OtherTok{\textless{}{-}} \FunctionTok{list}\NormalTok{(}
    \AttributeTok{L =}\NormalTok{ simData}\SpecialCharTok{$}\NormalTok{L[simData}\SpecialCharTok{$}\NormalTok{trial}\SpecialCharTok{==}\NormalTok{trial],}
    \AttributeTok{R =}\NormalTok{ simData}\SpecialCharTok{$}\NormalTok{R[simData}\SpecialCharTok{$}\NormalTok{trial}\SpecialCharTok{==}\NormalTok{trial]}
\NormalTok{  )  }
\NormalTok{  tempData }\OtherTok{\textless{}{-}} \FunctionTok{do.call}\NormalTok{(DDM, }\FunctionTok{c}\NormalTok{(trialData,fixedCyborg.ddm))}
\NormalTok{  tempData}\SpecialCharTok{$}\NormalTok{trial }\OtherTok{\textless{}{-}}\NormalTok{ trial}
\NormalTok{  fixedCyborg.data }\OtherTok{\textless{}{-}} \FunctionTok{rbind}\NormalTok{(fixedCyborg.data, tempData)}
\NormalTok{\}}
\NormalTok{fixedCyborg.data }\OtherTok{\textless{}{-}} \FunctionTok{na.omit}\NormalTok{(fixedCyborg.data)}
\FunctionTok{summary}\NormalTok{(fixedCyborg.data)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##      sample           choice           ae                trial       
##  Min.   : 1.000   Min.   :0.00   Min.   :-123.9434   Min.   :   1.0  
##  1st Qu.: 2.000   1st Qu.:2.00   1st Qu.: -27.4550   1st Qu.: 256.0  
##  Median : 3.000   Median :2.00   Median :  -0.1181   Median : 517.5  
##  Mean   : 4.606   Mean   :1.67   Mean   :   0.2420   Mean   : 508.7  
##  3rd Qu.: 6.000   3rd Qu.:2.00   3rd Qu.:  28.3773   3rd Qu.: 750.8  
##  Max.   :33.000   Max.   :2.00   Max.   : 134.0897   Max.   :1000.0
\end{verbatim}

\hypertarget{collapsing-bounds-cyborg}{%
\subsubsection*{Collapsing bounds cyborg}\label{collapsing-bounds-cyborg}}
\addcontentsline{toc}{subsubsection}{Collapsing bounds cyborg}

Bounds are decreasing as a Weibull function. Weibull parameters are taken directly from \citep{glickman2022}, which I'm led to believe are taken directly from \citep{hawkins2015}. The Weibull function is taken directly from \citep{hawkins2015}. The scale parameter (\(\lambda\)) is fixed to 4. Shape (\(\kappa\)) and asymptotic convergence (\(a'\)) can vary.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{set.seed}\NormalTok{(seed)}

\NormalTok{weibullbound }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(t, a, k, lam, ap) \{}
  \FunctionTok{return}\NormalTok{( a}\SpecialCharTok{{-}}\NormalTok{(}\DecValTok{1}\SpecialCharTok{{-}}\FunctionTok{exp}\NormalTok{(}\SpecialCharTok{{-}}\NormalTok{(t}\SpecialCharTok{/}\NormalTok{k)}\SpecialCharTok{\^{}}\NormalTok{k))}\SpecialCharTok{*}\NormalTok{(.}\DecValTok{5}\SpecialCharTok{*}\NormalTok{a}\SpecialCharTok{+}\NormalTok{ap) )}
\NormalTok{\}}

\NormalTok{collapsingCyborg.ddm }\OtherTok{\textless{}{-}} \FunctionTok{list}\NormalTok{(}
  \AttributeTok{b =} \DecValTok{0}\NormalTok{,}
  \AttributeTok{d =}\NormalTok{ .}\DecValTok{9}\NormalTok{,}
  \AttributeTok{sig =} \DecValTok{4}\NormalTok{,}
  \AttributeTok{bound =} \FunctionTok{weibullbound}\NormalTok{(}\AttributeTok{t=}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\SpecialCharTok{:}\NormalTok{nSamples), }\AttributeTok{a=}\DecValTok{100}\NormalTok{, }\AttributeTok{k=}\DecValTok{3}\NormalTok{, }\AttributeTok{lam=}\DecValTok{4}\NormalTok{, }\AttributeTok{ap=}\DecValTok{10}\NormalTok{) }\CommentTok{\# see Glickman et al. (2022) or Hawkins et al. (2015)}
\NormalTok{)}

\NormalTok{trialData }\OtherTok{\textless{}{-}} \FunctionTok{list}\NormalTok{(}
  \AttributeTok{L =}\NormalTok{ simData}\SpecialCharTok{$}\NormalTok{L[simData}\SpecialCharTok{$}\NormalTok{trial}\SpecialCharTok{==}\DecValTok{1}\NormalTok{],}
  \AttributeTok{R =}\NormalTok{ simData}\SpecialCharTok{$}\NormalTok{R[simData}\SpecialCharTok{$}\NormalTok{trial}\SpecialCharTok{==}\DecValTok{1}\NormalTok{]}
\NormalTok{)  }
\NormalTok{collapsingCyborg.data }\OtherTok{\textless{}{-}} \FunctionTok{do.call}\NormalTok{(DDM, }\FunctionTok{c}\NormalTok{(trialData,collapsingCyborg.ddm))}
\NormalTok{collapsingCyborg.data}\SpecialCharTok{$}\NormalTok{trial }\OtherTok{\textless{}{-}} \DecValTok{1}

\ControlFlowTok{for}\NormalTok{ (trial }\ControlFlowTok{in} \DecValTok{2}\SpecialCharTok{:}\NormalTok{nTrials) \{}
  \CommentTok{\#progress(trial,nTrials) \#progress tracker}
\NormalTok{  trialData }\OtherTok{\textless{}{-}} \FunctionTok{list}\NormalTok{(}
    \AttributeTok{L =}\NormalTok{ simData}\SpecialCharTok{$}\NormalTok{L[simData}\SpecialCharTok{$}\NormalTok{trial}\SpecialCharTok{==}\NormalTok{trial],}
    \AttributeTok{R =}\NormalTok{ simData}\SpecialCharTok{$}\NormalTok{R[simData}\SpecialCharTok{$}\NormalTok{trial}\SpecialCharTok{==}\NormalTok{trial]}
\NormalTok{  )  }
\NormalTok{  tempData }\OtherTok{\textless{}{-}} \FunctionTok{do.call}\NormalTok{(DDM, }\FunctionTok{c}\NormalTok{(trialData,collapsingCyborg.ddm))}
\NormalTok{  tempData}\SpecialCharTok{$}\NormalTok{trial }\OtherTok{\textless{}{-}}\NormalTok{ trial}
\NormalTok{  collapsingCyborg.data }\OtherTok{\textless{}{-}} \FunctionTok{rbind}\NormalTok{(collapsingCyborg.data, tempData)}
\NormalTok{\}}
\NormalTok{collapsingCyborg.data }\OtherTok{\textless{}{-}} \FunctionTok{na.omit}\NormalTok{(collapsingCyborg.data)}
\FunctionTok{summary}\NormalTok{(collapsingCyborg.data)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##      sample           choice            ae                trial       
##  Min.   : 1.000   Min.   :0.000   Min.   :-162.7401   Min.   :   1.0  
##  1st Qu.: 2.000   1st Qu.:2.000   1st Qu.: -29.7781   1st Qu.: 234.0  
##  Median : 3.000   Median :2.000   Median :   0.6016   Median : 500.0  
##  Mean   : 3.832   Mean   :1.684   Mean   :   0.7965   Mean   : 496.9  
##  3rd Qu.: 5.000   3rd Qu.:2.000   3rd Qu.:  32.0336   3rd Qu.: 747.0  
##  Max.   :30.000   Max.   :2.000   Max.   : 153.0255   Max.   :1000.0
\end{verbatim}

\hypertarget{check-behavior}{%
\subsection{Check behavior}\label{check-behavior}}

\hypertarget{fixed-bounds-cyborg-1}{%
\subsubsection*{Fixed bounds cyborg}\label{fixed-bounds-cyborg-1}}
\addcontentsline{toc}{subsubsection}{Fixed bounds cyborg}

Behavior makes sense given the decision boundaries. There is some leakage across the boundaries proportional to the variance of the noise in the DDM.

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/fixed_check-1} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/fixed_check-2} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/fixed_check-3} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/fixed_check-4} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/fixed_check-5} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/fixed_check-6} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/fixed_check-7} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/fixed_check-8} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/fixed_check-9} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/fixed_check-10} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/fixed_check-11} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/fixed_check-12} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/fixed_check-13} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/fixed_check-14} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/fixed_check-15} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/fixed_check-16} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/fixed_check-17} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/fixed_check-18} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/fixed_check-19} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/fixed_check-20} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/fixed_check-21} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/fixed_check-22} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/fixed_check-23} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/fixed_check-24} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/fixed_check-25} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/fixed_check-26} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/fixed_check-27} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/fixed_check-28} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/fixed_check-29} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/fixed_check-30} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/fixed_check-31} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/fixed_check-32} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/fixed_check-33} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/fixed_check-34} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/fixed_check-35} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/fixed_check-36} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/fixed_check-37} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/fixed_check-38} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/fixed_check-39} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/fixed_check-40} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/fixed_check-41} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/fixed_check-42} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/fixed_check-43} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/fixed_check-44} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/fixed_check-45} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/fixed_check-46} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/fixed_check-47} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/fixed_check-48} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/fixed_check-49} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/fixed_check-50} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/fixed_check-51} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/fixed_check-52} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/fixed_check-53} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/fixed_check-54} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/fixed_check-55} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/fixed_check-56} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/fixed_check-57} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/fixed_check-58} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/fixed_check-59} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/fixed_check-60} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/fixed_check-61} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/fixed_check-62} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/fixed_check-63} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/fixed_check-64} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/fixed_check-65} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/fixed_check-66} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/fixed_check-67} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/fixed_check-68} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/fixed_check-69} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/fixed_check-70} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/fixed_check-71} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/fixed_check-72} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/fixed_check-73} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/fixed_check-74} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/fixed_check-75} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/fixed_check-76} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/fixed_check-77} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/fixed_check-78} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/fixed_check-79} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/fixed_check-80} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/fixed_check-81} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/fixed_check-82} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/fixed_check-83} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/fixed_check-84} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/fixed_check-85} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/fixed_check-86} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/fixed_check-87} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/fixed_check-88} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/fixed_check-89} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/fixed_check-90} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/fixed_check-91} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/fixed_check-92} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/fixed_check-93} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/fixed_check-94} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/fixed_check-95} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/fixed_check-96} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/fixed_check-97} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/fixed_check-98} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/fixed_check-99} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/fixed_check-100} \end{center}

\hypertarget{collapsing-bounds-cyborg-1}{%
\subsubsection*{Collapsing bounds cyborg}\label{collapsing-bounds-cyborg-1}}
\addcontentsline{toc}{subsubsection}{Collapsing bounds cyborg}

Behavior makes sense given the decision boundaries. There is some leakage across the boundaries proportional to the variance of the noise in the DDM.

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/collapsing_check-1} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/collapsing_check-2} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/collapsing_check-3} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/collapsing_check-4} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/collapsing_check-5} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/collapsing_check-6} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/collapsing_check-7} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/collapsing_check-8} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/collapsing_check-9} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/collapsing_check-10} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/collapsing_check-11} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/collapsing_check-12} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/collapsing_check-13} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/collapsing_check-14} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/collapsing_check-15} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/collapsing_check-16} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/collapsing_check-17} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/collapsing_check-18} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/collapsing_check-19} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/collapsing_check-20} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/collapsing_check-21} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/collapsing_check-22} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/collapsing_check-23} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/collapsing_check-24} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/collapsing_check-25} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/collapsing_check-26} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/collapsing_check-27} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/collapsing_check-28} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/collapsing_check-29} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/collapsing_check-30} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/collapsing_check-31} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/collapsing_check-32} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/collapsing_check-33} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/collapsing_check-34} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/collapsing_check-35} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/collapsing_check-36} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/collapsing_check-37} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/collapsing_check-38} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/collapsing_check-39} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/collapsing_check-40} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/collapsing_check-41} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/collapsing_check-42} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/collapsing_check-43} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/collapsing_check-44} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/collapsing_check-45} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/collapsing_check-46} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/collapsing_check-47} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/collapsing_check-48} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/collapsing_check-49} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/collapsing_check-50} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/collapsing_check-51} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/collapsing_check-52} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/collapsing_check-53} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/collapsing_check-54} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/collapsing_check-55} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/collapsing_check-56} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/collapsing_check-57} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/collapsing_check-58} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/collapsing_check-59} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/collapsing_check-60} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/collapsing_check-61} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/collapsing_check-62} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/collapsing_check-63} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/collapsing_check-64} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/collapsing_check-65} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/collapsing_check-66} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/collapsing_check-67} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/collapsing_check-68} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/collapsing_check-69} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/collapsing_check-70} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/collapsing_check-71} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/collapsing_check-72} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/collapsing_check-73} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/collapsing_check-74} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/collapsing_check-75} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/collapsing_check-76} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/collapsing_check-77} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/collapsing_check-78} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/collapsing_check-79} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/collapsing_check-80} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/collapsing_check-81} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/collapsing_check-82} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/collapsing_check-83} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/collapsing_check-84} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/collapsing_check-85} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/collapsing_check-86} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/collapsing_check-87} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/collapsing_check-88} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/collapsing_check-89} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/collapsing_check-90} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/collapsing_check-91} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/collapsing_check-92} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/collapsing_check-93} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/collapsing_check-94} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/collapsing_check-95} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/collapsing_check-96} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/collapsing_check-97} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/collapsing_check-98} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/collapsing_check-99} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/collapsing_check-100} \end{center}

\hypertarget{dcb-1}{%
\subsection{DCB}\label{dcb-1}}

\hypertarget{dcb-function}{%
\subsubsection*{DCB function}\label{dcb-function}}
\addcontentsline{toc}{subsubsection}{DCB function}

Dynamically estimate collapsing decision boundaries up to a certain sample number.\\
\emph{Input}: (1) Time-series data for a single subject with trial, sample number, choice (\{0,1,2\} see above), and accumulated evidence. (2) Maximum sample number (since our figures only go up to 10, let's just set this as 10 for now).\\
\emph{Output}: Time-series of the bound, over sample number dimension (time). Note that \citep{glickman2022} assumed that the collapsing bounds were symmetrical, therefore they took the average of the separating planes.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{DCB }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(data, maxSample) \{}
\NormalTok{  samples }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\DecValTok{1}\SpecialCharTok{:}\NormalTok{maxSample)}
\NormalTok{  output }\OtherTok{\textless{}{-}} \FunctionTok{data.frame}\NormalTok{(}
    \AttributeTok{sample =}\NormalTok{ samples,}
    \AttributeTok{ub =} \FunctionTok{rep}\NormalTok{(}\ConstantTok{NA}\NormalTok{, }\FunctionTok{length}\NormalTok{(samples)),}
    \AttributeTok{lb =} \FunctionTok{rep}\NormalTok{(}\ConstantTok{NA}\NormalTok{, }\FunctionTok{length}\NormalTok{(samples)),}
    \AttributeTok{avgb =} \FunctionTok{rep}\NormalTok{(}\ConstantTok{NA}\NormalTok{, }\FunctionTok{length}\NormalTok{(samples))}
\NormalTok{  )}
\NormalTok{  x\_vals }\OtherTok{\textless{}{-}} \FunctionTok{data.frame}\NormalTok{(}\AttributeTok{ae =} \FunctionTok{seq}\NormalTok{(}\SpecialCharTok{{-}}\DecValTok{150}\NormalTok{,}\DecValTok{150}\NormalTok{,}\DecValTok{1}\NormalTok{)) }\CommentTok{\# resolution of the collapsing boundary}
  \ControlFlowTok{for}\NormalTok{ (n }\ControlFlowTok{in}\NormalTok{ samples) \{ }\CommentTok{\#samples}
    \FunctionTok{tryCatch}\NormalTok{(\{ }\CommentTok{\# In some cases, there may not be any decisions for left or right when sample number is small. Don\textquotesingle{}t return an error.}
\NormalTok{      lda.fit }\OtherTok{\textless{}{-}} \FunctionTok{lda}\NormalTok{(choice}\SpecialCharTok{\textasciitilde{}}\NormalTok{ae, data[data}\SpecialCharTok{$}\NormalTok{sample}\SpecialCharTok{==}\NormalTok{n,])}
\NormalTok{      lda.pred }\OtherTok{\textless{}{-}} \FunctionTok{predict}\NormalTok{(lda.fit,x\_vals)}
      \CommentTok{\#x\_val closest to decision boundary for upper bound (.5 posterior probability of being choice=1 or 2)}
\NormalTok{      ub\_x\_vals }\OtherTok{\textless{}{-}} \FunctionTok{seq}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{150}\NormalTok{,}\DecValTok{1}\NormalTok{)}
\NormalTok{      output}\SpecialCharTok{$}\NormalTok{ub[n] }\OtherTok{=}\NormalTok{ ub\_x\_vals[ }\FunctionTok{which}\NormalTok{(}\FunctionTok{abs}\NormalTok{(lda.pred}\SpecialCharTok{$}\NormalTok{posterior[}\DecValTok{151}\SpecialCharTok{:}\DecValTok{301}\NormalTok{,}\StringTok{\textquotesingle{}2\textquotesingle{}}\NormalTok{]}\SpecialCharTok{{-}}\FloatTok{0.5}\NormalTok{)}\SpecialCharTok{==}\FunctionTok{min}\NormalTok{(}\FunctionTok{abs}\NormalTok{(lda.pred}\SpecialCharTok{$}\NormalTok{posterior[}\DecValTok{151}\SpecialCharTok{:}\DecValTok{301}\NormalTok{,}\StringTok{\textquotesingle{}2\textquotesingle{}}\NormalTok{]}\SpecialCharTok{{-}}\FloatTok{0.5}\NormalTok{))) ]}
      \CommentTok{\#x\_val closest to decision boundary for lower bound (.5 posterior probability of being choice=0 or 2)}
\NormalTok{      lb\_x\_vals }\OtherTok{\textless{}{-}} \FunctionTok{seq}\NormalTok{(}\SpecialCharTok{{-}}\DecValTok{150}\NormalTok{,}\SpecialCharTok{{-}}\DecValTok{1}\NormalTok{,}\DecValTok{1}\NormalTok{)}
\NormalTok{      output}\SpecialCharTok{$}\NormalTok{lb[n] }\OtherTok{=}\NormalTok{ lb\_x\_vals[ }\FunctionTok{which}\NormalTok{(}\FunctionTok{abs}\NormalTok{(lda.pred}\SpecialCharTok{$}\NormalTok{posterior[}\DecValTok{1}\SpecialCharTok{:}\DecValTok{150}\NormalTok{,}\StringTok{\textquotesingle{}2\textquotesingle{}}\NormalTok{]}\SpecialCharTok{{-}}\FloatTok{0.5}\NormalTok{)}\SpecialCharTok{==}\FunctionTok{min}\NormalTok{(}\FunctionTok{abs}\NormalTok{(lda.pred}\SpecialCharTok{$}\NormalTok{posterior[}\DecValTok{1}\SpecialCharTok{:}\DecValTok{150}\NormalTok{,}\StringTok{\textquotesingle{}2\textquotesingle{}}\NormalTok{]}\SpecialCharTok{{-}}\FloatTok{0.5}\NormalTok{))) ]}
\NormalTok{      output}\SpecialCharTok{$}\NormalTok{avgb[n] }\OtherTok{=}\NormalTok{ .}\DecValTok{5}\SpecialCharTok{*}\NormalTok{(}\FunctionTok{abs}\NormalTok{(output}\SpecialCharTok{$}\NormalTok{ub[n])}\SpecialCharTok{+}\FunctionTok{abs}\NormalTok{(output}\SpecialCharTok{$}\NormalTok{lb[n]))}
\NormalTok{    \}, }\AttributeTok{error=}\ControlFlowTok{function}\NormalTok{(e)\{}\FunctionTok{cat}\NormalTok{(}\StringTok{"ERROR :"}\NormalTok{,}\FunctionTok{conditionMessage}\NormalTok{(e), }\StringTok{"}\SpecialCharTok{\textbackslash{}n}\StringTok{"}\NormalTok{)\})}
\NormalTok{  \}}
  \FunctionTok{return}\NormalTok{(output)}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\hypertarget{fixed-bounds-cyborg-2}{%
\subsubsection*{Fixed bounds cyborg}\label{fixed-bounds-cyborg-2}}
\addcontentsline{toc}{subsubsection}{Fixed bounds cyborg}

The DCB isn't perfect, but I honestly can't deny that I'm surprised by its accuracy. Clearly it performs worse as data becomes sparse (i.e.~when there are fewer choices at later times).

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/fixed_dcb-1} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/fixed_dcb-2} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/fixed_dcb-3} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/fixed_dcb-4} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/fixed_dcb-5} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/fixed_dcb-6} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/fixed_dcb-7} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/fixed_dcb-8} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/fixed_dcb-9} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/fixed_dcb-10} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/fixed_dcb-11} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/fixed_dcb-12} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/fixed_dcb-13} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/fixed_dcb-14} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/fixed_dcb-15} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/fixed_dcb-16} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/fixed_dcb-17} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/fixed_dcb-18} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/fixed_dcb-19} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/fixed_dcb-20} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/fixed_dcb-21} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/fixed_dcb-22} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/fixed_dcb-23} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/fixed_dcb-24} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/fixed_dcb-25} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/fixed_dcb-26} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/fixed_dcb-27} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/fixed_dcb-28} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/fixed_dcb-29} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/fixed_dcb-30} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/fixed_dcb-31} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/fixed_dcb-32} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/fixed_dcb-33} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/fixed_dcb-34} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/fixed_dcb-35} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/fixed_dcb-36} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/fixed_dcb-37} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/fixed_dcb-38} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/fixed_dcb-39} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/fixed_dcb-40} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/fixed_dcb-41} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/fixed_dcb-42} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/fixed_dcb-43} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/fixed_dcb-44} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/fixed_dcb-45} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/fixed_dcb-46} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/fixed_dcb-47} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/fixed_dcb-48} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/fixed_dcb-49} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/fixed_dcb-50} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/fixed_dcb-51} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/fixed_dcb-52} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/fixed_dcb-53} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/fixed_dcb-54} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/fixed_dcb-55} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/fixed_dcb-56} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/fixed_dcb-57} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/fixed_dcb-58} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/fixed_dcb-59} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/fixed_dcb-60} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/fixed_dcb-61} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/fixed_dcb-62} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/fixed_dcb-63} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/fixed_dcb-64} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/fixed_dcb-65} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/fixed_dcb-66} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/fixed_dcb-67} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/fixed_dcb-68} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/fixed_dcb-69} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/fixed_dcb-70} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/fixed_dcb-71} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/fixed_dcb-72} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/fixed_dcb-73} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/fixed_dcb-74} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/fixed_dcb-75} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/fixed_dcb-76} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/fixed_dcb-77} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/fixed_dcb-78} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/fixed_dcb-79} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/fixed_dcb-80} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/fixed_dcb-81} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/fixed_dcb-82} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/fixed_dcb-83} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/fixed_dcb-84} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/fixed_dcb-85} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/fixed_dcb-86} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/fixed_dcb-87} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/fixed_dcb-88} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/fixed_dcb-89} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/fixed_dcb-90} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/fixed_dcb-91} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/fixed_dcb-92} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/fixed_dcb-93} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/fixed_dcb-94} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/fixed_dcb-95} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/fixed_dcb-96} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/fixed_dcb-97} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/fixed_dcb-98} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/fixed_dcb-99} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/fixed_dcb-100} \end{center}

\hypertarget{collapsing-bounds-cyborg-2}{%
\subsubsection*{Collapsing bounds cyborg}\label{collapsing-bounds-cyborg-2}}
\addcontentsline{toc}{subsubsection}{Collapsing bounds cyborg}

This is where things get even more interesting. The DCB follows the collapsing bound generated by a Weibull function quite well.

\begin{verbatim}
## ERROR : infinite or missing values in 'x'
\end{verbatim}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/collapsing_dcb-1} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/collapsing_dcb-2} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/collapsing_dcb-3} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/collapsing_dcb-4} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/collapsing_dcb-5} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/collapsing_dcb-6} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/collapsing_dcb-7} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/collapsing_dcb-8} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/collapsing_dcb-9} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/collapsing_dcb-10} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/collapsing_dcb-11} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/collapsing_dcb-12} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/collapsing_dcb-13} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/collapsing_dcb-14} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/collapsing_dcb-15} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/collapsing_dcb-16} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/collapsing_dcb-17} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/collapsing_dcb-18} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/collapsing_dcb-19} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/collapsing_dcb-20} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/collapsing_dcb-21} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/collapsing_dcb-22} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/collapsing_dcb-23} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/collapsing_dcb-24} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/collapsing_dcb-25} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/collapsing_dcb-26} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/collapsing_dcb-27} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/collapsing_dcb-28} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/collapsing_dcb-29} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/collapsing_dcb-30} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/collapsing_dcb-31} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/collapsing_dcb-32} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/collapsing_dcb-33} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/collapsing_dcb-34} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/collapsing_dcb-35} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/collapsing_dcb-36} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/collapsing_dcb-37} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/collapsing_dcb-38} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/collapsing_dcb-39} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/collapsing_dcb-40} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/collapsing_dcb-41} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/collapsing_dcb-42} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/collapsing_dcb-43} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/collapsing_dcb-44} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/collapsing_dcb-45} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/collapsing_dcb-46} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/collapsing_dcb-47} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/collapsing_dcb-48} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/collapsing_dcb-49} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/collapsing_dcb-50} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/collapsing_dcb-51} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/collapsing_dcb-52} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/collapsing_dcb-53} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/collapsing_dcb-54} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/collapsing_dcb-55} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/collapsing_dcb-56} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/collapsing_dcb-57} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/collapsing_dcb-58} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/collapsing_dcb-59} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/collapsing_dcb-60} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/collapsing_dcb-61} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/collapsing_dcb-62} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/collapsing_dcb-63} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/collapsing_dcb-64} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/collapsing_dcb-65} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/collapsing_dcb-66} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/collapsing_dcb-67} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/collapsing_dcb-68} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/collapsing_dcb-69} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/collapsing_dcb-70} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/collapsing_dcb-71} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/collapsing_dcb-72} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/collapsing_dcb-73} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/collapsing_dcb-74} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/collapsing_dcb-75} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/collapsing_dcb-76} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/collapsing_dcb-77} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/collapsing_dcb-78} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/collapsing_dcb-79} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/collapsing_dcb-80} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/collapsing_dcb-81} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/collapsing_dcb-82} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/collapsing_dcb-83} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/collapsing_dcb-84} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/collapsing_dcb-85} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/collapsing_dcb-86} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/collapsing_dcb-87} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/collapsing_dcb-88} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/collapsing_dcb-89} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/collapsing_dcb-90} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/collapsing_dcb-91} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/collapsing_dcb-92} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/collapsing_dcb-93} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/collapsing_dcb-94} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/collapsing_dcb-95} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/collapsing_dcb-96} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/collapsing_dcb-97} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/collapsing_dcb-98} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/collapsing_dcb-99} \end{center}

\begin{center}\includegraphics[width=0.8\linewidth]{LateNightBayes_files/figure-latex/collapsing_dcb-100} \end{center}

\hypertarget{preliminary-conclusion}{%
\subsection{Preliminary conclusion}\label{preliminary-conclusion}}

The DCB performs remarkably well for simulated, perceptual data where there are sequences of stimuli for each decision.

There is one obvious problem at this stage. Decision boundaries cannot be estimated at a given point in time if, across all trials, all three actions are not made at that point in time. For instance, at sample 1, no choices were made for the right option; therefore, decision boundaries cannot be estimated at time \(\text{sample}=1\). This prevents the DCB from estimating the starting point of decision boundaries. This seems to be the case in \citep{glickman2022} too.

\includegraphics[width=0.3\textwidth,height=\textheight]{images/dcb-missingEarly.PNG}

\hypertarget{comparative-statics}{%
\subsection{Comparative statics}\label{comparative-statics}}

Let's see how the DCB performs when we alter some of the cyborgs' parameters.

\hypertarget{fixed-bounds-cyborg-3}{%
\subsubsection{Fixed bounds cyborg}\label{fixed-bounds-cyborg-3}}

\hypertarget{drift}{%
\paragraph*{Drift}\label{drift}}
\addcontentsline{toc}{paragraph}{Drift}

\emph{Prediction}: The DCB should work fine regardless of the drift rate since accumulated evidence can be modulated by drift rate. This should also extend to attentional discounting from the aDDM with fixation data.

\begin{itemize}
\tightlist
\item
  bias = \(0\)
\item
  noise = \(4\)
\item
  bound = \(\pm 50\)
\end{itemize}

\begin{verbatim}
## ERROR : infinite or missing values in 'x' 
## ERROR : infinite or missing values in 'x' 
## ERROR : infinite or missing values in 'x' 
## ERROR : infinite or missing values in 'x'
\end{verbatim}

\includegraphics{LateNightBayes_files/figure-latex/unnamed-chunk-7-1.pdf}

Aside from the fact that all the choices are not represented at early times when drift rate is low, we see that DCB tracks the fixed boundary well for any drift rate.

\hypertarget{noise}{%
\paragraph*{Noise}\label{noise}}
\addcontentsline{toc}{paragraph}{Noise}

This is important to consider since accumulated evidence can bleed over LDA boundaries. The more noise there is, the more that measurements of accumulated evidence will bleed over into other classifications. For instance, with a larger noise, there should be more ``continue sampling'' observations that fall above the separating plane for ``choose left'' and below the separating plane for ``choose right''. And vice versa.

\emph{Prediction}: I think more noise variance will negatively affect the performance of the DCB.

\begin{itemize}
\tightlist
\item
  bias = \(0\)
\item
  drift = \(0.9\)
\item
  bound = \(\pm 50\)
\end{itemize}

\includegraphics{LateNightBayes_files/figure-latex/unnamed-chunk-8-1.pdf}

As the variance of noise grows, we see the performance of DCB progressively deteriorate over time. I would imagine that this could become a huge problem in real data and might affect the robustness of this algorithm.

\hypertarget{bounds}{%
\paragraph*{Bounds}\label{bounds}}
\addcontentsline{toc}{paragraph}{Bounds}

\emph{Prediction}: I think this may end up mechanically similar to changing the drift rate, so I don't think changing the bounds will affect DCB performance.

\begin{itemize}
\tightlist
\item
  bias = \(0\)
\item
  drift = \(0.9\)
\item
  noise = \(4\)
\end{itemize}

\begin{verbatim}
## ERROR : infinite or missing values in 'x'
\end{verbatim}

\includegraphics{LateNightBayes_files/figure-latex/unnamed-chunk-9-1.pdf}

Bounds don't seem to affect the performance of the DCB. The relatively poor performance of the DCB when bounds are large is caused by the uneven distribution of choices at early times. Early times are dominated by ``continue sampling'', making it difficult for LDA to determine accurate classification bounds.

\hypertarget{number-of-trials}{%
\paragraph*{Number of trials}\label{number-of-trials}}
\addcontentsline{toc}{paragraph}{Number of trials}

Keeping all else constant, how does the DCB perform with varying numbers of trials.

\emph{Prediction}: DCB performance will asymptotically converge to some maximum performance. Hopefully it works well for approximately 300 trials, since I would like to apply this algorithm to more than simulated data.

\begin{itemize}
\tightlist
\item
  bias = \(0\)
\item
  drift = \(0.9\)
\item
  noise = \(4\)
\item
  bound = \(\pm 50\)
\end{itemize}

\begin{verbatim}
## ERROR : infinite or missing values in 'x'
\end{verbatim}

\includegraphics{LateNightBayes_files/figure-latex/unnamed-chunk-10-1.pdf}

The DCB performs ok at 150 trials. By 360 trials, it looks like it is fitting fixed bounds decently. Not too much performance improvement from 360 to 500 trials. I think this ultimately depends on how many choices are made at every time point, which may or may not be dependent on the total number of trials.

\hypertarget{collapsing-bounds-cyborg-3}{%
\subsubsection{Collapsing bounds cyborg}\label{collapsing-bounds-cyborg-3}}

\hypertarget{drift-1}{%
\paragraph*{Drift}\label{drift-1}}
\addcontentsline{toc}{paragraph}{Drift}

So far, our cyborgs are just linear accumulators since drift rate has been set to 1 for the cyborgs. This is a special case of the DDM, but does the DCB still work for other drift rates?\\
\emph{Prediction}: The DCB should work fine regardless of the drift rate. We just need to account for the drift rate in our accumulated evidence. This should also extend to attentional discounting from the aDDM, so long as we use fixation data.

\begin{itemize}
\tightlist
\item
  bias = \(0\)
\item
  noise = \(4\)
\item
  Weibull scale = \(4\)
\item
  Weibull shape = \(3\)
\item
  Weibull asymptote = \(10\)
\end{itemize}

\begin{verbatim}
## ERROR : infinite or missing values in 'x' 
## ERROR : infinite or missing values in 'x' 
## ERROR : infinite or missing values in 'x' 
## ERROR : infinite or missing values in 'x' 
## ERROR : infinite or missing values in 'x' 
## ERROR : infinite or missing values in 'x' 
## ERROR : infinite or missing values in 'x'
\end{verbatim}

\includegraphics{LateNightBayes_files/figure-latex/unnamed-chunk-11-1.pdf}

At low drift rates, the DCB fails to capture the asymptote of the collapsed bounds. Otherwise, it performs fine.

\hypertarget{noise-1}{%
\paragraph*{Noise}\label{noise-1}}
\addcontentsline{toc}{paragraph}{Noise}

This is important to consider since accumulated evidence can bleed over LDA boundaries. The more noise there is, the more that measurements of accumulated evidence will bleed over into other classifications. For instance, with a larger noise, there should be more ``continue sampling'' observations that fall above the separating plane for ``choose left'' and below the separating plane for ``choose right''. And vice versa.

\begin{itemize}
\tightlist
\item
  bias = \(0\)
\item
  drift = \(0.9\)
\item
  Weibull scale = \(4\)
\item
  Weibull shape = \(3\)
\item
  Weibull asymptote = \(10\)
\end{itemize}

\begin{verbatim}
## ERROR : infinite or missing values in 'x' 
## ERROR : infinite or missing values in 'x' 
## ERROR : infinite or missing values in 'x'
\end{verbatim}

\includegraphics{LateNightBayes_files/figure-latex/unnamed-chunk-12-1.pdf}

Again, performance degrades over time when noise is large. It almost looks like the boundaries collapse, then widen again. At absurdly large amounts of noise, we even see it widen, tighten, widen, and tighten (all within 10 samples!). I bet we'll see patterns like this in real data.

\hypertarget{weibull-shape}{%
\paragraph*{Weibull Shape}\label{weibull-shape}}
\addcontentsline{toc}{paragraph}{Weibull Shape}

Change the shape of the Weibull collapsing function. The larger the shape, the later the collapse.

\begin{itemize}
\tightlist
\item
  bias = \(0\)
\item
  drift = \(0.9\)
\item
  noise = \(4\)
\item
  Weibull scale = \(4\)
\item
  Weibull asymptote = \(10\)
\end{itemize}

\begin{verbatim}
## ERROR : infinite or missing values in 'x' 
## ERROR : infinite or missing values in 'x' 
## ERROR : infinite or missing values in 'x' 
## ERROR : infinite or missing values in 'x'
\end{verbatim}

\includegraphics{LateNightBayes_files/figure-latex/unnamed-chunk-13-1.pdf}

The DCB tracks the time of collapse well.

\hypertarget{weibull-asymptote}{%
\paragraph*{Weibull Asymptote}\label{weibull-asymptote}}
\addcontentsline{toc}{paragraph}{Weibull Asymptote}

The Weibull collapsing function starts at \(a=100\). It will converge to \(0.5a+a'\). We are adjusting \(a'\).
Dropping from \(a'>0\) to \(a'=0\) asymptotically brings us down to a bound of 50. \(a'<0\) drags the asymptote below 50.

\begin{itemize}
\tightlist
\item
  bias = \(0\)
\item
  drift = \(0.9\)
\item
  noise = \(4\)
\item
  Weibull scale = \(4\)
\item
  Weibull shape = \(3\)
\end{itemize}

\begin{verbatim}
## ERROR : infinite or missing values in 'x' 
## ERROR : infinite or missing values in 'x' 
## ERROR : infinite or missing values in 'x' 
## ERROR : infinite or missing values in 'x'
\end{verbatim}

\includegraphics{LateNightBayes_files/figure-latex/unnamed-chunk-14-1.pdf}

The DCB tracks the asymptote of collapse well.

\hypertarget{number-of-trials-1}{%
\paragraph*{Number of trials}\label{number-of-trials-1}}
\addcontentsline{toc}{paragraph}{Number of trials}

Keeping all else constant, how does the DCB perform with varying numbers of trials.

\begin{itemize}
\tightlist
\item
  bias = \(0\)
\item
  drift = \(0.9\)
\item
  noise = \(4\)
\item
  bound = \(\pm 50\)
\end{itemize}

\begin{verbatim}
## ERROR : infinite or missing values in 'x' 
## ERROR : infinite or missing values in 'x' 
## ERROR : infinite or missing values in 'x' 
## ERROR : infinite or missing values in 'x' 
## ERROR : infinite or missing values in 'x' 
## ERROR : infinite or missing values in 'x' 
## ERROR : infinite or missing values in 'x'
\end{verbatim}

\includegraphics{LateNightBayes_files/figure-latex/unnamed-chunk-15-1.pdf}

Performance seems sufficient at 150 trials, and improves (with diminishing returns) at larger trial counts.

\hypertarget{conclusion}{%
\subsection{Conclusion}\label{conclusion}}

Looks like DCB might work for tasks with sequential presentation and comparison of multiple stimuli, particularly in the perception and numerosity domains.

Need to make sure that the variance of noise is not too large amongst subjects, otherwise DCB will likely fail to track decision boundaries. This may be partially controlled by the noisiness of stimuli. For instance, displaying streams of numbers might result in less noise than displaying streams of collections of balls (where the collections represent a number).

DCB might work in as little as 150 trials per subject, though more trials only aids with accuracy. It's performance is more dependent on drift (since we need a decent distribution across all choices at a given time) and noise (since accumulated evidence can bleed over decision boundaries).

\hypertarget{perceptual-data-ddm}{%
\section{Perceptual data, DDM}\label{perceptual-data-ddm}}

We use data from a study currently in progress. I can't share this data yet since the project is still at an early phase. Subjects simultaneously view two streams of rectangles and are asked to choose which stream has the larger average as quickly as possible (see \citep{tsetsos2016}).

\hypertarget{prep-work}{%
\subsection{Prep work}\label{prep-work}}

\hypertarget{read-in-and-clean-data}{%
\subsubsection*{Read-in and clean data}\label{read-in-and-clean-data}}
\addcontentsline{toc}{subsubsection}{Read-in and clean data}

Reads in data and outputs a time-series of accumulated evidence and choices (along with slider location, etc.). Choices are 0=left, 1=right, 2=continue sampling.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{slider.data }\OtherTok{\textless{}{-}} 
  \FunctionTok{read.csv}\NormalTok{(}\StringTok{"data/dcb{-}all\_dataSlider.csv"}\NormalTok{)}
\NormalTok{slider.data }\OtherTok{\textless{}{-}} \FunctionTok{data.frame}\NormalTok{(}
  \AttributeTok{subject=}\FunctionTok{factor}\NormalTok{(slider.data}\SpecialCharTok{$}\NormalTok{participant),}
  \AttributeTok{trial=}\NormalTok{slider.data}\SpecialCharTok{$}\NormalTok{block.thisN}\SpecialCharTok{*}\DecValTok{120} \SpecialCharTok{+}\NormalTok{ slider.data}\SpecialCharTok{$}\NormalTok{trial.thisN,}
  \AttributeTok{sample=}\NormalTok{slider.data}\SpecialCharTok{$}\NormalTok{samplePhase.thisN,}
  \AttributeTok{choice=}\NormalTok{slider.data}\SpecialCharTok{$}\NormalTok{choice,}
  \AttributeTok{evidence=}\FunctionTok{round}\NormalTok{((slider.data}\SpecialCharTok{$}\NormalTok{heightR}\SpecialCharTok{{-}}\NormalTok{slider.data}\SpecialCharTok{$}\NormalTok{heightL)}\SpecialCharTok{*}\DecValTok{100}\NormalTok{,}\DecValTok{2}\NormalTok{),}
  \AttributeTok{sliderLoc=}\NormalTok{(slider.data}\SpecialCharTok{$}\NormalTok{sliderLoc}\SpecialCharTok{*}\DecValTok{2{-}1}\NormalTok{)}\SpecialCharTok{*}\DecValTok{100}\NormalTok{,}
  \AttributeTok{time=}\FunctionTok{round}\NormalTok{(slider.data}\SpecialCharTok{$}\NormalTok{sliderTime,}\DecValTok{3}\NormalTok{)}\SpecialCharTok{*}\DecValTok{1000}
\NormalTok{)}

\NormalTok{slider.data }\OtherTok{\textless{}{-}}\NormalTok{ slider.data }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{group\_by}\NormalTok{(subject,trial,sample) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{summarize}\NormalTok{(}
    \AttributeTok{choice=}\FunctionTok{last}\NormalTok{(choice),}
    \AttributeTok{evidence=}\FunctionTok{last}\NormalTok{(evidence),}
    \AttributeTok{sliderLoc=}\FunctionTok{last}\NormalTok{(sliderLoc),}
    \AttributeTok{time=}\FunctionTok{last}\NormalTok{(time)}
\NormalTok{  ) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{ungroup}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{group\_by}\NormalTok{(subject,trial) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}
    \AttributeTok{ae=}\FunctionTok{cumsum}\NormalTok{(evidence),}
    \AttributeTok{samples=}\FunctionTok{max}\NormalTok{(sample)}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## `summarise()` has grouped output by 'subject', 'trial'. You can override using
## the `.groups` argument.
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{slider.data}\SpecialCharTok{$}\NormalTok{choice[slider.data}\SpecialCharTok{$}\NormalTok{sample}\SpecialCharTok{!=}\NormalTok{slider.data}\SpecialCharTok{$}\NormalTok{samples] }\OtherTok{\textless{}{-}} \DecValTok{2}
\end{Highlighting}
\end{Shaded}

\hypertarget{take-subj-data-output-figure}{%
\subsubsection*{Take subj data, output figure}\label{take-subj-data-output-figure}}
\addcontentsline{toc}{subsubsection}{Take subj data, output figure}

Time dimension is along number of samples. Note that time-steps are not consistent since each pair of stimuli are displayed for a variable amount of time.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{plotDCB }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(data, }\AttributeTok{maxSamples=}\DecValTok{10}\NormalTok{) \{}
  \CommentTok{\# Get subject\textquotesingle{}s data and convert it to useable input to our DCB() function.}
  \CommentTok{\# Requires sample, choice, ae, and trial variables in time{-}series panel format.}
\NormalTok{  subj.data }\OtherTok{\textless{}{-}}\NormalTok{ data}
\NormalTok{  subj.data }\OtherTok{\textless{}{-}}\NormalTok{ subj.data[,}\FunctionTok{c}\NormalTok{(}\StringTok{\textquotesingle{}sample\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}choice\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}ae\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}trial\textquotesingle{}}\NormalTok{)]}
  
  \CommentTok{\# DCB}
\NormalTok{  subj.dcb }\OtherTok{\textless{}{-}} \FunctionTok{DCB}\NormalTok{(subj.data, maxSamples)}
\NormalTok{  subj.dcb}
  
\NormalTok{  tempData }\OtherTok{\textless{}{-}}\NormalTok{ subj.data}
\NormalTok{  tempData}\SpecialCharTok{$}\NormalTok{choice }\OtherTok{\textless{}{-}} \FunctionTok{factor}\NormalTok{(tempData}\SpecialCharTok{$}\NormalTok{choice, }\AttributeTok{levels=}\FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{), }\AttributeTok{labels=}\FunctionTok{c}\NormalTok{(}\StringTok{\textquotesingle{}Choose left\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}Choose right\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}Continue sampling\textquotesingle{}}\NormalTok{))}
\NormalTok{  tempData }\OtherTok{\textless{}{-}} \FunctionTok{merge}\NormalTok{(tempData,subj.dcb[,}\FunctionTok{c}\NormalTok{(}\StringTok{\textquotesingle{}sample\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}avgb\textquotesingle{}}\NormalTok{)], }\AttributeTok{by.x=}\StringTok{"sample"}\NormalTok{, }\AttributeTok{by.y=}\StringTok{"sample"}\NormalTok{)}
\NormalTok{  p }\OtherTok{\textless{}{-}}\NormalTok{ tempData[tempData}\SpecialCharTok{$}\NormalTok{sample}\SpecialCharTok{\textless{}=}\NormalTok{maxSamples,] }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x=}\NormalTok{ae, }\AttributeTok{fill=}\NormalTok{choice, }\AttributeTok{color=}\NormalTok{choice)) }\SpecialCharTok{+}
    \FunctionTok{geom\_histogram}\NormalTok{(}\AttributeTok{alpha=}\NormalTok{.}\DecValTok{25}\NormalTok{, }\AttributeTok{bins=}\DecValTok{100}\NormalTok{, }\AttributeTok{position=}\StringTok{\textquotesingle{}identity\textquotesingle{}}\NormalTok{) }\SpecialCharTok{+}
    \FunctionTok{geom\_vline}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{xintercept=}\NormalTok{avgb), }\AttributeTok{color=}\StringTok{\textquotesingle{}red\textquotesingle{}}\NormalTok{, }\AttributeTok{alpha=}\NormalTok{.}\DecValTok{65}\NormalTok{, }\AttributeTok{size=}\DecValTok{2}\NormalTok{) }\SpecialCharTok{+}
    \FunctionTok{geom\_vline}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{xintercept=}\SpecialCharTok{{-}}\NormalTok{avgb), }\AttributeTok{color=}\StringTok{\textquotesingle{}red\textquotesingle{}}\NormalTok{, }\AttributeTok{alpha=}\NormalTok{.}\DecValTok{65}\NormalTok{, }\AttributeTok{size=}\DecValTok{2}\NormalTok{) }\SpecialCharTok{+}
    \FunctionTok{coord\_flip}\NormalTok{() }\SpecialCharTok{+}
    \FunctionTok{theme\_classic}\NormalTok{() }\SpecialCharTok{+}
    \FunctionTok{labs}\NormalTok{(}\AttributeTok{x=}\StringTok{\textquotesingle{}Accumulated Evidence\textquotesingle{}}\NormalTok{, }\AttributeTok{y=}\StringTok{\textquotesingle{}Sample\textquotesingle{}}\NormalTok{) }\SpecialCharTok{+}
    \FunctionTok{xlim}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\SpecialCharTok{{-}}\DecValTok{150}\NormalTok{,}\DecValTok{150}\NormalTok{)) }\SpecialCharTok{+}
    \FunctionTok{theme}\NormalTok{(}
      \AttributeTok{plot.title =} \FunctionTok{element\_text}\NormalTok{(}\AttributeTok{size=}\DecValTok{22}\NormalTok{),}
      \AttributeTok{axis.ticks.x =} \FunctionTok{element\_blank}\NormalTok{(),}
      \AttributeTok{axis.text.x =} \FunctionTok{element\_blank}\NormalTok{()}
\NormalTok{    ) }\SpecialCharTok{+}
    \FunctionTok{facet\_grid}\NormalTok{(}\SpecialCharTok{\textasciitilde{}}\NormalTok{sample, }\AttributeTok{scales=}\StringTok{"free"}\NormalTok{)}
  \FunctionTok{return}\NormalTok{(p)}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\hypertarget{dcb-2}{%
\subsection{DCB}\label{dcb-2}}

\hypertarget{subject-1}{%
\subsubsection*{Subject 1}\label{subject-1}}
\addcontentsline{toc}{subsubsection}{Subject 1}

\begin{verbatim}
## ERROR : infinite or missing values in 'x'
\end{verbatim}

\includegraphics{LateNightBayes_files/figure-latex/unnamed-chunk-18-1.pdf}

Not great\ldots{} maybe this was just a fluke. If we consider the timepoints with the bulk of observations, then maybe we could argue evidence in favor of fixed bounds.

\hypertarget{subject-2}{%
\subsubsection*{Subject 2}\label{subject-2}}
\addcontentsline{toc}{subsubsection}{Subject 2}

\begin{verbatim}
## ERROR : missing value where TRUE/FALSE needed 
## ERROR : non-conformable arrays 
## ERROR : non-conformable arrays 
## ERROR : non-conformable arrays
\end{verbatim}

\includegraphics{LateNightBayes_files/figure-latex/unnamed-chunk-19-1.pdf}

If we only consider points in time with a sufficient amount of data, then definitely looks like collapsing bounds.

\hypertarget{subject-3}{%
\subsubsection*{Subject 3}\label{subject-3}}
\addcontentsline{toc}{subsubsection}{Subject 3}

\includegraphics{LateNightBayes_files/figure-latex/unnamed-chunk-20-1.pdf}

Not sure what to make of this.

\hypertarget{subject-4}{%
\subsubsection*{Subject 4}\label{subject-4}}
\addcontentsline{toc}{subsubsection}{Subject 4}

\begin{verbatim}
## ERROR : variable 1 appears to be constant within groups 
## ERROR : missing value where TRUE/FALSE needed 
## ERROR : missing value where TRUE/FALSE needed
\end{verbatim}

\includegraphics{LateNightBayes_files/figure-latex/unnamed-chunk-21-1.pdf}

If we only consider points in time with a sufficient amount of data, then looks like collapsing bounds.

\hypertarget{conclusion-1}{%
\subsection*{Conclusion}\label{conclusion-1}}
\addcontentsline{toc}{subsection}{Conclusion}

For 2 out of 4 subjects, the DCB clearly provides evidence in favor of a collapsing boundary. For the remaining subjects, the DCB looks scattered. I'm beginning to question the robustness of the DCB algorithm, though it clearly does well when modeling impatient subjects!

\hypertarget{perceptual-data-slider}{%
\section{Perceptual data, slider}\label{perceptual-data-slider}}

Instead of calculating accumulated evidence using a linear accumulator, I substitute it with slider bar location. Just curious if this works.

\hypertarget{prep-work-1}{%
\subsection{Prep work}\label{prep-work-1}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{slider.data}\SpecialCharTok{$}\NormalTok{ae }\OtherTok{\textless{}{-}}\NormalTok{ slider.data}\SpecialCharTok{$}\NormalTok{sliderLoc}
\end{Highlighting}
\end{Shaded}

\hypertarget{dcb-3}{%
\subsection{DCB}\label{dcb-3}}

\hypertarget{subject-1-1}{%
\subsubsection*{Subject 1}\label{subject-1-1}}
\addcontentsline{toc}{subsubsection}{Subject 1}

\begin{verbatim}
## ERROR : infinite or missing values in 'x'
\end{verbatim}

\includegraphics{LateNightBayes_files/figure-latex/unnamed-chunk-23-1.pdf}

More linear boundaries, but that's because the maximum / minimum slider bar location is 0 / 100, so this approach is naturally biased towards a linear boundary.

\hypertarget{subject-2-1}{%
\subsubsection*{Subject 2}\label{subject-2-1}}
\addcontentsline{toc}{subsubsection}{Subject 2}

\begin{verbatim}
## ERROR : variable 1 appears to be constant within groups 
## ERROR : missing value where TRUE/FALSE needed 
## ERROR : non-conformable arrays 
## ERROR : non-conformable arrays 
## ERROR : non-conformable arrays
\end{verbatim}

\includegraphics{LateNightBayes_files/figure-latex/unnamed-chunk-24-1.pdf}

Subtle hints of collapsing barrier, again biased towards a linear boundary.

\hypertarget{subject-3-1}{%
\subsubsection*{Subject 3}\label{subject-3-1}}
\addcontentsline{toc}{subsubsection}{Subject 3}

\includegraphics{LateNightBayes_files/figure-latex/unnamed-chunk-25-1.pdf}

Kinda looks like when noise is very large and bounds are collapsing\ldots{} that trend where the boundary collapses, widens, then collapses again.

\hypertarget{subject-4-1}{%
\subsubsection*{Subject 4}\label{subject-4-1}}
\addcontentsline{toc}{subsubsection}{Subject 4}

\begin{verbatim}
## ERROR : variable 1 appears to be constant within groups 
## ERROR : missing value where TRUE/FALSE needed 
## ERROR : missing value where TRUE/FALSE needed
\end{verbatim}

\includegraphics{LateNightBayes_files/figure-latex/unnamed-chunk-26-1.pdf}

Subtle hints of collapsing barrier.

\hypertarget{conclusion-2}{%
\subsection*{Conclusion}\label{conclusion-2}}
\addcontentsline{toc}{subsection}{Conclusion}

The fact that the ``accumulated evidence'' for choices cannot differ from \(\pm 100\) biases the collapsing boundary towards linear bounds. There is still some hint of collapse for the subjects who previously displayed collapsing boundaries, but I'm not sure we can call this a success. That's ok, I took a shot in the dark asking if the algorithm could work with just slider bar locations, and it turns out that it probably doesn't.

\hypertarget{value-based-data-ddm}{%
\section{Value-based data, DDM}\label{value-based-data-ddm}}

I use data from \citep{eum2022} visible trials. The data can be downloaded here: \url{https://www.rnl.caltech.edu/publications/index.html}. I am not assuming a drift diffusion model for accumulated evidence. I am simply assuming a linear accumulator (drift=1). If the DCB exhibit a bias that is linear in samples, then perhaps performance can be improved by using subject-specific drift rate parameters. However, if the DCB exhibit non-linear bias, then I find it hard to believe that drift rate will make much difference.

\hypertarget{prep-work-2}{%
\subsection{Prep work}\label{prep-work-2}}

\hypertarget{read-data}{%
\subsubsection*{Read data}\label{read-data}}
\addcontentsline{toc}{subsubsection}{Read data}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{load}\NormalTok{(}\StringTok{"data/dcb{-}choices.R"}\NormalTok{)}
\NormalTok{ddm.data }\OtherTok{\textless{}{-}} \FunctionTok{data.frame}\NormalTok{(}
  \AttributeTok{subject=}\NormalTok{choices}\SpecialCharTok{$}\NormalTok{parcode,}
  \AttributeTok{hidden=}\NormalTok{choices}\SpecialCharTok{$}\NormalTok{hidden,}
  \AttributeTok{condition=}\NormalTok{choices}\SpecialCharTok{$}\NormalTok{lr\_diff,}
  \AttributeTok{response=}\NormalTok{choices}\SpecialCharTok{$}\NormalTok{choice,}
  \AttributeTok{RT=}\NormalTok{choices}\SpecialCharTok{$}\NormalTok{rt}\SpecialCharTok{/}\DecValTok{1000}
\NormalTok{)}
\NormalTok{ddm.data }\OtherTok{\textless{}{-}}\NormalTok{ ddm.data[ddm.data}\SpecialCharTok{$}\NormalTok{hidden}\SpecialCharTok{==}\DecValTok{0}\NormalTok{,] }\CommentTok{\#keep visible trials}
\end{Highlighting}
\end{Shaded}

\hypertarget{take-subj-data-output-figure-1}{%
\subsubsection*{Take subj data, output figure}\label{take-subj-data-output-figure-1}}
\addcontentsline{toc}{subsubsection}{Take subj data, output figure}

Let's assume one sample occurs every 250 ms. This splits the time dimension into roughly the same resolution as the simulations above.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{plotDCB }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(data, }\AttributeTok{maxSamples=}\DecValTok{10}\NormalTok{) \{}
  \CommentTok{\# Get subject\textquotesingle{}s data and convert it to useable input to our DCB() function.}
  \CommentTok{\# Requires sample, choice, ae, and trial variables in time{-}series panel format.}
\NormalTok{  subj.data }\OtherTok{\textless{}{-}}\NormalTok{ data}
\NormalTok{  subj.data}\SpecialCharTok{$}\NormalTok{samples }\OtherTok{\textless{}{-}}\NormalTok{ (}\FunctionTok{round}\NormalTok{(subj.data}\SpecialCharTok{$}\NormalTok{RT}\SpecialCharTok{/}\NormalTok{.}\DecValTok{25}\NormalTok{)}\SpecialCharTok{*}\NormalTok{.}\DecValTok{25}\NormalTok{) }\SpecialCharTok{/}\NormalTok{.}\DecValTok{25} \CommentTok{\#250m}
\NormalTok{  subj.data}\SpecialCharTok{$}\NormalTok{trial }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\DecValTok{1}\SpecialCharTok{:}\FunctionTok{length}\NormalTok{(subj.data}\SpecialCharTok{$}\NormalTok{RT))}
\NormalTok{  subj.data }\OtherTok{\textless{}{-}}\NormalTok{ subj.data[}\FunctionTok{rep}\NormalTok{(}\FunctionTok{seq}\NormalTok{(}\FunctionTok{nrow}\NormalTok{(subj.data)), subj.data}\SpecialCharTok{$}\NormalTok{samples),] }\CommentTok{\#repeat each row by number of samples}
\NormalTok{  subj.data }\OtherTok{\textless{}{-}}\NormalTok{ subj.data }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{group\_by}\NormalTok{(trial) }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{mutate}\NormalTok{(}\AttributeTok{ae=}\FunctionTok{cumsum}\NormalTok{(condition),}
           \AttributeTok{sample=}\FunctionTok{row\_number}\NormalTok{())}
\NormalTok{  subj.data}\SpecialCharTok{$}\NormalTok{choice }\OtherTok{\textless{}{-}}\NormalTok{ subj.data}\SpecialCharTok{$}\NormalTok{response}
\NormalTok{  subj.data[subj.data}\SpecialCharTok{$}\NormalTok{sample}\SpecialCharTok{!=}\NormalTok{subj.data}\SpecialCharTok{$}\NormalTok{samples,}\StringTok{\textquotesingle{}choice\textquotesingle{}}\NormalTok{] }\OtherTok{\textless{}{-}} \DecValTok{2}
\NormalTok{  subj.data }\OtherTok{\textless{}{-}}\NormalTok{ subj.data[,}\FunctionTok{c}\NormalTok{(}\StringTok{\textquotesingle{}sample\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}choice\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}ae\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}trial\textquotesingle{}}\NormalTok{)]}
  
  \CommentTok{\# DCB}
\NormalTok{  subj.dcb }\OtherTok{\textless{}{-}} \FunctionTok{DCB}\NormalTok{(subj.data, maxSamples)}
\NormalTok{  subj.dcb}
  
\NormalTok{  tempData }\OtherTok{\textless{}{-}}\NormalTok{ subj.data}
\NormalTok{  tempData}\SpecialCharTok{$}\NormalTok{choice }\OtherTok{\textless{}{-}} \FunctionTok{factor}\NormalTok{(tempData}\SpecialCharTok{$}\NormalTok{choice, }\AttributeTok{levels=}\FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{), }\AttributeTok{labels=}\FunctionTok{c}\NormalTok{(}\StringTok{\textquotesingle{}Choose right\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}Choose left\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}Continue sampling\textquotesingle{}}\NormalTok{))}
\NormalTok{  tempData }\OtherTok{\textless{}{-}} \FunctionTok{merge}\NormalTok{(tempData,subj.dcb[,}\FunctionTok{c}\NormalTok{(}\StringTok{\textquotesingle{}sample\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}avgb\textquotesingle{}}\NormalTok{)], }\AttributeTok{by.x=}\StringTok{"sample"}\NormalTok{, }\AttributeTok{by.y=}\StringTok{"sample"}\NormalTok{)}
\NormalTok{  p }\OtherTok{\textless{}{-}}\NormalTok{ tempData[tempData}\SpecialCharTok{$}\NormalTok{sample}\SpecialCharTok{\textless{}=}\NormalTok{maxSamples,] }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x=}\NormalTok{ae, }\AttributeTok{fill=}\NormalTok{choice, }\AttributeTok{color=}\NormalTok{choice)) }\SpecialCharTok{+}
    \FunctionTok{geom\_histogram}\NormalTok{(}\AttributeTok{alpha=}\NormalTok{.}\DecValTok{5}\NormalTok{, }\AttributeTok{bins=}\DecValTok{50}\NormalTok{, }\AttributeTok{position=}\StringTok{\textquotesingle{}identity\textquotesingle{}}\NormalTok{) }\SpecialCharTok{+}
    \FunctionTok{geom\_vline}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{xintercept=}\NormalTok{avgb), }\AttributeTok{color=}\StringTok{\textquotesingle{}red\textquotesingle{}}\NormalTok{, }\AttributeTok{alpha=}\NormalTok{.}\DecValTok{5}\NormalTok{, }\AttributeTok{size=}\DecValTok{2}\NormalTok{) }\SpecialCharTok{+}
    \FunctionTok{geom\_vline}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{xintercept=}\SpecialCharTok{{-}}\NormalTok{avgb), }\AttributeTok{color=}\StringTok{\textquotesingle{}red\textquotesingle{}}\NormalTok{, }\AttributeTok{alpha=}\NormalTok{.}\DecValTok{5}\NormalTok{, }\AttributeTok{size=}\DecValTok{2}\NormalTok{) }\SpecialCharTok{+}
    \FunctionTok{coord\_flip}\NormalTok{() }\SpecialCharTok{+}
    \FunctionTok{theme\_classic}\NormalTok{() }\SpecialCharTok{+}
    \FunctionTok{labs}\NormalTok{(}\AttributeTok{x=}\StringTok{\textquotesingle{}Accumulated Evidence\textquotesingle{}}\NormalTok{, }\AttributeTok{y=}\StringTok{\textquotesingle{}Sample (250 ms)\textquotesingle{}}\NormalTok{) }\SpecialCharTok{+}
    \FunctionTok{xlim}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\SpecialCharTok{{-}}\DecValTok{50}\NormalTok{,}\DecValTok{50}\NormalTok{)) }\SpecialCharTok{+}
    \FunctionTok{theme}\NormalTok{(}
      \AttributeTok{plot.title =} \FunctionTok{element\_text}\NormalTok{(}\AttributeTok{size=}\DecValTok{22}\NormalTok{),}
      \AttributeTok{axis.ticks.x =} \FunctionTok{element\_blank}\NormalTok{(),}
      \AttributeTok{axis.text.x =} \FunctionTok{element\_blank}\NormalTok{()}
\NormalTok{    ) }\SpecialCharTok{+}
    \FunctionTok{facet\_grid}\NormalTok{(}\SpecialCharTok{\textasciitilde{}}\NormalTok{sample, }\AttributeTok{scales=}\StringTok{"free"}\NormalTok{)}
  \FunctionTok{return}\NormalTok{(p)}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\hypertarget{dcb-4}{%
\subsection{DCB}\label{dcb-4}}

\hypertarget{subj-225}{%
\subsubsection*{Subj 225}\label{subj-225}}
\addcontentsline{toc}{subsubsection}{Subj 225}

\begin{verbatim}
## ERROR : infinite or missing values in 'x' 
## ERROR : infinite or missing values in 'x' 
## ERROR : infinite or missing values in 'x'
\end{verbatim}

\includegraphics{LateNightBayes_files/figure-latex/unnamed-chunk-29-1.pdf}

Perhaps collapsing boundary with large noise? This conclusion is based on the simulations of the collapsing cyborg with a large noise parameter.

\hypertarget{subj-304}{%
\subsubsection*{Subj 304}\label{subj-304}}
\addcontentsline{toc}{subsubsection}{Subj 304}

\begin{verbatim}
## ERROR : infinite or missing values in 'x' 
## ERROR : infinite or missing values in 'x'
\end{verbatim}

\includegraphics{LateNightBayes_files/figure-latex/unnamed-chunk-30-1.pdf}

Not sure what to make of this.

\hypertarget{subj-316}{%
\subsubsection*{Subj 316}\label{subj-316}}
\addcontentsline{toc}{subsubsection}{Subj 316}

\begin{verbatim}
## ERROR : infinite or missing values in 'x' 
## ERROR : infinite or missing values in 'x'
\end{verbatim}

\includegraphics{LateNightBayes_files/figure-latex/unnamed-chunk-31-1.pdf}

Looks a lot like the collapsing barrier cyborg with large noise.

\hypertarget{subj-319}{%
\subsubsection*{Subj 319}\label{subj-319}}
\addcontentsline{toc}{subsubsection}{Subj 319}

\begin{verbatim}
## ERROR : infinite or missing values in 'x' 
## ERROR : infinite or missing values in 'x'
\end{verbatim}

\includegraphics{LateNightBayes_files/figure-latex/unnamed-chunk-32-1.pdf}

Potentially an increasingly patient subject? More likely that the algorithm is struggling to fit properly.

\hypertarget{conclusion-3}{%
\subsection{Conclusion}\label{conclusion-3}}

DCB is not looking promising in the value-based choice domain. Of course, I don't know what subjects' actual collapsing bounds are, but my attempt at fitting the DCB either suggests there is too much noise in the process for DCB to be effective. Perhaps value signals are too noisy compared to perceptual or numerosity stimuli. Also, the rate of evidence accumulation in these cases is constant since they are staring at the same stimuli for the entirety of the decision making process. I don't think the DCB was intended to be used on stimuli like this, so it's like trying to use a fork to drink soup.

\hypertarget{value-based-data-addm}{%
\section{Value-based data, aDDM}\label{value-based-data-addm}}

Now, let's see what happens if we calculate accumulated evidence with the aDDM (without noise). I have a hunch that this might work better!

\hypertarget{prep-work-3}{%
\subsection{Prep work}\label{prep-work-3}}

\hypertarget{read-data-1}{%
\subsubsection*{Read data}\label{read-data-1}}
\addcontentsline{toc}{subsubsection}{Read data}

We want to take the choice-fixations data and transform it into an object that we can feed into plotDCB() below.

Ideally, the output should have:
* subject
* trial
* a time dimension
* accumulated evidence (at that point in time)
* choice

We also need subject-speccific aDDM estimates.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Choice{-}fixation data}
\FunctionTok{load}\NormalTok{(}\StringTok{"data/dcb{-}cf.R"}\NormalTok{)}
\NormalTok{ddm.data }\OtherTok{\textless{}{-}} \FunctionTok{data.frame}\NormalTok{(}
  \AttributeTok{subject=}\NormalTok{cf}\SpecialCharTok{$}\NormalTok{parcode,}
  \AttributeTok{trial=}\NormalTok{cf}\SpecialCharTok{$}\NormalTok{trial,}
  \AttributeTok{hidden=}\NormalTok{cf}\SpecialCharTok{$}\NormalTok{hidden,}
  \AttributeTok{vl=}\NormalTok{cf}\SpecialCharTok{$}\NormalTok{avgWTP\_left,}
  \AttributeTok{vr=}\NormalTok{cf}\SpecialCharTok{$}\NormalTok{avgWTP\_right,}
  \AttributeTok{loc=}\NormalTok{cf}\SpecialCharTok{$}\NormalTok{location,}
  \AttributeTok{dur=}\NormalTok{cf}\SpecialCharTok{$}\NormalTok{duration,}
  \AttributeTok{choice=}\NormalTok{cf}\SpecialCharTok{$}\NormalTok{choice,}
  \AttributeTok{rt=}\NormalTok{cf}\SpecialCharTok{$}\NormalTok{rt}\SpecialCharTok{/}\DecValTok{1000}
\NormalTok{)}
\NormalTok{ddm.data }\OtherTok{\textless{}{-}}\NormalTok{ ddm.data[ddm.data}\SpecialCharTok{$}\NormalTok{hidden}\SpecialCharTok{==}\DecValTok{0}\NormalTok{,] }\CommentTok{\#keep visible trials}

\CommentTok{\# Subject{-}level aDDM estimates}
\NormalTok{subs }\OtherTok{\textless{}{-}} \FunctionTok{unique}\NormalTok{(ddm.data}\SpecialCharTok{$}\NormalTok{subject)}
\NormalTok{selected.subs }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\DecValTok{225}\NormalTok{,}\DecValTok{304}\NormalTok{,}\DecValTok{316}\NormalTok{,}\DecValTok{319}\NormalTok{) }\CommentTok{\#Pick 4 subjects}
\NormalTok{selected.subs.ind }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\DecValTok{25}\NormalTok{,}\DecValTok{28}\NormalTok{,}\DecValTok{38}\NormalTok{,}\DecValTok{41}\NormalTok{) }\CommentTok{\#indexes}
\NormalTok{ddm.estim }\OtherTok{\textless{}{-}} \FunctionTok{read.csv}\NormalTok{(}\StringTok{"data/dcb{-}MAP\_estimates.csv"}\NormalTok{)}

\CommentTok{\# Transform data}
\NormalTok{ddm.data }\OtherTok{\textless{}{-}}\NormalTok{ ddm.data[}\FunctionTok{which}\NormalTok{(ddm.data}\SpecialCharTok{$}\NormalTok{subject }\SpecialCharTok{\%in\%}\NormalTok{ selected.subs),]}
\NormalTok{ddm.data}\SpecialCharTok{$}\NormalTok{evidence }\OtherTok{\textless{}{-}} \ConstantTok{NA}
\ControlFlowTok{for}\NormalTok{ (i }\ControlFlowTok{in} \FunctionTok{c}\NormalTok{(}\DecValTok{1}\SpecialCharTok{:}\FunctionTok{length}\NormalTok{(selected.subs))) \{}
  \CommentTok{\# looking nowhere}
\NormalTok{  ind }\OtherTok{\textless{}{-}}\NormalTok{ (ddm.data}\SpecialCharTok{$}\NormalTok{subject}\SpecialCharTok{==}\NormalTok{selected.subs[i] }\SpecialCharTok{\&}\NormalTok{ (ddm.data}\SpecialCharTok{$}\NormalTok{loc}\SpecialCharTok{==}\DecValTok{0} \SpecialCharTok{|}\NormalTok{ ddm.data}\SpecialCharTok{$}\NormalTok{loc}\SpecialCharTok{==}\DecValTok{4}\NormalTok{) )}
\NormalTok{  ddm.data[ind,}\StringTok{\textquotesingle{}evidence\textquotesingle{}}\NormalTok{] }\OtherTok{\textless{}{-}} \DecValTok{0}
  \CommentTok{\# looking right}
\NormalTok{  ind }\OtherTok{\textless{}{-}}\NormalTok{ (ddm.data}\SpecialCharTok{$}\NormalTok{subject}\SpecialCharTok{==}\NormalTok{selected.subs[i] }\SpecialCharTok{\&}\NormalTok{ ddm.data}\SpecialCharTok{$}\NormalTok{loc}\SpecialCharTok{==}\DecValTok{2}\NormalTok{)}
\NormalTok{  ddm.data[ind,}\StringTok{\textquotesingle{}evidence\textquotesingle{}}\NormalTok{] }\OtherTok{\textless{}{-}}\NormalTok{ ddm.estim}\SpecialCharTok{$}\NormalTok{d\_v[selected.subs.ind[i]] }\SpecialCharTok{*} 
\NormalTok{    (ddm.estim}\SpecialCharTok{$}\NormalTok{t\_v[selected.subs.ind[i]]}\SpecialCharTok{*}\NormalTok{ddm.data[ind,}\StringTok{\textquotesingle{}vl\textquotesingle{}}\NormalTok{] }\SpecialCharTok{{-}}\NormalTok{ ddm.data[ind,}\StringTok{\textquotesingle{}vr\textquotesingle{}}\NormalTok{])}
  \CommentTok{\# looking left}
\NormalTok{  ind }\OtherTok{\textless{}{-}}\NormalTok{ (ddm.data}\SpecialCharTok{$}\NormalTok{subject}\SpecialCharTok{==}\NormalTok{selected.subs[i] }\SpecialCharTok{\&}\NormalTok{ ddm.data}\SpecialCharTok{$}\NormalTok{loc}\SpecialCharTok{==}\DecValTok{1}\NormalTok{)}
\NormalTok{  ddm.data[ind,}\StringTok{\textquotesingle{}evidence\textquotesingle{}}\NormalTok{] }\OtherTok{\textless{}{-}}\NormalTok{ ddm.estim}\SpecialCharTok{$}\NormalTok{d\_v[selected.subs.ind[i]] }\SpecialCharTok{*} 
\NormalTok{    (ddm.data[ind,}\StringTok{\textquotesingle{}vl\textquotesingle{}}\NormalTok{] }\SpecialCharTok{{-}}\NormalTok{ ddm.estim}\SpecialCharTok{$}\NormalTok{t\_v[selected.subs.ind[i]]}\SpecialCharTok{*}\NormalTok{ddm.data[ind,}\StringTok{\textquotesingle{}vr\textquotesingle{}}\NormalTok{])}
\NormalTok{\}}
\NormalTok{ddm.data }\OtherTok{\textless{}{-}}\NormalTok{ ddm.data[}\FunctionTok{rep}\NormalTok{(}\FunctionTok{seq}\NormalTok{(}\FunctionTok{nrow}\NormalTok{(ddm.data)), ddm.data}\SpecialCharTok{$}\NormalTok{dur),] }\CommentTok{\#repeat each row by number of samples}
\NormalTok{ddm.data }\OtherTok{\textless{}{-}}\NormalTok{ ddm.data }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{group\_by}\NormalTok{(subject,trial) }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{mutate}\NormalTok{(}\AttributeTok{ae=}\FunctionTok{cumsum}\NormalTok{(evidence),}
           \AttributeTok{time=}\FunctionTok{row\_number}\NormalTok{())}
\end{Highlighting}
\end{Shaded}

\hypertarget{take-subj-data-output-figure-2}{%
\subsubsection*{Take subj data, output figure}\label{take-subj-data-output-figure-2}}
\addcontentsline{toc}{subsubsection}{Take subj data, output figure}

Let's assume one sample occurs every 250 ms. This splits the time dimension into roughly the same resolution as the simulations above.

This overwrites the previous function so that we can calculate accumulated evidence (ae) using the aDDM instead of a linear accumulator.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{plotDCB }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(data, }\AttributeTok{maxSamples=}\DecValTok{10}\NormalTok{) \{}
  \CommentTok{\# Get subject\textquotesingle{}s data and convert it to useable input to our DCB() function.}
  \CommentTok{\# Requires sample, choice, ae, and trial variables in time{-}series panel format.}
\NormalTok{  data}\SpecialCharTok{$}\NormalTok{time }\OtherTok{\textless{}{-}} \FunctionTok{ceiling}\NormalTok{(data}\SpecialCharTok{$}\NormalTok{time }\SpecialCharTok{/} \DecValTok{250}\NormalTok{) }\SpecialCharTok{*} \DecValTok{250} \CommentTok{\#round up times to the nearest 250 above.}
\NormalTok{  subj.data }\OtherTok{\textless{}{-}}\NormalTok{ data }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{group\_by}\NormalTok{(subject,trial,time) }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{summarize}\NormalTok{(}
      \AttributeTok{sample=}\FunctionTok{last}\NormalTok{(time)}\SpecialCharTok{/}\DecValTok{250}\NormalTok{,}
      \AttributeTok{choice=}\FunctionTok{last}\NormalTok{(choice),}
      \AttributeTok{ae=}\FunctionTok{last}\NormalTok{(ae)}
\NormalTok{    ) }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{ungroup}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{group\_by}\NormalTok{(subject,trial) }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{mutate}\NormalTok{(}
      \AttributeTok{samples=}\FunctionTok{max}\NormalTok{(sample)}
\NormalTok{    )}
\NormalTok{  subj.data[subj.data}\SpecialCharTok{$}\NormalTok{sample}\SpecialCharTok{!=}\NormalTok{subj.data}\SpecialCharTok{$}\NormalTok{samples,}\StringTok{\textquotesingle{}choice\textquotesingle{}}\NormalTok{] }\OtherTok{\textless{}{-}} \DecValTok{2}
  
  \CommentTok{\# DCB}
\NormalTok{  subj.dcb }\OtherTok{\textless{}{-}} \FunctionTok{DCB}\NormalTok{(subj.data, maxSamples)}
\NormalTok{  subj.dcb}
  
\NormalTok{  tempData }\OtherTok{\textless{}{-}}\NormalTok{ subj.data}
\NormalTok{  tempData}\SpecialCharTok{$}\NormalTok{choice }\OtherTok{\textless{}{-}} \FunctionTok{factor}\NormalTok{(tempData}\SpecialCharTok{$}\NormalTok{choice, }\AttributeTok{levels=}\FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{), }\AttributeTok{labels=}\FunctionTok{c}\NormalTok{(}\StringTok{\textquotesingle{}Choose right\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}Choose left\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}Continue sampling\textquotesingle{}}\NormalTok{))}
\NormalTok{  tempData }\OtherTok{\textless{}{-}} \FunctionTok{merge}\NormalTok{(tempData,subj.dcb[,}\FunctionTok{c}\NormalTok{(}\StringTok{\textquotesingle{}sample\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}avgb\textquotesingle{}}\NormalTok{)], }\AttributeTok{by.x=}\StringTok{"sample"}\NormalTok{, }\AttributeTok{by.y=}\StringTok{"sample"}\NormalTok{)}
\NormalTok{  p }\OtherTok{\textless{}{-}}\NormalTok{ tempData[tempData}\SpecialCharTok{$}\NormalTok{sample}\SpecialCharTok{\textless{}=}\NormalTok{maxSamples,] }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x=}\NormalTok{ae, }\AttributeTok{fill=}\NormalTok{choice, }\AttributeTok{color=}\NormalTok{choice)) }\SpecialCharTok{+}
    \FunctionTok{geom\_histogram}\NormalTok{(}\AttributeTok{alpha=}\NormalTok{.}\DecValTok{5}\NormalTok{, }\AttributeTok{bins=}\DecValTok{25}\NormalTok{, }\AttributeTok{position=}\StringTok{\textquotesingle{}identity\textquotesingle{}}\NormalTok{) }\SpecialCharTok{+}
    \FunctionTok{geom\_vline}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{xintercept=}\NormalTok{avgb), }\AttributeTok{color=}\StringTok{\textquotesingle{}red\textquotesingle{}}\NormalTok{, }\AttributeTok{alpha=}\NormalTok{.}\DecValTok{5}\NormalTok{, }\AttributeTok{size=}\DecValTok{2}\NormalTok{) }\SpecialCharTok{+}
    \FunctionTok{geom\_vline}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{xintercept=}\SpecialCharTok{{-}}\NormalTok{avgb), }\AttributeTok{color=}\StringTok{\textquotesingle{}red\textquotesingle{}}\NormalTok{, }\AttributeTok{alpha=}\NormalTok{.}\DecValTok{5}\NormalTok{, }\AttributeTok{size=}\DecValTok{2}\NormalTok{) }\SpecialCharTok{+}
    \FunctionTok{coord\_flip}\NormalTok{() }\SpecialCharTok{+}
    \FunctionTok{theme\_classic}\NormalTok{() }\SpecialCharTok{+}
    \FunctionTok{labs}\NormalTok{(}\AttributeTok{x=}\StringTok{\textquotesingle{}Accumulated Evidence\textquotesingle{}}\NormalTok{, }\AttributeTok{y=}\StringTok{\textquotesingle{}Sample (250 ms)\textquotesingle{}}\NormalTok{) }\SpecialCharTok{+}
    \FunctionTok{xlim}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\SpecialCharTok{{-}}\DecValTok{25}\NormalTok{,}\DecValTok{25}\NormalTok{)) }\SpecialCharTok{+}
    \FunctionTok{theme}\NormalTok{(}
      \AttributeTok{plot.title =} \FunctionTok{element\_text}\NormalTok{(}\AttributeTok{size=}\DecValTok{22}\NormalTok{),}
      \AttributeTok{axis.ticks.x =} \FunctionTok{element\_blank}\NormalTok{(),}
      \AttributeTok{axis.text.x =} \FunctionTok{element\_blank}\NormalTok{()}
\NormalTok{    ) }\SpecialCharTok{+}
    \FunctionTok{facet\_grid}\NormalTok{(}\SpecialCharTok{\textasciitilde{}}\NormalTok{sample, }\AttributeTok{scales=}\StringTok{"free"}\NormalTok{)}
  \FunctionTok{return}\NormalTok{(p)}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\hypertarget{dcb-5}{%
\subsection{DCB}\label{dcb-5}}

\hypertarget{subj-225-1}{%
\subsubsection*{Subj 225}\label{subj-225-1}}
\addcontentsline{toc}{subsubsection}{Subj 225}

\begin{verbatim}
## ERROR : infinite or missing values in 'x' 
## ERROR : infinite or missing values in 'x' 
## ERROR : infinite or missing values in 'x' 
## ERROR : infinite or missing values in 'x'
\end{verbatim}

\includegraphics{LateNightBayes_files/figure-latex/unnamed-chunk-35-1.pdf}

Confusion\ldots{}

\hypertarget{subj-304-1}{%
\subsubsection*{Subj 304}\label{subj-304-1}}
\addcontentsline{toc}{subsubsection}{Subj 304}

\begin{verbatim}
## ERROR : infinite or missing values in 'x' 
## ERROR : infinite or missing values in 'x'
\end{verbatim}

\includegraphics{LateNightBayes_files/figure-latex/unnamed-chunk-36-1.pdf}

Looks like collapsing bounds with large noise?

\hypertarget{subj-316-1}{%
\subsubsection*{Subj 316}\label{subj-316-1}}
\addcontentsline{toc}{subsubsection}{Subj 316}

\begin{verbatim}
## ERROR : infinite or missing values in 'x' 
## ERROR : infinite or missing values in 'x' 
## ERROR : infinite or missing values in 'x'
\end{verbatim}

\includegraphics{LateNightBayes_files/figure-latex/unnamed-chunk-37-1.pdf}

Again, looks like collapsing bounds with large noise???

\hypertarget{subj-319-1}{%
\subsubsection*{Subj 319}\label{subj-319-1}}
\addcontentsline{toc}{subsubsection}{Subj 319}

\begin{verbatim}
## ERROR : infinite or missing values in 'x' 
## ERROR : infinite or missing values in 'x'
\end{verbatim}

\includegraphics{LateNightBayes_files/figure-latex/unnamed-chunk-38-1.pdf}

More confusion\ldots{}

\hypertarget{conclusion-4}{%
\subsection{Conclusion}\label{conclusion-4}}

I'm not sure the DCB's make any sense here, but if we were to interpret them, then subjects mostly seem like they have collapsing bounds with large noise. This might make sense if we believe that value signals are noisier than perceptual or numerosity stimuli, but that also makes DCB a poor candidate algorithm for fitting decision bounds to value-based behavioral data.

\hypertarget{discussion}{%
\section{Discussion}\label{discussion}}

Overall, the DCB seems to show some promise with perceptual data, but not with value-based data. This is by no fault of the DCB, I was just curious if it would work in the value-based domain (like a baby trying to drink soup with a fork).

For perceptual data, I think it works particularly well on subjects who are very impatient (both of the collapsing bound subjects in the perceptual data mentioned that they were getting very impatient with the task). Aside from those subjects, it seems to estimate boundaries that appear very volatile over time. I'm not really sure what to make of those results, and the extreme volatility does not leave much room for interpretation.

Personally, I think that although the DCB could be estimating decision boundaries more accurately, we lose the interpretability that comes with using a functional form for collapsing bounds. At the end of the day, isn't that the purpose of a simplified model of decision making?

Furthermore, if subjects aren't arriving at all possible choices early on in the trial, the DCB fails to estimate boundaries. This prevents us from estimating the starting point of the decision boundaries.

\hypertarget{mem-aDDM}{%
\chapter{mem-aDDM}\label{mem-aDDM}}

(TL;DR) I tried to incorporate the effects of working memory (mem-) into the Attentional Drift-Diffusion-Model (aDDM) by allowing the drift rate parameter to scale with the number of previous exposures to the chosen stimulus in the session. This was an attempt to (1) improve the accuracy of response time predictions from the aDDM and (2) model shorter response times with repeated exposures. It didn't work, but at least now I know what not to try next ¯\textbackslash{}\emph{(ツ)}/¯.

\includegraphics[width=0.6\textwidth,height=\textheight]{images/mem-aDDM-rt-results.PNG}

\hypertarget{introduction}{%
\section{Introduction}\label{introduction}}

In value-based decisions, there are different ways that familiarity with a stimulus might affect decisions over time. Adopting intuition from Signal Detection Theory, repeated exposure to a stimulus might reduce the variance of the value signal. When it comes to sequential sampling models, we can model this in two ways. The obvious approach would be to reduce the noise parameter as a function of stimulus exposure time. However, previous studies have shown that response times decrease with repeated exposure to a stimulus in an experiment (a wonderful report written by Trinity Pruitt when she was rotating through the Rangel Lab in 2021, or \citep{agranov2017}). A reduced noise parameter can only serve to increase response times, therefore this adjustment to the model would likely fail to account for behavior. Similarly, I believe the extension of the DDM used in \citep{agranov2017} fails to account for the effects of repeated exposure on parameters of the DDM.

\includegraphics[width=0.3\textwidth,height=\textheight]{images/mem-aDDM-fasterRTs.PNG}
Source: Trinity Pruitt. Faster RTs for stimuli seen more than the median number of times a stimulus is seen in \citep{smith2018} and in \citep{eum2022}.\\

Instead, I hypothesize that familiarity with a stimulus will affect the drift rate parameter. For one, a drift rate parameter that scales with previous encounters is capable of explaining faster response times with repeated exposure. \citep{kelly2013} find that faster response times correlate with faster buildup rate of centroparietal positive potential independent of stimulus coherence, suggesting that faster response times might be explained by a larger drift rate parameter. But the main inspiration behind an encounter-scaling drift rate parameter comes from the memory and decision-making literature. \citep{shadlen2016} argue that value signals are modulated by memory (episodic, working, etc.), specifically that value signals in sequential sampling models integrated in the LIP are modulated by activity in the hippocampus. Studies using EEG also find a neural signal that reflects sampling from memory \citep{vanede2022}. If we buy the argument that sampling from memory is more difficult than sampling from a visual representation (\citep{weilbacher2021} and \citep{eum2022}), then we might suspect that recent exposure to a stimulus will reduce the difficulty of sampling information from working memory. Again, this could potentially result in a smaller noise parameter, but seeing that this fails to explain behavior, I believe it is instead explained by drift rate parameter that scales with previous encounters.

I also think this will make different RT predictions depending on the value difference. Since value differences integrate over time, the lack of evidence in a difficult decision compounds over time. This means that a larger drift rate parameter will reduce response times by more in difficult choices than in easy choices. This may remedy problems that the aDDM has with fitting RT distributions across value differences (see below).

\includegraphics[width=0.3\textwidth,height=\textheight]{images/mem-aDDM-aDDM_rt_pred.PNG}

The goals of this report:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Incorporate the idea that internal samples are modulated by (and sometimes even sampled from) memory into a sequential sampling model.
\item
  Build a variation of the aDDM that explains shorter response times with more familiar stimuli.
\item
  Improve the performance of the aDDM, which has previously overestimated response times when choices are difficult.
\end{enumerate}

\hypertarget{warning}{%
\section{Warning}\label{warning}}

Not a great display of coding. But with one weekend for a side-project, this is what I wound up with. If the project turns into something bigger, then I'll consider re-writing the code into something more elegant.

\hypertarget{methods}{%
\section{Methods}\label{methods}}

\hypertarget{prep-work-4}{%
\subsection{Prep work}\label{prep-work-4}}

\hypertarget{load-libraries}{%
\subsubsection{Load libraries}\label{load-libraries}}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{rm}\NormalTok{(}\AttributeTok{list =} \FunctionTok{ls}\NormalTok{())}
\NormalTok{seed }\OtherTok{=} \DecValTok{1337}
\FunctionTok{library}\NormalTok{(dplyr)}
\FunctionTok{library}\NormalTok{(ggplot2)}
\FunctionTok{library}\NormalTok{(hrbrthemes)}
\FunctionTok{library}\NormalTok{(runjags)}
\FunctionTok{library}\NormalTok{(brms)}
\CommentTok{\#library(cmdstanr)}
\FunctionTok{library}\NormalTok{(data.table)}
\FunctionTok{library}\NormalTok{(plotrix)}
\FunctionTok{library}\NormalTok{(grid)}
\FunctionTok{library}\NormalTok{(gridExtra)}
\CommentTok{\#set\_cmdstan\_path("D:/Program Files/R{-}4.0.2/library/cmdstan{-}2.24.1") \#gotta do this everytime :\textbackslash{}}
\end{Highlighting}
\end{Shaded}

\hypertarget{read-in-data-and-calculations}{%
\subsubsection{Read-in data and calculations}\label{read-in-data-and-calculations}}

I will use data from the ``two food'' choice task in \citep{smith2018}. The data can be downloaded here: \url{https://osf.io/x2jhp/?view_only=2669d8f3983d4442952a52c5de5814f7}. I calculate a variable called ``PreviousEncountersChosen'', which counts the number of previous trials in which the subject has seen the chosen item for this trial.

I was thinking about extending the model so that we calculate ``PreviousExposure'' up until the current fixation, but this would require that we use a different (and MUCH slower) toolbox to estimate the aDDM. If we fit the data by fixations, then we need should use the Tavares toolbox \citep{tavares2017}. But, that will take a long time and will not result in posterior distributions for parameter estimates. So instead, I will use the Lombardi and Hare toolbox \citep{lombardi2021} and let drift rate vary trial-by-trial systematically as a function of previous encounters. This differs from the trial-by-trial variability in drift rate that draws drift from a distribution, as in \citep{lombardi2021} or \citep{eum2022}.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{load}\NormalTok{(}\StringTok{"data/mem{-}aDDM{-}smithkrajbich2018.RData"}\NormalTok{)}

\NormalTok{twofoodeyedata }\OtherTok{\textless{}{-}}\NormalTok{ twofoodeyedata }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{group\_by}\NormalTok{(SubjectNumber, Trial) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{( }\CommentTok{\# fixation number}
    \AttributeTok{fixNum=}\FunctionTok{row\_number}\NormalTok{()}
\NormalTok{  ) }

\CommentTok{\# Running counts of the number of times the subjects have seen the left and right options across previous trials}
\NormalTok{twofoodchoicedata}\SpecialCharTok{$}\NormalTok{PreviousEncounterLeft }\OtherTok{\textless{}{-}} \ConstantTok{NA}
\NormalTok{twofoodchoicedata}\SpecialCharTok{$}\NormalTok{PreviousEncounterRight }\OtherTok{\textless{}{-}} \ConstantTok{NA}
\NormalTok{data }\OtherTok{\textless{}{-}}\NormalTok{ twofoodchoicedata[}\FunctionTok{order}\NormalTok{(twofoodchoicedata}\SpecialCharTok{$}\NormalTok{SubjectNumber, twofoodchoicedata}\SpecialCharTok{$}\NormalTok{Trial),]}
\ControlFlowTok{for}\NormalTok{ (n }\ControlFlowTok{in} \DecValTok{1}\SpecialCharTok{:}\FunctionTok{length}\NormalTok{(data}\SpecialCharTok{$}\NormalTok{SubjectNumber)) \{}
\NormalTok{  tempdata }\OtherTok{\textless{}{-}}\NormalTok{ data[data}\SpecialCharTok{$}\NormalTok{SubjectNumber}\SpecialCharTok{==}\NormalTok{data}\SpecialCharTok{$}\NormalTok{SubjectNumber[n] }\SpecialCharTok{\&}\NormalTok{ data}\SpecialCharTok{$}\NormalTok{Trial}\SpecialCharTok{\textless{}=}\NormalTok{data}\SpecialCharTok{$}\NormalTok{Trial[n],]}
\NormalTok{  prevList }\OtherTok{\textless{}{-}} \FunctionTok{rbind}\NormalTok{(tempdata}\SpecialCharTok{$}\NormalTok{FoodLeft,tempdata}\SpecialCharTok{$}\NormalTok{FoodRight)}
\NormalTok{  data}\SpecialCharTok{$}\NormalTok{PreviousEncounterLeft[n] }\OtherTok{\textless{}{-}} \FunctionTok{sum}\NormalTok{(prevList}\SpecialCharTok{==}\NormalTok{data}\SpecialCharTok{$}\NormalTok{FoodLeft[n])}\SpecialCharTok{{-}}\DecValTok{1}
\NormalTok{  data}\SpecialCharTok{$}\NormalTok{PreviousEncounterRight[n] }\OtherTok{\textless{}{-}} \FunctionTok{sum}\NormalTok{(prevList}\SpecialCharTok{==}\NormalTok{data}\SpecialCharTok{$}\NormalTok{FoodRight[n])}\SpecialCharTok{{-}}\DecValTok{1}
\NormalTok{\}}
\NormalTok{twofoodchoicedata }\OtherTok{\textless{}{-}}\NormalTok{ data}
\NormalTok{twofoodchoicedata}\SpecialCharTok{$}\NormalTok{PreviousEncounterBoth }\OtherTok{\textless{}{-}}\NormalTok{ twofoodchoicedata}\SpecialCharTok{$}\NormalTok{PreviousEncounterLeft}\SpecialCharTok{+}\NormalTok{twofoodchoicedata}\SpecialCharTok{$}\NormalTok{PreviousEncounterRight}
\NormalTok{twofoodchoicedata}\SpecialCharTok{$}\NormalTok{PreviousEncounterChosen }\OtherTok{\textless{}{-}} 
  \FunctionTok{ifelse}\NormalTok{(twofoodchoicedata}\SpecialCharTok{$}\NormalTok{LeftRight}\SpecialCharTok{==}\DecValTok{1}\NormalTok{, twofoodchoicedata}\SpecialCharTok{$}\NormalTok{PreviousEncounterLeft, twofoodchoicedata}\SpecialCharTok{$}\NormalTok{PreviousEncounterRight)}

\NormalTok{food }\OtherTok{\textless{}{-}} \FunctionTok{merge}\NormalTok{(twofoodchoicedata, twofoodeyedata, }\AttributeTok{by=}\FunctionTok{c}\NormalTok{(}\StringTok{"SubjectNumber"}\NormalTok{, }\StringTok{"Trial"}\NormalTok{))}
\NormalTok{food }\OtherTok{\textless{}{-}}\NormalTok{ food[}\FunctionTok{order}\NormalTok{(food}\SpecialCharTok{$}\NormalTok{SubjectNumber, food}\SpecialCharTok{$}\NormalTok{Trial, food}\SpecialCharTok{$}\NormalTok{fixNum),]}
\NormalTok{food}\SpecialCharTok{$}\NormalTok{valDiff }\OtherTok{\textless{}{-}}\NormalTok{ food}\SpecialCharTok{$}\NormalTok{ValueLeft}\SpecialCharTok{{-}}\NormalTok{food}\SpecialCharTok{$}\NormalTok{ValueRight}
\NormalTok{food}\SpecialCharTok{$}\NormalTok{difficulty }\OtherTok{\textless{}{-}} \FunctionTok{abs}\NormalTok{(food}\SpecialCharTok{$}\NormalTok{ValueLeft}\SpecialCharTok{{-}}\NormalTok{food}\SpecialCharTok{$}\NormalTok{ValueRight)}
\NormalTok{food}\SpecialCharTok{$}\NormalTok{fixID }\OtherTok{\textless{}{-}} \FunctionTok{ifelse}\NormalTok{(food}\SpecialCharTok{$}\NormalTok{ROI}\SpecialCharTok{==}\DecValTok{1}\NormalTok{, food}\SpecialCharTok{$}\NormalTok{FoodLeft, food}\SpecialCharTok{$}\NormalTok{FoodRight) }\CommentTok{\# ID for currently fixated food}
\NormalTok{food}\SpecialCharTok{$}\NormalTok{choiceID }\OtherTok{\textless{}{-}} \FunctionTok{ifelse}\NormalTok{(food}\SpecialCharTok{$}\NormalTok{LeftRight}\SpecialCharTok{==}\DecValTok{1}\NormalTok{, food}\SpecialCharTok{$}\NormalTok{FoodLeft, food}\SpecialCharTok{$}\NormalTok{FoodRight) }\CommentTok{\# ID for chosen food}

\NormalTok{food }\OtherTok{\textless{}{-}}\NormalTok{ food }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{group\_by}\NormalTok{(SubjectNumber, fixID) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{( }\CommentTok{\# Get total dwell time up until this fixation}
    \AttributeTok{Exposure =} \FunctionTok{cumsum}\NormalTok{(DwellLength)}\SpecialCharTok{{-}}\NormalTok{DwellLength }
\NormalTok{  ) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{ungroup}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{group\_by}\NormalTok{(SubjectNumber, Trial, fixID) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{( }\CommentTok{\# Get total dwell time up until this trial for each unique stimulus}
    \AttributeTok{TrialPreviousExposure =} \FunctionTok{min}\NormalTok{(Exposure) }
\NormalTok{  ) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{ungroup}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{group\_by}\NormalTok{(SubjectNumber, Trial) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{( }\CommentTok{\# Get total dwell time for both stimuli up until this trial}
    \AttributeTok{PreviousExposureBoth =} \FunctionTok{sum}\NormalTok{(}\FunctionTok{unique}\NormalTok{(TrialPreviousExposure),}\AttributeTok{na.rm=}\ConstantTok{TRUE}\NormalTok{)}
\NormalTok{  ) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{ungroup}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}
    \AttributeTok{fixToChoice =}\NormalTok{ (fixID}\SpecialCharTok{==}\NormalTok{choiceID),}
    \AttributeTok{placeholder =} \DecValTok{0}
\NormalTok{  )}

\NormalTok{food}\SpecialCharTok{$}\NormalTok{placeholder }\OtherTok{\textless{}{-}} \FunctionTok{ifelse}\NormalTok{(food}\SpecialCharTok{$}\NormalTok{fixToChoice}\SpecialCharTok{==}\DecValTok{1}\NormalTok{, food}\SpecialCharTok{$}\NormalTok{TrialPreviousExposure, }\DecValTok{0}\NormalTok{)}
\NormalTok{food }\OtherTok{\textless{}{-}}\NormalTok{ food }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{group\_by}\NormalTok{(SubjectNumber, Trial) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{( }
    \AttributeTok{PreviousExposureChosen =} \FunctionTok{max}\NormalTok{(placeholder), }\CommentTok{\# Get total dwell time for chosen stimulus up until this trial}
    \AttributeTok{maxFixNum =} \FunctionTok{max}\NormalTok{(fixNum) }\CommentTok{\# use this to get middle fixation indicators later}
\NormalTok{  )}

\CommentTok{\# middle fixations}
\NormalTok{food}\SpecialCharTok{$}\NormalTok{middleFix }\OtherTok{\textless{}{-}}\NormalTok{ (food}\SpecialCharTok{$}\NormalTok{fixNum}\SpecialCharTok{\textgreater{}}\DecValTok{1} \SpecialCharTok{\&}\NormalTok{ food}\SpecialCharTok{$}\NormalTok{fixNum}\SpecialCharTok{!=}\NormalTok{food}\SpecialCharTok{$}\NormalTok{maxFixNum)}
\end{Highlighting}
\end{Shaded}

\hypertarget{how-should-drift-change}{%
\section{How should drift change?}\label{how-should-drift-change}}

Let's regress response time on value difference (L-R) and various metrics of previous exposure. If previous exposure leads to larger drift rate parameters, then we necessarily need a negative correlation between response time and previous exposure.

Really quickly, let's define the data set we will use for regressions. This should be trial-by-trial data. Also, let's change RT to ms for better parameterization. Also, let's set the settings for the hierarchical regressions.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{data }\OtherTok{\textless{}{-}}\NormalTok{ food[food}\SpecialCharTok{$}\NormalTok{fixNum}\SpecialCharTok{==}\DecValTok{1}\NormalTok{,]}
\NormalTok{data}\SpecialCharTok{$}\NormalTok{RT }\OtherTok{\textless{}{-}}\NormalTok{ data}\SpecialCharTok{$}\NormalTok{RT}\SpecialCharTok{*}\DecValTok{1000} \CommentTok{\# convert to ms}

\NormalTok{chainscores }\OtherTok{=} \DecValTok{3}
\NormalTok{iterations }\OtherTok{=} \DecValTok{6000}
\NormalTok{burnin }\OtherTok{=} \FunctionTok{floor}\NormalTok{(iterations}\SpecialCharTok{/}\DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\hypertarget{previous-exposure-to-both-options}{%
\subsection{Previous exposure to both options}\label{previous-exposure-to-both-options}}

Here, I take previous exposure as the sum of total fixation time to either option in previous trials.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#reg.exp.both \textless{}{-} brm(}
\CommentTok{\#  RT \textasciitilde{} difficulty+PreviousExposureBoth + (1+difficulty+PreviousExposureBoth|SubjectNumber),}
\CommentTok{\#  data=data,}
\CommentTok{\#  family=gaussian,}
\CommentTok{\#  chains=chainscores,}
\CommentTok{\#  cores=chainscores,}
\CommentTok{\#  iter=iterations,}
\CommentTok{\#  warmup=burnin,}
\CommentTok{\#  seed=seed,}
\CommentTok{\#  refresh=0}
\CommentTok{\#)}
\NormalTok{reg.exp.both }\OtherTok{=} \FunctionTok{lm}\NormalTok{(RT }\SpecialCharTok{\textasciitilde{}}\NormalTok{ difficulty}\SpecialCharTok{+}\NormalTok{PreviousExposureBoth }\SpecialCharTok{+}\NormalTok{ (}\DecValTok{1}\SpecialCharTok{+}\NormalTok{difficulty}\SpecialCharTok{+}\NormalTok{PreviousExposureBoth}\SpecialCharTok{|}\NormalTok{SubjectNumber), }\AttributeTok{data=}\NormalTok{data)}
\NormalTok{reg.exp.both}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## lm(formula = RT ~ difficulty + PreviousExposureBoth + (1 + difficulty + 
##     PreviousExposureBoth | SubjectNumber), data = data)
## 
## Coefficients:
##                                               (Intercept)  
##                                                   1521.98  
##                                                difficulty  
##                                                    -66.48  
##                                      PreviousExposureBoth  
##                                                    109.17  
## 1 + difficulty + PreviousExposureBoth | SubjectNumberTRUE  
##                                                        NA
\end{verbatim}

The results don't look very promising. It doesn't seem like previous exposure to both options is affecting the response times.

\hypertarget{previous-exposure-to-chosen-option}{%
\subsection{Previous exposure to chosen option}\label{previous-exposure-to-chosen-option}}

Here, I take previous exposure as the total fixation time to the chosen option in previous trials.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#reg.exp.chosen \textless{}{-} brm(}
\CommentTok{\#  RT \textasciitilde{} difficulty+PreviousExposureChosen + (1+difficulty+PreviousExposureChosen|SubjectNumber),}
\CommentTok{\#  data=data,}
\CommentTok{\#  family=gaussian,}
\CommentTok{\#  chains=chainscores,}
\CommentTok{\#  cores=chainscores,}
\CommentTok{\#  iter=iterations,}
\CommentTok{\#  warmup=burnin,}
\CommentTok{\#  seed=seed,}
\CommentTok{\#  refresh=0}
\CommentTok{\#)}
\NormalTok{reg.exp.chosen }\OtherTok{=} \FunctionTok{lm}\NormalTok{(RT }\SpecialCharTok{\textasciitilde{}}\NormalTok{ difficulty}\SpecialCharTok{+}\NormalTok{PreviousExposureChosen }\SpecialCharTok{+}\NormalTok{ (}\DecValTok{1}\SpecialCharTok{+}\NormalTok{difficulty}\SpecialCharTok{+}\NormalTok{PreviousExposureChosen}\SpecialCharTok{|}\NormalTok{SubjectNumber), }\AttributeTok{data=}\NormalTok{data)}
\NormalTok{reg.exp.chosen}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## lm(formula = RT ~ difficulty + PreviousExposureChosen + (1 + 
##     difficulty + PreviousExposureChosen | SubjectNumber), data = data)
## 
## Coefficients:
##                                                 (Intercept)  
##                                                     1571.36  
##                                                  difficulty  
##                                                      -67.62  
##                                      PreviousExposureChosen  
##                                                      159.42  
## 1 + difficulty + PreviousExposureChosen | SubjectNumberTRUE  
##                                                          NA
\end{verbatim}

The results don't look very promising. It doesn't seem like previous exposure to the chosen option is affecting the response times.

\hypertarget{previous-encounters-with-both-options}{%
\subsection{Previous encounters with both options}\label{previous-encounters-with-both-options}}

Here, I take previous encounters as the number of times the subject has encountered both options before.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#reg.enc.both \textless{}{-} brm(}
\CommentTok{\#  RT \textasciitilde{} difficulty+PreviousEncounterBoth + (1+difficulty+PreviousEncounterBoth|SubjectNumber),}
\CommentTok{\#  data=data,}
\CommentTok{\#  family=gaussian,}
\CommentTok{\#  chains=chainscores,}
\CommentTok{\#  cores=chainscores,}
\CommentTok{\#  iter=iterations,}
\CommentTok{\#  warmup=burnin,}
\CommentTok{\#  seed=seed,}
\CommentTok{\#  save\_pars = save\_pars(all = TRUE), \#for LOO CV later}
\CommentTok{\#  refresh=0}
\CommentTok{\#)}
\NormalTok{reg.enc.both }\OtherTok{=} \FunctionTok{lm}\NormalTok{(RT }\SpecialCharTok{\textasciitilde{}}\NormalTok{ difficulty}\SpecialCharTok{+}\NormalTok{PreviousEncounterBoth }\SpecialCharTok{+}\NormalTok{ (}\DecValTok{1}\SpecialCharTok{+}\NormalTok{difficulty}\SpecialCharTok{+}\NormalTok{PreviousEncounterBoth}\SpecialCharTok{|}\NormalTok{SubjectNumber), }\AttributeTok{data=}\NormalTok{data)}
\NormalTok{reg.enc.both}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## lm(formula = RT ~ difficulty + PreviousEncounterBoth + (1 + difficulty + 
##     PreviousEncounterBoth | SubjectNumber), data = data)
## 
## Coefficients:
##                                                (Intercept)  
##                                                    1893.35  
##                                                 difficulty  
##                                                     -71.17  
##                                      PreviousEncounterBoth  
##                                                     -41.61  
## 1 + difficulty + PreviousEncounterBoth | SubjectNumberTRUE  
##                                                         NA
\end{verbatim}

Interestingly, previous encounters with both options is negatively correlated with response times.

\hypertarget{previous-encounters-with-chosen-option}{%
\subsection{Previous encounters with chosen option}\label{previous-encounters-with-chosen-option}}

Here, I take previous encounters as the number of times the subject has encountered the chosen option before.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#reg.enc.chosen \textless{}{-} brm(}
\CommentTok{\#  RT \textasciitilde{} difficulty+PreviousEncounterChosen + (1+difficulty+PreviousEncounterChosen|SubjectNumber),}
\CommentTok{\#  data=data,}
\CommentTok{\#  family=gaussian,}
\CommentTok{\#  chains=chainscores,}
\CommentTok{\#  cores=chainscores,}
\CommentTok{\#  iter=iterations,}
\CommentTok{\#  warmup=burnin,}
\CommentTok{\#  seed=seed,}
\CommentTok{\#  save\_pars = save\_pars(all = TRUE), \#for LOO CV later}
\CommentTok{\#  refresh=0}
\CommentTok{\#)}
\NormalTok{reg.enc.chosen }\OtherTok{=} \FunctionTok{lm}\NormalTok{(RT }\SpecialCharTok{\textasciitilde{}}\NormalTok{ difficulty}\SpecialCharTok{+}\NormalTok{PreviousEncounterChosen }\SpecialCharTok{+}\NormalTok{ (}\DecValTok{1}\SpecialCharTok{+}\NormalTok{difficulty}\SpecialCharTok{+}\NormalTok{PreviousEncounterChosen}\SpecialCharTok{|}\NormalTok{SubjectNumber), }\AttributeTok{data=}\NormalTok{data)}
\NormalTok{reg.enc.chosen}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## lm(formula = RT ~ difficulty + PreviousEncounterChosen + (1 + 
##     difficulty + PreviousEncounterChosen | SubjectNumber), data = data)
## 
## Coefficients:
##                                                  (Intercept)  
##                                                      1836.70  
##                                                   difficulty  
##                                                       -70.50  
##                                      PreviousEncounterChosen  
##                                                       -53.42  
## 1 + difficulty + PreviousEncounterChosen | SubjectNumberTRUE  
##                                                           NA
\end{verbatim}

It seems that previous encounters with the chosen option is also negatively correlated with response times.

\hypertarget{model-comparison}{%
\subsection{Model comparison}\label{model-comparison}}

So now we have two potential ways in which working memory might affect response times. (1) Previous encounters with both options, and (2) Previous encounters with the chosen item. Let's run a quick model comparison using Leave-One-Out Cross Validation to see which explains the data better.

We are comparing the expected log pointwise predictive density (ELPD) of the ``chosen'' model compared to the ``both'' model. For this, we should look at the elpd\_loo. The better model has the higher elpd\_loo.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#loo1 \textless{}{-} loo(reg.enc.both)}
\CommentTok{\#loo2 \textless{}{-} loo(reg.enc.chosen)}

\CommentTok{\#comparison \textless{}{-} loo\_compare(loo1,loo2)}
\CommentTok{\#print(comparison, simplify=FALSE, digits=3)}
\end{Highlighting}
\end{Shaded}

{[}I ran these at some point in the past, but I didn't want to have to rerun the MCMC algorithms when I reknit the book again. I've commented out all the analyses using Bayesian heirarchical modeling and used OLS instead. This means there's no need to use ELPD, but I've left the written analyses in from a long time ago so you can see what the results were.{]}

It looks like previous encounters with the chosen option slightly outperforms previous encounters with both options.

The results here suggest that previous encounters with the chosen option are correlated with faster responses. My hunch is that working memory is somehow affecting behavior. My hypothesis is that repeated exposure to the chosen item is increasing the ease with which subjects can sample value signals from working memory \citep{weilbacher2021}.

These results make sense with the previous literature. \citep{weilbacher2021} showed that the amount of attention to an item did not affect whether or not subjects remembered that item. However, \citep{agranov2017} found that repeated encounters with the same item sped up response times. Perhaps value become easier to sample from memory with more encounters, but is not modulated by the amount of exposure per encounter.

In the next section, I will design a variation of the aDDM where the drift rate scales with previous encounters with the chosen item.

\hypertarget{mem-addm}{%
\section{mem-aDDM}\label{mem-addm}}

\hypertarget{fitting-methods}{%
\subsection{Fitting Methods}\label{fitting-methods}}

The general piecewise constant DDM (pcDDM) does not have fully time-dependent drift rates. Instead, it has drift rates that are constant over discrete intervals. The continuous pcDDM is written as follows:

\(dx(t) = \mu(t) dt + \sigma dW(t)\)

where:

\begin{itemize}
\tightlist
\item
  \(x(t)\) is evidence at time \(t\)
\item
  \(\mu(t)\) is the drift rate at time \(t\)
\item
  \(\sigma\) is the standard deviation of the Brownian motion
\item
  \(W(t)\) is standard Brownian motion
\end{itemize}

Bias is \(x(0)=x_0\). Drift is \(\mu(t)=\mu_i\) for \(t_i \leq t < t_{i+1}\). Response time is \(\tau = \inf\{t>0|x(t)\not\in(-B,B)\}\).

Following \citep{lombardi2021}, we can rewrite drift rate when two conditions hold: (1) when it is constant in discrete time intervals, and (2) when stopping time is explicitly known. We rewrite it:

\begin{equation}
\begin{aligned}

\mu(t) &= \sum_{i=0}^{n-1} \mu_i 1_{[t_i,t_{i+1})} \\

\int_0^\tau \mu(t) dt &= \int_0^\tau \sum_{i=0}^{n-1} \mu_i 1_{[t_i,t_{i+1})} dt \\

\int_0^\tau \sum_{i=0}^{n-1} |\mu_i 1_{[t_i,t_{i+1})}| dt &< \infty, \; \therefore \text{by Fubini's theorem,} \\

\int_0^\tau \mu(t) dt &= \sum_{i=0}^{n-1} \int_0^\tau \mu_i 1_{[t_i,t_{i+1})} dt \\

&= \sum_{i=0}^{n-1} \int_{t_i}^{t_{i+1}} \mu_i dt \\

&= \tau \left( \sum_{i=0}^{n-1} \int_{t_i}^{t_{i+1}} \mu_i dt \right) \frac{1}{\tau} \\

\text{By Fundamental theorem of} &\text{ calculus and some continuity conditions...} \\

&= \int_0^\tau \frac{d}{d\tau} \left[ \tau \left( \sum_{i=0}^{n-1} \int_{t_i}^{t_{i+1}} \mu_i dt \right) \frac{1}{\tau} \right] dt \\

&= \int_0^\tau \left( \frac{1}{\tau} \sum_{i=0}^{n-1} \int_{t_i}^{t_{i+1}} \mu_i dt \right) dt - \int_0^\tau \left( \frac{1}{\tau} \sum_{i=0}^{n-1} \int_{t_i}^{t_{i+1}} \mu_i dt \right) dt \\

&= ??? \\

&= \int_0^\tau \left( \frac{1}{\tau} \sum_{i=0}^{n-1} \int_{t_i}^{t_{i+1}} \mu_i dt \right) dt \\

\text{Let } t_0=0 \text{ and } t_n=\tau. &\text{ If } n \text{ is the number of intervals, then} \\

\mu(t) &= \frac{1}{\tau} \sum_{i=0}^{n-1} \int_{t_i}^{t_{i+1}} \mu_i dt \\

&= \frac{1}{\tau} \sum_{i=0}^{n-1} \mu_i (t_{i+1}-t_i)

\end{aligned}
\end{equation}

Here, \(\mu_i\) is constant across each time interval \((t_{i+1}-t_i)\). The drift rate in the aDDM can be written as:

\(\bar{\mu} = \frac{\tau_A}{\tau} d (V_A-\theta V_B) + \frac{\tau_B}{\tau} d (\theta V_A- V_B)\)

I modify drift rate to account for previous encounters with the chosen option. Note that this remains constant across an entire trial, thus we can transform the drift rate parameter and still use the toolbox by \citep{lombardi2021}:

\(\bar{\mu} = (d+\gamma \text{PreviousEncounters}) \left[ \frac{\tau_A}{\tau} (V_A-\theta V_B) + \frac{\tau_B}{\tau} (\theta V_A- V_B) \right]\)

where \(\text{PreviousEncounters}\) is the number of times the chosen item was seen in previous trials.

\hypertarget{lombardi-hare-toolbox}{%
\subsection{Lombardi \& Hare Toolbox}\label{lombardi-hare-toolbox}}

This is the part of the toolbox that prepares the data. I've modified it to include PreviousEncounters.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# \# \# Input a dataframe with: \# \# \# \# \# \# \# \# \# \# \# \# \# \# \# \# \# \# \# \# \# \# \# \# \# \# \# \# \# \# \# \# \# \# \# \# \# \#}
\CommentTok{\#}
\CommentTok{\# choice   {-}\textgreater{} =1 if left food item chosen, =0 if right food item chosen}
\CommentTok{\# leftval  {-}\textgreater{} value option on the left}
\CommentTok{\# rightval {-}\textgreater{} value option on the right}
\CommentTok{\# rt       {-}\textgreater{} reaction time in ms}
\CommentTok{\# fixnum   {-}\textgreater{} fixation number}
\CommentTok{\# fixdur   {-}\textgreater{} fixation duration in ms}
\CommentTok{\# pe       {-}\textgreater{} total number of times the chosen option was seen in previous trials}
\CommentTok{\# roi      {-}\textgreater{} region of interest of the fixation (1 if fixation to the left option, 2 to the right option)}
\CommentTok{\# trial    {-}\textgreater{} trial number}
\CommentTok{\# subject  {-}\textgreater{} subject number}
\CommentTok{\#}
\CommentTok{\# \# \# \# \# \# \# \# \# \# \# \# \# \# \# \# \# \# \# \# \# \# \# \# \# \# \# \# \# \# \# \# \# \# \# \# \# \# \# \# \# \# \# \# \# \# \# \# \# \# \# \# \# }

\NormalTok{LHToolbox }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(data) \{}
  
  \CommentTok{\# subject numbers}
\NormalTok{  subjs}\OtherTok{\textless{}{-}} \FunctionTok{unique}\NormalTok{(data}\SpecialCharTok{$}\NormalTok{subject)}
  
  \CommentTok{\# calculate total fixation duration}
  \CommentTok{\# total fixation time to the left option }
  \CommentTok{\# and total fixation time to the right option}
  \ControlFlowTok{for}\NormalTok{( s }\ControlFlowTok{in}\NormalTok{ subjs)\{}
    \ControlFlowTok{for}\NormalTok{ (t }\ControlFlowTok{in} \FunctionTok{unique}\NormalTok{(data}\SpecialCharTok{$}\NormalTok{trial[data}\SpecialCharTok{$}\NormalTok{subject}\SpecialCharTok{==}\NormalTok{s]))\{}
      \CommentTok{\#index for all fixations in one trial}
\NormalTok{      ind}\OtherTok{=}\FunctionTok{which}\NormalTok{(data}\SpecialCharTok{$}\NormalTok{subject}\SpecialCharTok{==}\NormalTok{s }\SpecialCharTok{\&}\NormalTok{ data}\SpecialCharTok{$}\NormalTok{trial}\SpecialCharTok{==}\NormalTok{t)}
      \CommentTok{\#index for left fixations in the trial}
\NormalTok{      indl}\OtherTok{=}\FunctionTok{which}\NormalTok{(data}\SpecialCharTok{$}\NormalTok{subject}\SpecialCharTok{==}\NormalTok{s }\SpecialCharTok{\&}\NormalTok{ data}\SpecialCharTok{$}\NormalTok{trial}\SpecialCharTok{==}\NormalTok{t }\SpecialCharTok{\&}\NormalTok{ data}\SpecialCharTok{$}\NormalTok{roi}\SpecialCharTok{==}\DecValTok{1}\NormalTok{)}
      \CommentTok{\#index for right fixations in the trial}
\NormalTok{      indr}\OtherTok{=}\FunctionTok{which}\NormalTok{(data}\SpecialCharTok{$}\NormalTok{subject}\SpecialCharTok{==}\NormalTok{s }\SpecialCharTok{\&}\NormalTok{ data}\SpecialCharTok{$}\NormalTok{trial}\SpecialCharTok{==}\NormalTok{t }\SpecialCharTok{\&}\NormalTok{ data}\SpecialCharTok{$}\NormalTok{roi}\SpecialCharTok{==}\DecValTok{0}\NormalTok{)}
      \CommentTok{\#total fixation duration}
\NormalTok{      data}\SpecialCharTok{$}\NormalTok{totfix[data}\SpecialCharTok{$}\NormalTok{subject}\SpecialCharTok{==}\NormalTok{s }\SpecialCharTok{\&}\NormalTok{ data}\SpecialCharTok{$}\NormalTok{trial}\SpecialCharTok{==}\NormalTok{t] }\OtherTok{=} \FunctionTok{sum}\NormalTok{(data}\SpecialCharTok{$}\NormalTok{fixdur[ind])}
      \CommentTok{\#fixation time to the left option}
\NormalTok{      data}\SpecialCharTok{$}\NormalTok{fixleft[data}\SpecialCharTok{$}\NormalTok{subject}\SpecialCharTok{==}\NormalTok{s }\SpecialCharTok{\&}\NormalTok{ data}\SpecialCharTok{$}\NormalTok{trial}\SpecialCharTok{==}\NormalTok{t] }\OtherTok{=} \FunctionTok{sum}\NormalTok{(data}\SpecialCharTok{$}\NormalTok{fixdur[indl])}
      \CommentTok{\#fixation time to the right option}
\NormalTok{      data}\SpecialCharTok{$}\NormalTok{fixright[data}\SpecialCharTok{$}\NormalTok{subject}\SpecialCharTok{==}\NormalTok{s }\SpecialCharTok{\&}\NormalTok{ data}\SpecialCharTok{$}\NormalTok{trial}\SpecialCharTok{==}\NormalTok{t] }\OtherTok{=} \FunctionTok{sum}\NormalTok{(data}\SpecialCharTok{$}\NormalTok{fixdur[indr])}
\NormalTok{    \}}
\NormalTok{  \}}
  
  \CommentTok{\# discard all the fixations, keep the first one}
\NormalTok{  data}\OtherTok{\textless{}{-}}\NormalTok{data[data}\SpecialCharTok{$}\NormalTok{fixnum}\SpecialCharTok{==}\DecValTok{1}\NormalTok{,]}
  
  \CommentTok{\#non decision time = rt {-} total fixation time}
\NormalTok{  data}\SpecialCharTok{$}\NormalTok{ndt }\OtherTok{\textless{}{-}}\NormalTok{ (data}\SpecialCharTok{$}\NormalTok{rt }\SpecialCharTok{{-}}\NormalTok{ data}\SpecialCharTok{$}\NormalTok{totfix) }\CommentTok{\# in seconds}
\NormalTok{  data}\SpecialCharTok{$}\NormalTok{ndt[data}\SpecialCharTok{$}\NormalTok{ndt}\SpecialCharTok{\textless{}}\DecValTok{0}\NormalTok{] }\OtherTok{\textless{}{-}} \FloatTok{0.0001} \CommentTok{\# you can decide whether to fit the ndt or give it as input to the model}
  
  \CommentTok{\# NB BEFORE FITTING THE MODEL MAKE SURE YOU HAVE NO NAN or NA IN YOUR DATA}
  
  \CommentTok{\#{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}\#{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}}
  
  \CommentTok{\# RT is positive if left food item choosen, negative if right food item chosen}
\NormalTok{  data}\SpecialCharTok{$}\NormalTok{rtPN[data}\SpecialCharTok{$}\NormalTok{choice}\SpecialCharTok{==}\DecValTok{1}\NormalTok{]}\OtherTok{\textless{}{-}}\NormalTok{ data}\SpecialCharTok{$}\NormalTok{rt[data}\SpecialCharTok{$}\NormalTok{choice}\SpecialCharTok{==}\DecValTok{1}\NormalTok{] }\CommentTok{\# in seconds}
\NormalTok{  data}\SpecialCharTok{$}\NormalTok{rtPN[data}\SpecialCharTok{$}\NormalTok{choice}\SpecialCharTok{==}\DecValTok{0}\NormalTok{]}\OtherTok{\textless{}{-}} \SpecialCharTok{{-}}\NormalTok{data}\SpecialCharTok{$}\NormalTok{rt[data}\SpecialCharTok{$}\NormalTok{choice}\SpecialCharTok{==}\DecValTok{0}\NormalTok{] }\CommentTok{\# in seconds}
  
  \CommentTok{\# Index of subjects}
\NormalTok{  idxP }\OtherTok{=} \FunctionTok{as.numeric}\NormalTok{(}\FunctionTok{ordered}\NormalTok{(data}\SpecialCharTok{$}\NormalTok{subject)) }\CommentTok{\#makes a sequentially numbered subj index}
  
  \CommentTok{\# rescale the value of the options}
\NormalTok{  v\_left }\OtherTok{=}\NormalTok{ data}\SpecialCharTok{$}\NormalTok{leftval}\SpecialCharTok{/}\DecValTok{10} \CommentTok{\# Smith \& Krajbich 2018 scale was from 1{-}10}
\NormalTok{  v\_right }\OtherTok{=}\NormalTok{ data}\SpecialCharTok{$}\NormalTok{rightval}\SpecialCharTok{/}\DecValTok{10}
  
  \CommentTok{\# value diff}
\NormalTok{  vDiff }\OtherTok{=} \FunctionTok{round}\NormalTok{(v\_left}\SpecialCharTok{{-}}\NormalTok{v\_right,}\DecValTok{1}\NormalTok{)}
  
  \CommentTok{\# proportion of fixations to the left option (nb. fixright = 1{-}gazeL)}
\NormalTok{  gazeL }\OtherTok{=}\NormalTok{ data}\SpecialCharTok{$}\NormalTok{fixleft}\SpecialCharTok{/}\NormalTok{data}\SpecialCharTok{$}\NormalTok{totfix}

  \CommentTok{\# rt to fit}
\NormalTok{  y }\OtherTok{=}\NormalTok{ data}\SpecialCharTok{$}\NormalTok{rtPN}
  
  \CommentTok{\# number of trials}
\NormalTok{  N }\OtherTok{=} \FunctionTok{length}\NormalTok{(y)}
  
  \CommentTok{\# number of subjects}
\NormalTok{  ns }\OtherTok{=} \FunctionTok{length}\NormalTok{(}\FunctionTok{unique}\NormalTok{(idxP))}
  
  \CommentTok{\# non{-}decision time}
\NormalTok{  ndt }\OtherTok{=}\NormalTok{ data}\SpecialCharTok{$}\NormalTok{ndt}
  
  \CommentTok{\# previous encounters, scaled from 0 to 1 by the maximum number of previous encounters.}
\NormalTok{  pe }\OtherTok{=}\NormalTok{ data}\SpecialCharTok{$}\NormalTok{pe}\SpecialCharTok{/}\FunctionTok{max}\NormalTok{(data}\SpecialCharTok{$}\NormalTok{pe)}
  
  \CommentTok{\#{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}}
  \CommentTok{\# fit the model}
  
  \CommentTok{\# data}
\NormalTok{  dat }\OtherTok{\textless{}{-}} \FunctionTok{list}\NormalTok{(}
    \AttributeTok{subject=}\NormalTok{data}\SpecialCharTok{$}\NormalTok{subject,}
    \AttributeTok{trial=}\NormalTok{data}\SpecialCharTok{$}\NormalTok{trial,}
    \AttributeTok{choice=}\NormalTok{data}\SpecialCharTok{$}\NormalTok{choice,}
    \AttributeTok{rt=}\NormalTok{data}\SpecialCharTok{$}\NormalTok{rt,}
    \AttributeTok{N=}\NormalTok{N, }
    \AttributeTok{y=}\NormalTok{y, }
    \AttributeTok{idxP=}\NormalTok{idxP, }
    \AttributeTok{v\_L=}\NormalTok{v\_left,}
    \AttributeTok{v\_R=}\NormalTok{v\_right, }
    \AttributeTok{vDiff=}\NormalTok{vDiff,}
    \AttributeTok{gazeL=}\NormalTok{gazeL, }
    \AttributeTok{ns=}\NormalTok{ns, }
    \AttributeTok{ndt=}\NormalTok{ndt, }
    \AttributeTok{pe=}\NormalTok{pe}
\NormalTok{  )}
  
  \FunctionTok{return}\NormalTok{(dat)}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\hypertarget{jags-code}{%
\subsection{JAGS code}\label{jags-code}}

\(RDV_t = RDV_{t-1} + (d+\gamma*\text{PreviousEncounters})\mu+\epsilon\)

where \(\mu=(V_L-\theta V_R)\) if looking left, and \(\mu=(\theta V_L-V_R)\) if looking right. \(\epsilon \sim N(0,\sigma)\) is white, Gaussian noise. \(\gamma\) is sensitivity to previous time spent looking at either stimuli.

Don't forget that JAGS rnorm works with precision\ldots{} so confusing keeping track of what Stan or JAGS use\ldots{}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{cat}\NormalTok{( }\StringTok{"model \{}

\StringTok{    \# drift rate}
\StringTok{        d\_mu \textasciitilde{} dunif(0.00001,50)}
\StringTok{        d\_pr \textasciitilde{} dgamma(1, 0.1)}
\StringTok{        }
\StringTok{    \# previous exposure sensitivity}
\StringTok{        g\_mu \textasciitilde{} dunif(0.00001,50)}
\StringTok{        g\_pr \textasciitilde{} dgamma(1, 0.1)}

\StringTok{    \# noise}
\StringTok{        sig\_mu \textasciitilde{} dunif(0.000001, 2)}
\StringTok{        sig\_pr \textasciitilde{} dgamma(1, 0.1)}

\StringTok{    \# Bias of the DDM}
\StringTok{        bias\_alpha \textless{}{-} bias\_mu * bias\_kappa}
\StringTok{        bias\_beta \textless{}{-} (1 {-} bias\_mu) * bias\_kappa}
\StringTok{        bias\_mu \textasciitilde{} dbeta(2, 2)T(0.01,0.99)}
\StringTok{        bias\_kappa \textasciitilde{} dgamma(1, 0.5)}

\StringTok{    \# attentional bias}
\StringTok{        theta\_mu \textasciitilde{} dnorm(.5,.3)T(0,1)}
\StringTok{        theta\_pr \textasciitilde{} dgamma(1, 0.1)}

\StringTok{    for (p in 1:ns) \{ \# subject level}

\StringTok{        d[p] \textasciitilde{} dnorm(d\_mu, d\_pr)T(0.000001,50)}
\StringTok{        }
\StringTok{        g[p] \textasciitilde{} dnorm(g\_mu, g\_pr)T(0.000001,50)}
\StringTok{        }
\StringTok{        sig[p] \textasciitilde{} dnorm(sig\_mu, sig\_pr)T(0.00001,2)}
\StringTok{        }
\StringTok{        bias[p] \textasciitilde{} dbeta(bias\_alpha, bias\_beta)T(0.01,0.99)}

\StringTok{        theta[p] \textasciitilde{} dnorm(theta\_mu, theta\_pr)T(0,1)}
\StringTok{    \}}

\StringTok{    for (i in 1:N) \{ \# trial level}

\StringTok{    \#\# WIENER model, fixing the threshold to 2 and estimating the noise}
\StringTok{        y[i] \textasciitilde{} dwieners(2, tau[i], bet[i], w[i], sig[idxP[i]] ) \# actual DDM distribution}

\StringTok{        \# generate trial{-}by{-}trial nDT}
\StringTok{        tau[i] \textless{}{-} ndt[i]}

\StringTok{        \# generate trial{-}by{-}trial Bias}
\StringTok{        bet[i] \textless{}{-} bias[idxP[i]]}

\StringTok{        \# Drift rate}
\StringTok{        w[i] \textless{}{-} (d[idxP[i]]+g[idxP[i]]*pe[i]) * ( (gazeL[i]*v\_L[i] {-} (1{-}gazeL[i])*v\_R[i]) + theta[idxP[i]]*((1{-}gazeL[i])*v\_L[i] {-} gazeL[i]*v\_R[i]))}

\StringTok{    \}}
\StringTok{\}"}\NormalTok{, }\AttributeTok{file=}\StringTok{"temp/mem{-}aDDM\_memaDDM.txt"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\hypertarget{fit-mem-addm}{%
\subsection{Fit mem-aDDM}\label{fit-mem-addm}}

Use odd trials as training data. At the end, check whether all distributions have converged with Gelman-Rubin statistics.

\textbf{One key thing I've learned about the Lombardi-Hare Toolbox from this project: If non-decision time takes up more than 99\% of the response time, the JAGS wiener module will completely break (``Node inconsistent with parent''). To use the toolbox, you need to drop the trials where (NDT/RT) \textgreater{} 0.99!}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# rename and transform}
\NormalTok{toolboxdata }\OtherTok{\textless{}{-}} \FunctionTok{data.frame}\NormalTok{(}
  \AttributeTok{choice =} \FunctionTok{ifelse}\NormalTok{(food}\SpecialCharTok{$}\NormalTok{LeftRight}\SpecialCharTok{==}\DecValTok{1}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{0}\NormalTok{),}
  \AttributeTok{leftval =}\NormalTok{ food}\SpecialCharTok{$}\NormalTok{ValueLeft,}
  \AttributeTok{rightval =}\NormalTok{ food}\SpecialCharTok{$}\NormalTok{ValueRight,}
  \AttributeTok{rt =}\NormalTok{ food}\SpecialCharTok{$}\NormalTok{RT,}
  \AttributeTok{fixnum =}\NormalTok{ food}\SpecialCharTok{$}\NormalTok{fixNum,}
  \AttributeTok{fixdur =}\NormalTok{ food}\SpecialCharTok{$}\NormalTok{DwellLength,}
  \AttributeTok{pe =}\NormalTok{ food}\SpecialCharTok{$}\NormalTok{PreviousEncounterChosen,}
  \AttributeTok{roi =} \FunctionTok{ifelse}\NormalTok{(food}\SpecialCharTok{$}\NormalTok{ROI}\SpecialCharTok{==}\DecValTok{1}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{0}\NormalTok{),}
  \AttributeTok{trial =}\NormalTok{ food}\SpecialCharTok{$}\NormalTok{Trial,}
  \AttributeTok{subject =}\NormalTok{ food}\SpecialCharTok{$}\NormalTok{SubjectNumber,}
  \AttributeTok{totfix =} \ConstantTok{NA}\NormalTok{, }\CommentTok{\#placeholder}
  \AttributeTok{fixleft =} \ConstantTok{NA}\NormalTok{, }\CommentTok{\#placeholder}
  \AttributeTok{fixright =} \ConstantTok{NA} \CommentTok{\#placeholder}
\NormalTok{)}
\NormalTok{train }\OtherTok{\textless{}{-}}\NormalTok{ toolboxdata[toolboxdata}\SpecialCharTok{$}\NormalTok{trial}\SpecialCharTok{\%\%}\DecValTok{2}\SpecialCharTok{!=}\DecValTok{0}\NormalTok{,] }\CommentTok{\# Training data}
\NormalTok{test }\OtherTok{\textless{}{-}}\NormalTok{ toolboxdata[toolboxdata}\SpecialCharTok{$}\NormalTok{trial}\SpecialCharTok{\%\%}\DecValTok{2}\SpecialCharTok{==}\DecValTok{0}\NormalTok{,] }\CommentTok{\# Testing data}

\CommentTok{\# Lombardi Hare toolbox transformation}
\NormalTok{train }\OtherTok{\textless{}{-}} \FunctionTok{data.frame}\NormalTok{(}\FunctionTok{LHToolbox}\NormalTok{(train))}
\NormalTok{test }\OtherTok{\textless{}{-}} \FunctionTok{data.frame}\NormalTok{(}\FunctionTok{LHToolbox}\NormalTok{(test))}

\CommentTok{\# Drop any trials where NDT is more than 99\% of the trial. Why?}
\CommentTok{\# (1) This breaks JAGS wiener module.}
\CommentTok{\# (2) Who the heck is spending more than 99\% of a trial not fixating on anything?}
\NormalTok{train}\SpecialCharTok{$}\NormalTok{who }\OtherTok{\textless{}{-}}\NormalTok{ train}\SpecialCharTok{$}\NormalTok{ndt}\SpecialCharTok{/}\NormalTok{train}\SpecialCharTok{$}\NormalTok{rt}
\NormalTok{train }\OtherTok{\textless{}{-}}\NormalTok{ train[train}\SpecialCharTok{$}\NormalTok{who}\SpecialCharTok{\textless{}}\NormalTok{.}\DecValTok{99}\NormalTok{,]}
\NormalTok{test}\SpecialCharTok{$}\NormalTok{who }\OtherTok{\textless{}{-}}\NormalTok{ test}\SpecialCharTok{$}\NormalTok{ndt}\SpecialCharTok{/}\NormalTok{test}\SpecialCharTok{$}\NormalTok{rt}
\NormalTok{test }\OtherTok{\textless{}{-}}\NormalTok{ test[test}\SpecialCharTok{$}\NormalTok{who}\SpecialCharTok{\textless{}}\NormalTok{.}\DecValTok{99}\NormalTok{,]}

\CommentTok{\# Any recent adjustments to the data require that I remake the data dump that goes into JAGS}
\NormalTok{dat }\OtherTok{\textless{}{-}} \FunctionTok{dump.format}\NormalTok{(}\FunctionTok{list}\NormalTok{(}
  \AttributeTok{N=}\FunctionTok{length}\NormalTok{(train}\SpecialCharTok{$}\NormalTok{y), }
  \AttributeTok{y=}\NormalTok{train}\SpecialCharTok{$}\NormalTok{y, }
  \AttributeTok{idxP=}\FunctionTok{as.numeric}\NormalTok{(}\FunctionTok{ordered}\NormalTok{(train}\SpecialCharTok{$}\NormalTok{subject)), }
  \AttributeTok{v\_L=}\NormalTok{train}\SpecialCharTok{$}\NormalTok{v\_L,}
  \AttributeTok{v\_R=}\NormalTok{train}\SpecialCharTok{$}\NormalTok{v\_R, }
  \AttributeTok{gazeL=}\NormalTok{train}\SpecialCharTok{$}\NormalTok{gazeL, }
  \AttributeTok{ns=}\FunctionTok{length}\NormalTok{(}\FunctionTok{unique}\NormalTok{(train}\SpecialCharTok{$}\NormalTok{subject)), }
  \AttributeTok{ndt=}\NormalTok{train}\SpecialCharTok{$}\NormalTok{ndt, }
  \AttributeTok{pe=}\NormalTok{train}\SpecialCharTok{$}\NormalTok{pe}
\NormalTok{))}

\CommentTok{\# initial guesses}
\NormalTok{inits1 }\OtherTok{\textless{}{-}} \FunctionTok{dump.format}\NormalTok{(}\FunctionTok{list}\NormalTok{( }
  \AttributeTok{d\_mu=}\FloatTok{0.2}\NormalTok{, }\AttributeTok{d\_pr=}\FloatTok{0.05}\NormalTok{,}
  \AttributeTok{g\_mu=}\FloatTok{0.2}\NormalTok{, }\AttributeTok{g\_pr=}\FloatTok{0.05}\NormalTok{,}
  \AttributeTok{sig\_mu=}\DecValTok{1}\NormalTok{,}\AttributeTok{sig\_pr=}\DecValTok{1}\NormalTok{,}
  \AttributeTok{bias\_mu=}\FloatTok{0.5}\NormalTok{, }\AttributeTok{bias\_kappa=}\DecValTok{1}\NormalTok{,}
  \AttributeTok{theta\_mu=}\FloatTok{0.6}\NormalTok{,}\AttributeTok{theta\_pr=}\FloatTok{0.5}\NormalTok{,}
  \AttributeTok{.RNG.name=}\StringTok{"base::Super{-}Duper"}\NormalTok{, }\AttributeTok{.RNG.seed=}\DecValTok{1}
\NormalTok{))}

\NormalTok{inits2 }\OtherTok{\textless{}{-}} \FunctionTok{dump.format}\NormalTok{(}\FunctionTok{list}\NormalTok{( }
  \AttributeTok{d\_mu=}\FloatTok{0.1}\NormalTok{, }\AttributeTok{d\_pr=}\FloatTok{0.05}\NormalTok{,}
  \AttributeTok{g\_mu=}\FloatTok{0.1}\NormalTok{, }\AttributeTok{g\_pr=}\FloatTok{0.05}\NormalTok{,}
  \AttributeTok{sig\_mu=}\DecValTok{1}\NormalTok{,}\AttributeTok{sig\_pr=}\DecValTok{1}\NormalTok{,}
  \AttributeTok{bias\_mu=}\FloatTok{0.6}\NormalTok{, }\AttributeTok{bias\_kappa=}\DecValTok{1}\NormalTok{,}
  \AttributeTok{theta\_mu=}\FloatTok{0.5}\NormalTok{,}\AttributeTok{theta\_pr=}\FloatTok{0.5}\NormalTok{,}
  \AttributeTok{.RNG.name=}\StringTok{"base::Wichmann{-}Hill"}\NormalTok{, }\AttributeTok{.RNG.seed=}\DecValTok{2}
\NormalTok{))}

\NormalTok{inits3 }\OtherTok{\textless{}{-}} \FunctionTok{dump.format}\NormalTok{(}\FunctionTok{list}\NormalTok{( }
  \AttributeTok{d\_mu=}\FloatTok{0.05}\NormalTok{, }\AttributeTok{d\_pr=}\FloatTok{0.05}\NormalTok{,}
  \AttributeTok{g\_mu=}\FloatTok{0.05}\NormalTok{, }\AttributeTok{g\_pr=}\FloatTok{0.05}\NormalTok{,}
  \AttributeTok{sig\_mu=}\DecValTok{1}\NormalTok{,}\AttributeTok{sig\_pr=}\DecValTok{1}\NormalTok{,}
  \AttributeTok{bias\_mu=}\FloatTok{0.4}\NormalTok{, }\AttributeTok{bias\_kappa=}\DecValTok{1}\NormalTok{,}
  \AttributeTok{theta\_mu=}\FloatTok{0.2}\NormalTok{,}\AttributeTok{theta\_pr=}\FloatTok{0.5}\NormalTok{,}
  \AttributeTok{.RNG.name=}\StringTok{"base::Mersenne{-}Twister"}\NormalTok{, }\AttributeTok{.RNG.seed=}\DecValTok{3}
\NormalTok{))}

\CommentTok{\# parameters to monitor}
\NormalTok{monitor }\OtherTok{=} \FunctionTok{c}\NormalTok{(}
  \StringTok{"d\_mu"}\NormalTok{, }\StringTok{"d\_pr"}\NormalTok{, }\StringTok{"d"}\NormalTok{, }\CommentTok{\# drift rate}
  \StringTok{"g\_mu"}\NormalTok{, }\StringTok{"g\_pr"}\NormalTok{, }\StringTok{"g"}\NormalTok{, }\CommentTok{\# exposure modulates drift rate}
  \StringTok{"sig\_mu"}\NormalTok{, }\StringTok{"sig\_pr"}\NormalTok{, }\StringTok{"sig"}\NormalTok{, }\CommentTok{\# noise }
  \StringTok{"bias\_mu"}\NormalTok{, }\StringTok{"bias\_kappa"}\NormalTok{, }\StringTok{"bias"}\NormalTok{, }\CommentTok{\# bias}
  \StringTok{"theta\_mu"}\NormalTok{, }\StringTok{"theta\_pr"}\NormalTok{, }\StringTok{"theta"} \CommentTok{\# attentional discounting}
\NormalTok{) }

\CommentTok{\# \# run the fitting}
\CommentTok{\# set.seed(seed)}
\CommentTok{\# results \textless{}{-} run.jags(}
\CommentTok{\#   model="temp/mem{-}aDDM\_memaDDM.txt", }
\CommentTok{\#   monitor=monitor, }
\CommentTok{\#   data=dat, }
\CommentTok{\#   n.chains=3, }
\CommentTok{\#   inits=list(inits1,inits2,inits3),}
\CommentTok{\#   plots = TRUE, }
\CommentTok{\#   method="parallel", }
\CommentTok{\#   module="wiener", }
\CommentTok{\#   burnin=15000, sample=5000 \#burnin=25000 sample=10000}
\CommentTok{\# ) }
\CommentTok{\# }
\CommentTok{\# memFit \textless{}{-} add.summary(results)}
\CommentTok{\# }
\CommentTok{\# save(memFit, file="temp/mem{-}aDDM\_memaDDMfit.RData")}
\CommentTok{\# }
\CommentTok{\# \# Convergence reached?}
\CommentTok{\# memFit$psrf$mpsrf}
\end{Highlighting}
\end{Shaded}

Looks like we're in the clear.

\hypertarget{map-estimates}{%
\subsection{MAP estimates}\label{map-estimates}}

Let's get the mode and 95\% HDI for each subject's parameter estimates.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# estimate and return the mode of a distribution (in this case, the posterior)}
\NormalTok{estimate\_mode }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(x) \{}
\NormalTok{  d }\OtherTok{\textless{}{-}} \FunctionTok{density}\NormalTok{(x)}
  \FunctionTok{return}\NormalTok{( d}\SpecialCharTok{$}\NormalTok{x[}\FunctionTok{which.max}\NormalTok{(d}\SpecialCharTok{$}\NormalTok{y)] )}
\NormalTok{\}}

\CommentTok{\# estimate 95 HDI}
\NormalTok{estimate\_hdi }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(x, }\AttributeTok{conf=}\NormalTok{.}\DecValTok{95}\NormalTok{) \{}
\NormalTok{  lb }\OtherTok{\textless{}{-}} \DecValTok{0} \SpecialCharTok{+}\NormalTok{ (}\DecValTok{1}\SpecialCharTok{{-}}\NormalTok{conf)}\SpecialCharTok{/}\DecValTok{2}
\NormalTok{  ub }\OtherTok{\textless{}{-}} \DecValTok{1} \SpecialCharTok{{-}}\NormalTok{ (}\DecValTok{1}\SpecialCharTok{{-}}\NormalTok{conf)}\SpecialCharTok{/}\DecValTok{2}
\NormalTok{  d }\OtherTok{\textless{}{-}} \FunctionTok{quantile}\NormalTok{(x, }\AttributeTok{probs =} \FunctionTok{c}\NormalTok{(lb,ub), }\AttributeTok{na.rm =}\NormalTok{ F,}
           \AttributeTok{names =} \ConstantTok{TRUE}\NormalTok{)}
  \FunctionTok{return}\NormalTok{(d)}
\NormalTok{\}}

\FunctionTok{load}\NormalTok{(}\AttributeTok{file=}\StringTok{"temp/mem{-}aDDM\_memaDDMfit.RData"}\NormalTok{)}

\CommentTok{\# Get the traces}
\NormalTok{memtraces }\OtherTok{\textless{}{-}} \FunctionTok{data.frame}\NormalTok{(}\FunctionTok{combine.mcmc}\NormalTok{(}\AttributeTok{mcmc.objects=}\NormalTok{memFit}\SpecialCharTok{$}\NormalTok{mcmc))}

\CommentTok{\# placeholders}
\NormalTok{memMAP }\OtherTok{\textless{}{-}} \FunctionTok{data.frame}\NormalTok{(}
  \AttributeTok{d =} \FunctionTok{unique}\NormalTok{(food}\SpecialCharTok{$}\NormalTok{SubjectNumber),}
  \AttributeTok{d\_lb =} \FunctionTok{unique}\NormalTok{(food}\SpecialCharTok{$}\NormalTok{SubjectNumber),}
  \AttributeTok{d\_ub =} \FunctionTok{unique}\NormalTok{(food}\SpecialCharTok{$}\NormalTok{SubjectNumber),}
  \AttributeTok{g =} \FunctionTok{unique}\NormalTok{(food}\SpecialCharTok{$}\NormalTok{SubjectNumber),}
  \AttributeTok{g\_lb =} \FunctionTok{unique}\NormalTok{(food}\SpecialCharTok{$}\NormalTok{SubjectNumber),}
  \AttributeTok{g\_ub =} \FunctionTok{unique}\NormalTok{(food}\SpecialCharTok{$}\NormalTok{SubjectNumber),}
  \AttributeTok{sig =} \FunctionTok{unique}\NormalTok{(food}\SpecialCharTok{$}\NormalTok{SubjectNumber),}
  \AttributeTok{sig\_lb =} \FunctionTok{unique}\NormalTok{(food}\SpecialCharTok{$}\NormalTok{SubjectNumber),}
  \AttributeTok{sig\_ub =} \FunctionTok{unique}\NormalTok{(food}\SpecialCharTok{$}\NormalTok{SubjectNumber),}
  \AttributeTok{bias =} \FunctionTok{unique}\NormalTok{(food}\SpecialCharTok{$}\NormalTok{SubjectNumber),}
  \AttributeTok{bias\_lb =} \FunctionTok{unique}\NormalTok{(food}\SpecialCharTok{$}\NormalTok{SubjectNumber),}
  \AttributeTok{bias\_ub =} \FunctionTok{unique}\NormalTok{(food}\SpecialCharTok{$}\NormalTok{SubjectNumber),}
  \AttributeTok{theta =} \FunctionTok{unique}\NormalTok{(food}\SpecialCharTok{$}\NormalTok{SubjectNumber),}
  \AttributeTok{theta\_lb =} \FunctionTok{unique}\NormalTok{(food}\SpecialCharTok{$}\NormalTok{SubjectNumber),}
  \AttributeTok{theta\_ub =} \FunctionTok{unique}\NormalTok{(food}\SpecialCharTok{$}\NormalTok{SubjectNumber)}
\NormalTok{)}

\ControlFlowTok{for}\NormalTok{ (j }\ControlFlowTok{in} \FunctionTok{unique}\NormalTok{(food}\SpecialCharTok{$}\NormalTok{SubjectNumber)) \{}
  
  \CommentTok{\# column names}
\NormalTok{  d.ind }\OtherTok{\textless{}{-}} \FunctionTok{paste0}\NormalTok{(}\StringTok{\textquotesingle{}d.\textquotesingle{}}\NormalTok{,}\FunctionTok{toString}\NormalTok{(j),}\StringTok{\textquotesingle{}.\textquotesingle{}}\NormalTok{)}
\NormalTok{  g.ind }\OtherTok{\textless{}{-}} \FunctionTok{paste0}\NormalTok{(}\StringTok{\textquotesingle{}g.\textquotesingle{}}\NormalTok{,}\FunctionTok{toString}\NormalTok{(j),}\StringTok{\textquotesingle{}.\textquotesingle{}}\NormalTok{)}
\NormalTok{  sig.ind }\OtherTok{\textless{}{-}} \FunctionTok{paste0}\NormalTok{(}\StringTok{\textquotesingle{}sig.\textquotesingle{}}\NormalTok{,}\FunctionTok{toString}\NormalTok{(j),}\StringTok{\textquotesingle{}.\textquotesingle{}}\NormalTok{)}
\NormalTok{  bias.ind }\OtherTok{\textless{}{-}} \FunctionTok{paste0}\NormalTok{(}\StringTok{\textquotesingle{}bias.\textquotesingle{}}\NormalTok{,}\FunctionTok{toString}\NormalTok{(j),}\StringTok{\textquotesingle{}.\textquotesingle{}}\NormalTok{)}
\NormalTok{  theta.ind }\OtherTok{\textless{}{-}} \FunctionTok{paste0}\NormalTok{(}\StringTok{\textquotesingle{}theta.\textquotesingle{}}\NormalTok{,}\FunctionTok{toString}\NormalTok{(j),}\StringTok{\textquotesingle{}.\textquotesingle{}}\NormalTok{)}
  
  \CommentTok{\# Get modes}
\NormalTok{  memMAP}\SpecialCharTok{$}\NormalTok{d[j]     }\OtherTok{\textless{}{-}} \FunctionTok{estimate\_mode}\NormalTok{(memtraces[,d.ind])}
\NormalTok{  memMAP}\SpecialCharTok{$}\NormalTok{g[j]     }\OtherTok{\textless{}{-}} \FunctionTok{estimate\_mode}\NormalTok{(memtraces[,g.ind])}
\NormalTok{  memMAP}\SpecialCharTok{$}\NormalTok{sig[j]   }\OtherTok{\textless{}{-}} \FunctionTok{estimate\_mode}\NormalTok{(memtraces[,sig.ind])}
\NormalTok{  memMAP}\SpecialCharTok{$}\NormalTok{bias[j]  }\OtherTok{\textless{}{-}} \FunctionTok{estimate\_mode}\NormalTok{(memtraces[,bias.ind])}
\NormalTok{  memMAP}\SpecialCharTok{$}\NormalTok{theta[j] }\OtherTok{\textless{}{-}} \FunctionTok{estimate\_mode}\NormalTok{(memtraces[,theta.ind])}
  
  \CommentTok{\# Get HDIs}
\NormalTok{  d\_hdi     }\OtherTok{\textless{}{-}} \FunctionTok{estimate\_hdi}\NormalTok{(memtraces[,d.ind])}
\NormalTok{  g\_hdi     }\OtherTok{\textless{}{-}} \FunctionTok{estimate\_hdi}\NormalTok{(memtraces[,g.ind])}
\NormalTok{  sig\_hdi   }\OtherTok{\textless{}{-}} \FunctionTok{estimate\_hdi}\NormalTok{(memtraces[,sig.ind])}
\NormalTok{  bias\_hdi  }\OtherTok{\textless{}{-}} \FunctionTok{estimate\_hdi}\NormalTok{(memtraces[,bias.ind])}
\NormalTok{  theta\_hdi }\OtherTok{\textless{}{-}} \FunctionTok{estimate\_hdi}\NormalTok{(memtraces[,theta.ind])}
\NormalTok{  memMAP}\SpecialCharTok{$}\NormalTok{d\_lb[j]     }\OtherTok{\textless{}{-}}\NormalTok{ d\_hdi[}\DecValTok{1}\NormalTok{]}
\NormalTok{  memMAP}\SpecialCharTok{$}\NormalTok{g\_lb[j]     }\OtherTok{\textless{}{-}}\NormalTok{ g\_hdi[}\DecValTok{1}\NormalTok{]}
\NormalTok{  memMAP}\SpecialCharTok{$}\NormalTok{sig\_lb[j]   }\OtherTok{\textless{}{-}}\NormalTok{ sig\_hdi[}\DecValTok{1}\NormalTok{]}
\NormalTok{  memMAP}\SpecialCharTok{$}\NormalTok{bias\_lb[j]  }\OtherTok{\textless{}{-}}\NormalTok{ bias\_hdi[}\DecValTok{1}\NormalTok{]}
\NormalTok{  memMAP}\SpecialCharTok{$}\NormalTok{theta\_lb[j] }\OtherTok{\textless{}{-}}\NormalTok{ theta\_hdi[}\DecValTok{1}\NormalTok{]}
\NormalTok{  memMAP}\SpecialCharTok{$}\NormalTok{d\_ub[j]     }\OtherTok{\textless{}{-}}\NormalTok{ d\_hdi[}\DecValTok{2}\NormalTok{]}
\NormalTok{  memMAP}\SpecialCharTok{$}\NormalTok{g\_ub[j]     }\OtherTok{\textless{}{-}}\NormalTok{ g\_hdi[}\DecValTok{2}\NormalTok{]}
\NormalTok{  memMAP}\SpecialCharTok{$}\NormalTok{sig\_ub[j]   }\OtherTok{\textless{}{-}}\NormalTok{ sig\_hdi[}\DecValTok{2}\NormalTok{]}
\NormalTok{  memMAP}\SpecialCharTok{$}\NormalTok{bias\_ub[j]  }\OtherTok{\textless{}{-}}\NormalTok{ bias\_hdi[}\DecValTok{2}\NormalTok{]}
\NormalTok{  memMAP}\SpecialCharTok{$}\NormalTok{theta\_ub[j] }\OtherTok{\textless{}{-}}\NormalTok{ theta\_hdi[}\DecValTok{2}\NormalTok{]}
  
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\hypertarget{addm}{%
\section{aDDM}\label{addm}}

We need something to compare the mem-aDDM to. The obvious benchmark is the aDDM since the mem-aDDM is an attempt to improve the RT fits of the aDDM.

\hypertarget{jags-code-1}{%
\subsection{JAGS code}\label{jags-code-1}}

\(RDV_t = RDV_{t-1} + d\mu+\epsilon\)

where \(\mu=(V_L-\theta V_R)\) if looking left, and \(\mu=(\theta V_L-V_R)\) if looking right. \(\epsilon \sim N(0,\sigma)\) is white, Gaussian noise. \(\gamma\) is sensitivity to previous time spent looking at either stimuli.

Don't forget that JAGS rnorm works with precision\ldots{} so confusing keeping track of what Stan or JAGS use\ldots{}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{cat}\NormalTok{( }\StringTok{"model \{}

\StringTok{    \# drift rate}
\StringTok{        d\_mu \textasciitilde{} dunif(0.00001,50)}
\StringTok{        d\_pr \textasciitilde{} dgamma(1, 0.1)}

\StringTok{    \# noise}
\StringTok{        sig\_mu \textasciitilde{} dunif(0.000001, 2)}
\StringTok{        sig\_pr \textasciitilde{} dgamma(1, 0.1)}

\StringTok{    \# Bias of the DDM}
\StringTok{        bias\_alpha \textless{}{-} bias\_mu * bias\_kappa}
\StringTok{        bias\_beta \textless{}{-} (1 {-} bias\_mu) * bias\_kappa}
\StringTok{        bias\_mu \textasciitilde{} dbeta(2, 2)T(0.01,0.99)}
\StringTok{        bias\_kappa \textasciitilde{} dgamma(1, 0.5)}

\StringTok{    \# attentional bias}
\StringTok{        theta\_mu \textasciitilde{} dnorm(.5,.3)T(0,1)}
\StringTok{        theta\_pr \textasciitilde{} dgamma(1, 0.1)}

\StringTok{    for (p in 1:ns) \{ \# subject level}

\StringTok{        d[p] \textasciitilde{} dnorm(d\_mu, d\_pr)T(0.000001,50)}
\StringTok{        }
\StringTok{        sig[p] \textasciitilde{} dnorm(sig\_mu, sig\_pr)T(0.00001,2)}
\StringTok{        }
\StringTok{        bias[p] \textasciitilde{} dbeta(bias\_alpha, bias\_beta)T(0.01,0.99)}

\StringTok{        theta[p] \textasciitilde{} dnorm(theta\_mu, theta\_pr)T(0,1)}
\StringTok{    \}}

\StringTok{    for (i in 1:N) \{ \# trial level}

\StringTok{    \#\# WIENER model, fixing the threshold to 2 and estimating the noise}
\StringTok{        y[i] \textasciitilde{} dwieners(2, tau[i], bet[i], w[i], sig[idxP[i]] ) \# actual DDM distribution}

\StringTok{        \# generate trial{-}by{-}trial nDT}
\StringTok{        tau[i] \textless{}{-} ndt[i]}

\StringTok{        \# generate trial{-}by{-}trial Bias}
\StringTok{        bet[i] \textless{}{-} bias[idxP[i]]}

\StringTok{        \# Drift rate}
\StringTok{        w[i] \textless{}{-} d[idxP[i]] * ( (gazeL[i]*v\_L[i] {-} (1{-}gazeL[i])*v\_R[i]) + theta[idxP[i]]*((1{-}gazeL[i])*v\_L[i] {-} gazeL[i]*v\_R[i]))}

\StringTok{    \}}
\StringTok{\}"}\NormalTok{, }\AttributeTok{file=}\StringTok{"temp/mem{-}aDDM\_aDDM.txt"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\hypertarget{fit-addm}{%
\subsection{Fit aDDM}\label{fit-addm}}

Use odd trials as training data. At the end, check whether all distributions have converged with Gelman-Rubin statistics.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# initial guesses}
\NormalTok{inits1 }\OtherTok{\textless{}{-}} \FunctionTok{dump.format}\NormalTok{(}\FunctionTok{list}\NormalTok{( }
  \AttributeTok{d\_mu=}\FloatTok{0.2}\NormalTok{, }\AttributeTok{d\_pr=}\FloatTok{0.05}\NormalTok{,}
  \AttributeTok{sig\_mu=}\DecValTok{1}\NormalTok{,}\AttributeTok{sig\_pr=}\DecValTok{1}\NormalTok{,}
  \AttributeTok{bias\_mu=}\FloatTok{0.5}\NormalTok{, }\AttributeTok{bias\_kappa=}\DecValTok{1}\NormalTok{,}
  \AttributeTok{theta\_mu=}\FloatTok{0.6}\NormalTok{,}\AttributeTok{theta\_pr=}\FloatTok{0.5}\NormalTok{,}
  \AttributeTok{.RNG.name=}\StringTok{"base::Super{-}Duper"}\NormalTok{, }\AttributeTok{.RNG.seed=}\DecValTok{1}
\NormalTok{))}

\NormalTok{inits2 }\OtherTok{\textless{}{-}} \FunctionTok{dump.format}\NormalTok{(}\FunctionTok{list}\NormalTok{( }
  \AttributeTok{d\_mu=}\FloatTok{0.1}\NormalTok{, }\AttributeTok{d\_pr=}\FloatTok{0.05}\NormalTok{,}
  \AttributeTok{sig\_mu=}\DecValTok{1}\NormalTok{,}\AttributeTok{sig\_pr=}\DecValTok{1}\NormalTok{,}
  \AttributeTok{bias\_mu=}\FloatTok{0.6}\NormalTok{, }\AttributeTok{bias\_kappa=}\DecValTok{1}\NormalTok{,}
  \AttributeTok{theta\_mu=}\FloatTok{0.5}\NormalTok{,}\AttributeTok{theta\_pr=}\FloatTok{0.5}\NormalTok{,}
  \AttributeTok{.RNG.name=}\StringTok{"base::Wichmann{-}Hill"}\NormalTok{, }\AttributeTok{.RNG.seed=}\DecValTok{2}
\NormalTok{))}

\NormalTok{inits3 }\OtherTok{\textless{}{-}} \FunctionTok{dump.format}\NormalTok{(}\FunctionTok{list}\NormalTok{( }
  \AttributeTok{d\_mu=}\FloatTok{0.05}\NormalTok{, }\AttributeTok{d\_pr=}\FloatTok{0.05}\NormalTok{,}
  \AttributeTok{sig\_mu=}\DecValTok{1}\NormalTok{,}\AttributeTok{sig\_pr=}\DecValTok{1}\NormalTok{,}
  \AttributeTok{bias\_mu=}\FloatTok{0.4}\NormalTok{, }\AttributeTok{bias\_kappa=}\DecValTok{1}\NormalTok{,}
  \AttributeTok{theta\_mu=}\FloatTok{0.2}\NormalTok{,}\AttributeTok{theta\_pr=}\FloatTok{0.5}\NormalTok{,}
  \AttributeTok{.RNG.name=}\StringTok{"base::Mersenne{-}Twister"}\NormalTok{, }\AttributeTok{.RNG.seed=}\DecValTok{3}
\NormalTok{))}

\CommentTok{\# parameters to monitor}
\NormalTok{monitor }\OtherTok{=} \FunctionTok{c}\NormalTok{(}
  \StringTok{"d\_mu"}\NormalTok{, }\StringTok{"d\_pr"}\NormalTok{, }\StringTok{"d"}\NormalTok{, }\CommentTok{\# drift rate}
  \StringTok{"sig\_mu"}\NormalTok{, }\StringTok{"sig\_pr"}\NormalTok{, }\StringTok{"sig"}\NormalTok{, }\CommentTok{\# noise }
  \StringTok{"bias\_mu"}\NormalTok{, }\StringTok{"bias\_kappa"}\NormalTok{, }\StringTok{"bias"}\NormalTok{, }\CommentTok{\# bias}
  \StringTok{"theta\_mu"}\NormalTok{, }\StringTok{"theta\_pr"}\NormalTok{, }\StringTok{"theta"} \CommentTok{\# attentional discounting}
\NormalTok{)}

\CommentTok{\# run the fitting}
\FunctionTok{set.seed}\NormalTok{(seed)}
\NormalTok{results }\OtherTok{\textless{}{-}} \FunctionTok{run.jags}\NormalTok{(}
  \AttributeTok{model=}\StringTok{"temp/mem{-}aDDM\_aDDM.txt"}\NormalTok{,}
  \AttributeTok{monitor=}\NormalTok{monitor,}
  \AttributeTok{data=}\NormalTok{dat,}
  \AttributeTok{n.chains=}\DecValTok{3}\NormalTok{,}
  \AttributeTok{inits=}\FunctionTok{list}\NormalTok{(inits1,inits2,inits3),}
  \AttributeTok{plots =} \ConstantTok{TRUE}\NormalTok{,}
  \AttributeTok{method=}\StringTok{"parallel"}\NormalTok{,}
  \AttributeTok{module=}\StringTok{"wiener"}\NormalTok{,}
  \AttributeTok{burnin=}\DecValTok{15000}\NormalTok{, }\AttributeTok{sample=}\DecValTok{5000}
\NormalTok{)}

\NormalTok{aFit }\OtherTok{\textless{}{-}} \FunctionTok{add.summary}\NormalTok{(results)}

\FunctionTok{save}\NormalTok{(aFit, }\AttributeTok{file=}\StringTok{"temp/mem{-}aDDM\_aDDMfit.RData"}\NormalTok{)}

\CommentTok{\# Convergence reached?}
\NormalTok{aFit}\SpecialCharTok{$}\NormalTok{psrf}\SpecialCharTok{$}\NormalTok{mpsrf}
\end{Highlighting}
\end{Shaded}

Looks like we're in the clear.

\hypertarget{map-estimates-1}{%
\subsection{MAP estimates}\label{map-estimates-1}}

Let's get the mode and 95\% HDI for each subject's parameter estimates.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{load}\NormalTok{(}\AttributeTok{file=}\StringTok{"temp/mem{-}aDDM\_aDDMfit.RData"}\NormalTok{)}

\CommentTok{\# Get the traces}
\NormalTok{atraces }\OtherTok{\textless{}{-}} \FunctionTok{data.frame}\NormalTok{(}\FunctionTok{combine.mcmc}\NormalTok{(}\AttributeTok{mcmc.objects=}\NormalTok{aFit}\SpecialCharTok{$}\NormalTok{mcmc))}

\CommentTok{\# placeholders}
\NormalTok{aMAP }\OtherTok{\textless{}{-}} \FunctionTok{data.frame}\NormalTok{(}
  \AttributeTok{d =} \FunctionTok{unique}\NormalTok{(food}\SpecialCharTok{$}\NormalTok{SubjectNumber),}
  \AttributeTok{d\_lb =} \FunctionTok{unique}\NormalTok{(food}\SpecialCharTok{$}\NormalTok{SubjectNumber),}
  \AttributeTok{d\_ub =} \FunctionTok{unique}\NormalTok{(food}\SpecialCharTok{$}\NormalTok{SubjectNumber),}
  \AttributeTok{sig =} \FunctionTok{unique}\NormalTok{(food}\SpecialCharTok{$}\NormalTok{SubjectNumber),}
  \AttributeTok{sig\_lb =} \FunctionTok{unique}\NormalTok{(food}\SpecialCharTok{$}\NormalTok{SubjectNumber),}
  \AttributeTok{sig\_ub =} \FunctionTok{unique}\NormalTok{(food}\SpecialCharTok{$}\NormalTok{SubjectNumber),}
  \AttributeTok{bias =} \FunctionTok{unique}\NormalTok{(food}\SpecialCharTok{$}\NormalTok{SubjectNumber),}
  \AttributeTok{bias\_lb =} \FunctionTok{unique}\NormalTok{(food}\SpecialCharTok{$}\NormalTok{SubjectNumber),}
  \AttributeTok{bias\_ub =} \FunctionTok{unique}\NormalTok{(food}\SpecialCharTok{$}\NormalTok{SubjectNumber),}
  \AttributeTok{theta =} \FunctionTok{unique}\NormalTok{(food}\SpecialCharTok{$}\NormalTok{SubjectNumber),}
  \AttributeTok{theta\_lb =} \FunctionTok{unique}\NormalTok{(food}\SpecialCharTok{$}\NormalTok{SubjectNumber),}
  \AttributeTok{theta\_ub =} \FunctionTok{unique}\NormalTok{(food}\SpecialCharTok{$}\NormalTok{SubjectNumber)}
\NormalTok{)}

\ControlFlowTok{for}\NormalTok{ (j }\ControlFlowTok{in} \FunctionTok{unique}\NormalTok{(food}\SpecialCharTok{$}\NormalTok{SubjectNumber)) \{}
  
  \CommentTok{\# column names}
\NormalTok{  d.ind }\OtherTok{\textless{}{-}} \FunctionTok{paste0}\NormalTok{(}\StringTok{\textquotesingle{}d.\textquotesingle{}}\NormalTok{,}\FunctionTok{toString}\NormalTok{(j),}\StringTok{\textquotesingle{}.\textquotesingle{}}\NormalTok{)}
\NormalTok{  sig.ind }\OtherTok{\textless{}{-}} \FunctionTok{paste0}\NormalTok{(}\StringTok{\textquotesingle{}sig.\textquotesingle{}}\NormalTok{,}\FunctionTok{toString}\NormalTok{(j),}\StringTok{\textquotesingle{}.\textquotesingle{}}\NormalTok{)}
\NormalTok{  bias.ind }\OtherTok{\textless{}{-}} \FunctionTok{paste0}\NormalTok{(}\StringTok{\textquotesingle{}bias.\textquotesingle{}}\NormalTok{,}\FunctionTok{toString}\NormalTok{(j),}\StringTok{\textquotesingle{}.\textquotesingle{}}\NormalTok{)}
\NormalTok{  theta.ind }\OtherTok{\textless{}{-}} \FunctionTok{paste0}\NormalTok{(}\StringTok{\textquotesingle{}theta.\textquotesingle{}}\NormalTok{,}\FunctionTok{toString}\NormalTok{(j),}\StringTok{\textquotesingle{}.\textquotesingle{}}\NormalTok{)}
  
  \CommentTok{\# Get modes}
\NormalTok{  aMAP}\SpecialCharTok{$}\NormalTok{d[j]     }\OtherTok{\textless{}{-}} \FunctionTok{estimate\_mode}\NormalTok{(atraces[,d.ind])}
\NormalTok{  aMAP}\SpecialCharTok{$}\NormalTok{sig[j]   }\OtherTok{\textless{}{-}} \FunctionTok{estimate\_mode}\NormalTok{(atraces[,sig.ind])}
\NormalTok{  aMAP}\SpecialCharTok{$}\NormalTok{bias[j]  }\OtherTok{\textless{}{-}} \FunctionTok{estimate\_mode}\NormalTok{(atraces[,bias.ind])}
\NormalTok{  aMAP}\SpecialCharTok{$}\NormalTok{theta[j] }\OtherTok{\textless{}{-}} \FunctionTok{estimate\_mode}\NormalTok{(atraces[,theta.ind])}
  
  \CommentTok{\# Get HDIs}
\NormalTok{  d\_hdi     }\OtherTok{\textless{}{-}} \FunctionTok{estimate\_hdi}\NormalTok{(atraces[,d.ind])}
\NormalTok{  sig\_hdi   }\OtherTok{\textless{}{-}} \FunctionTok{estimate\_hdi}\NormalTok{(atraces[,sig.ind])}
\NormalTok{  bias\_hdi  }\OtherTok{\textless{}{-}} \FunctionTok{estimate\_hdi}\NormalTok{(atraces[,bias.ind])}
\NormalTok{  theta\_hdi }\OtherTok{\textless{}{-}} \FunctionTok{estimate\_hdi}\NormalTok{(atraces[,theta.ind])}
\NormalTok{  aMAP}\SpecialCharTok{$}\NormalTok{d\_lb[j]     }\OtherTok{\textless{}{-}}\NormalTok{ d\_hdi[}\DecValTok{1}\NormalTok{]}
\NormalTok{  aMAP}\SpecialCharTok{$}\NormalTok{sig\_lb[j]   }\OtherTok{\textless{}{-}}\NormalTok{ sig\_hdi[}\DecValTok{1}\NormalTok{]}
\NormalTok{  aMAP}\SpecialCharTok{$}\NormalTok{bias\_lb[j]  }\OtherTok{\textless{}{-}}\NormalTok{ bias\_hdi[}\DecValTok{1}\NormalTok{]}
\NormalTok{  aMAP}\SpecialCharTok{$}\NormalTok{theta\_lb[j] }\OtherTok{\textless{}{-}}\NormalTok{ theta\_hdi[}\DecValTok{1}\NormalTok{]}
\NormalTok{  aMAP}\SpecialCharTok{$}\NormalTok{d\_ub[j]     }\OtherTok{\textless{}{-}}\NormalTok{ d\_hdi[}\DecValTok{2}\NormalTok{]}
\NormalTok{  aMAP}\SpecialCharTok{$}\NormalTok{sig\_ub[j]   }\OtherTok{\textless{}{-}}\NormalTok{ sig\_hdi[}\DecValTok{2}\NormalTok{]}
\NormalTok{  aMAP}\SpecialCharTok{$}\NormalTok{bias\_ub[j]  }\OtherTok{\textless{}{-}}\NormalTok{ bias\_hdi[}\DecValTok{2}\NormalTok{]}
\NormalTok{  aMAP}\SpecialCharTok{$}\NormalTok{theta\_ub[j] }\OtherTok{\textless{}{-}}\NormalTok{ theta\_hdi[}\DecValTok{2}\NormalTok{]}
  
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\hypertarget{compare-predictions}{%
\section{Compare predictions}\label{compare-predictions}}

\hypertarget{mem-addm-trial-simulation}{%
\subsection{mem-aDDM trial simulation}\label{mem-addm-trial-simulation}}

Write a function that simulates behavior (choice, rt) for a single trial using the mem-aDDM. It will take as inputs parameters to the mem-aDDM and fixation properties (e.g.~probability of first fixating left which is a scalar, or middle fixations which is the distribution of all middle fixations for that subject from the testing set).

This is code taken from \citep{eum2022}, which is code based on \citep{lombardi2021}.

Note that the mem-aDDM nests the original aDDM. If you want to run an aDDM trial, all you need to do is feed in g=c(0). This eliminates any effect of previous encounter in the algorithm!

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mem.sim.trial }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(b, d, g, t, s, vL, vR, pe, prFirstLeft, firstFix, middleFix, latency, transition) \{}
  
  \DocumentationTok{\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#}
  \CommentTok{\# create a variable to track when to stop (for efficiency purposes)}
\NormalTok{  stopper }\OtherTok{\textless{}{-}} \DecValTok{0}
  
  \DocumentationTok{\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#}
  \CommentTok{\# initialize rdv at bias point}
\NormalTok{  RDV }\OtherTok{\textless{}{-}}\NormalTok{ b}
\NormalTok{  rt  }\OtherTok{\textless{}{-}} \DecValTok{0}
  
  \DocumentationTok{\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#}
  \CommentTok{\# latency to first fixation}
\NormalTok{  latencyDur }\OtherTok{\textless{}{-}} \FunctionTok{sample}\NormalTok{(latency,}\DecValTok{1}\NormalTok{)}
\NormalTok{  latency\_err }\OtherTok{\textless{}{-}} \FunctionTok{rnorm}\NormalTok{(}\AttributeTok{n=}\NormalTok{latencyDur, }\AttributeTok{mean=}\DecValTok{0}\NormalTok{, }\AttributeTok{sd=}\NormalTok{s)}
  
  \ControlFlowTok{if}\NormalTok{ (}\FunctionTok{abs}\NormalTok{(RDV}\SpecialCharTok{+}\FunctionTok{sum}\NormalTok{(latency\_err))}\SpecialCharTok{\textgreater{}=}\DecValTok{1}\NormalTok{) \{}
    \ControlFlowTok{for}\NormalTok{ (t }\ControlFlowTok{in} \DecValTok{1}\SpecialCharTok{:}\NormalTok{latencyDur) \{}
\NormalTok{      RDV }\OtherTok{\textless{}{-}}\NormalTok{ RDV }\SpecialCharTok{+}\NormalTok{ latency\_err[t]}
\NormalTok{      rt }\OtherTok{\textless{}{-}}\NormalTok{ rt }\SpecialCharTok{+} \DecValTok{1}
\NormalTok{      lastLoc }\OtherTok{\textless{}{-}} \DecValTok{4}
      \ControlFlowTok{if}\NormalTok{ (}\FunctionTok{abs}\NormalTok{(RDV)}\SpecialCharTok{\textgreater{}=}\DecValTok{1}\NormalTok{) \{stopper}\OtherTok{\textless{}{-}}\DecValTok{1}\NormalTok{; }\ControlFlowTok{break}\NormalTok{\}}
\NormalTok{    \}}
\NormalTok{  \} }\ControlFlowTok{else}\NormalTok{ \{}
\NormalTok{    RDV }\OtherTok{\textless{}{-}}\NormalTok{ RDV }\SpecialCharTok{+} \FunctionTok{sum}\NormalTok{(latency\_err)}
\NormalTok{    rt }\OtherTok{\textless{}{-}}\NormalTok{ rt }\SpecialCharTok{+}\NormalTok{ latencyDur}
\NormalTok{  \}}
  
  \DocumentationTok{\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#}
  \CommentTok{\# first fixation}
  \ControlFlowTok{if}\NormalTok{ (stopper}\SpecialCharTok{==}\DecValTok{0}\NormalTok{) \{}
\NormalTok{    firstDur }\OtherTok{\textless{}{-}} \FunctionTok{sample}\NormalTok{(firstFix,}\DecValTok{1}\NormalTok{)}
\NormalTok{    loc }\OtherTok{\textless{}{-}} \FunctionTok{rbinom}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{1}\NormalTok{,prFirstLeft)}
    \ControlFlowTok{if}\NormalTok{ (loc}\SpecialCharTok{==}\DecValTok{1}\NormalTok{) \{drift\_mean }\OtherTok{\textless{}{-}}\NormalTok{ (d}\SpecialCharTok{+}\NormalTok{g}\SpecialCharTok{*}\NormalTok{pe)}\SpecialCharTok{*}\NormalTok{(vL}\SpecialCharTok{{-}}\NormalTok{t}\SpecialCharTok{*}\NormalTok{vR)\}}
    \ControlFlowTok{if}\NormalTok{ (loc}\SpecialCharTok{==}\DecValTok{0}\NormalTok{) \{drift\_mean }\OtherTok{\textless{}{-}}\NormalTok{ (d}\SpecialCharTok{+}\NormalTok{g}\SpecialCharTok{*}\NormalTok{pe)}\SpecialCharTok{*}\NormalTok{(t}\SpecialCharTok{*}\NormalTok{vL}\SpecialCharTok{{-}}\NormalTok{vR)\}}
\NormalTok{    drift }\OtherTok{\textless{}{-}}\NormalTok{ drift\_mean }\SpecialCharTok{+} \FunctionTok{rnorm}\NormalTok{(}\AttributeTok{n=}\NormalTok{firstDur, }\AttributeTok{mean=}\DecValTok{0}\NormalTok{, }\AttributeTok{sd=}\NormalTok{s)}
  
    \ControlFlowTok{if}\NormalTok{ (}\FunctionTok{abs}\NormalTok{(RDV}\SpecialCharTok{+}\FunctionTok{sum}\NormalTok{(drift))}\SpecialCharTok{\textgreater{}=}\DecValTok{1}\NormalTok{) \{}
      \ControlFlowTok{for}\NormalTok{ (t }\ControlFlowTok{in} \DecValTok{1}\SpecialCharTok{:}\NormalTok{firstDur) \{}
\NormalTok{        RDV }\OtherTok{\textless{}{-}}\NormalTok{ RDV }\SpecialCharTok{+}\NormalTok{ drift[t]}
\NormalTok{        rt }\OtherTok{\textless{}{-}}\NormalTok{ rt }\SpecialCharTok{+} \DecValTok{1}
\NormalTok{        lastLoc }\OtherTok{\textless{}{-}}\NormalTok{ loc}
        \ControlFlowTok{if}\NormalTok{ (}\FunctionTok{abs}\NormalTok{(RDV)}\SpecialCharTok{\textgreater{}=}\DecValTok{1}\NormalTok{) \{stopper}\OtherTok{\textless{}{-}}\DecValTok{1}\NormalTok{; }\ControlFlowTok{break}\NormalTok{\}}
\NormalTok{      \}}
\NormalTok{    \} }\ControlFlowTok{else}\NormalTok{ \{}
\NormalTok{      RDV }\OtherTok{\textless{}{-}}\NormalTok{ RDV }\SpecialCharTok{+} \FunctionTok{sum}\NormalTok{(drift)}
\NormalTok{      rt }\OtherTok{\textless{}{-}}\NormalTok{ rt }\SpecialCharTok{+}\NormalTok{ firstDur}
\NormalTok{      prevLoc }\OtherTok{\textless{}{-}}\NormalTok{ loc}
\NormalTok{    \}}
\NormalTok{  \}}
  
  \DocumentationTok{\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#}
  \CommentTok{\# transitions and middle fixations until choice is made}
  \ControlFlowTok{while}\NormalTok{ (}\FunctionTok{abs}\NormalTok{(RDV)}\SpecialCharTok{\textless{}}\DecValTok{1}\NormalTok{) \{}
\NormalTok{    transDur }\OtherTok{\textless{}{-}} \FunctionTok{sample}\NormalTok{(transition,}\DecValTok{1}\NormalTok{)}
\NormalTok{    trans\_err }\OtherTok{\textless{}{-}} \FunctionTok{rnorm}\NormalTok{(}\AttributeTok{n=}\NormalTok{transDur, }\AttributeTok{mean=}\DecValTok{0}\NormalTok{, }\AttributeTok{sd=}\NormalTok{s)}
    
    \ControlFlowTok{if}\NormalTok{ (}\FunctionTok{abs}\NormalTok{(RDV}\SpecialCharTok{+}\FunctionTok{sum}\NormalTok{(trans\_err))}\SpecialCharTok{\textgreater{}=}\DecValTok{1}\NormalTok{) \{}
      \ControlFlowTok{for}\NormalTok{ (t }\ControlFlowTok{in} \DecValTok{1}\SpecialCharTok{:}\NormalTok{transDur) \{}
\NormalTok{        RDV }\OtherTok{\textless{}{-}}\NormalTok{ RDV }\SpecialCharTok{+}\NormalTok{ trans\_err[t]}
\NormalTok{        rt }\OtherTok{\textless{}{-}}\NormalTok{ rt }\SpecialCharTok{+} \DecValTok{1}
\NormalTok{        lastLoc }\OtherTok{\textless{}{-}}\NormalTok{ prevLoc}
        \ControlFlowTok{if}\NormalTok{ (}\FunctionTok{abs}\NormalTok{(RDV)}\SpecialCharTok{\textgreater{}=}\DecValTok{1}\NormalTok{) \{stopper}\OtherTok{\textless{}{-}}\DecValTok{1}\NormalTok{; }\ControlFlowTok{break}\NormalTok{\}}
\NormalTok{      \}}
\NormalTok{    \} }\ControlFlowTok{else}\NormalTok{ \{}
\NormalTok{      RDV }\OtherTok{\textless{}{-}}\NormalTok{ RDV }\SpecialCharTok{+} \FunctionTok{sum}\NormalTok{(trans\_err)}
\NormalTok{      rt }\OtherTok{\textless{}{-}}\NormalTok{ rt }\SpecialCharTok{+}\NormalTok{ transDur}
\NormalTok{    \}}
    
    \ControlFlowTok{if}\NormalTok{ (stopper}\SpecialCharTok{==}\DecValTok{0}\NormalTok{) \{}
\NormalTok{      middleDur }\OtherTok{\textless{}{-}} \FunctionTok{sample}\NormalTok{(middleFix,}\DecValTok{1}\NormalTok{)}
      \ControlFlowTok{if}\NormalTok{ (prevLoc}\SpecialCharTok{==}\DecValTok{1}\NormalTok{) \{loc}\OtherTok{\textless{}{-}}\DecValTok{0}\NormalTok{\}}
      \ControlFlowTok{if}\NormalTok{ (prevLoc}\SpecialCharTok{==}\DecValTok{0}\NormalTok{) \{loc}\OtherTok{\textless{}{-}}\DecValTok{1}\NormalTok{\}}
      \ControlFlowTok{if}\NormalTok{ (loc}\SpecialCharTok{==}\DecValTok{1}\NormalTok{) \{drift\_mean }\OtherTok{\textless{}{-}}\NormalTok{ (d}\SpecialCharTok{+}\NormalTok{g}\SpecialCharTok{*}\NormalTok{pe)}\SpecialCharTok{*}\NormalTok{(vL}\SpecialCharTok{{-}}\NormalTok{t}\SpecialCharTok{*}\NormalTok{vR)\}}
      \ControlFlowTok{if}\NormalTok{ (loc}\SpecialCharTok{==}\DecValTok{0}\NormalTok{) \{drift\_mean }\OtherTok{\textless{}{-}}\NormalTok{ (d}\SpecialCharTok{+}\NormalTok{g}\SpecialCharTok{*}\NormalTok{pe)}\SpecialCharTok{*}\NormalTok{(t}\SpecialCharTok{*}\NormalTok{vL}\SpecialCharTok{{-}}\NormalTok{vR)\}}
\NormalTok{      drift }\OtherTok{\textless{}{-}}\NormalTok{ drift\_mean }\SpecialCharTok{+} \FunctionTok{rnorm}\NormalTok{(}\AttributeTok{n=}\NormalTok{middleDur, }\AttributeTok{mean=}\DecValTok{0}\NormalTok{, }\AttributeTok{sd=}\NormalTok{s)}
    
      \ControlFlowTok{if}\NormalTok{ (}\FunctionTok{abs}\NormalTok{(RDV}\SpecialCharTok{+}\FunctionTok{sum}\NormalTok{(drift))}\SpecialCharTok{\textgreater{}=}\DecValTok{1}\NormalTok{) \{}
        \ControlFlowTok{for}\NormalTok{ (t }\ControlFlowTok{in} \DecValTok{1}\SpecialCharTok{:}\NormalTok{middleDur) \{}
\NormalTok{          RDV }\OtherTok{\textless{}{-}}\NormalTok{ RDV }\SpecialCharTok{+}\NormalTok{ drift[t]}
\NormalTok{          rt }\OtherTok{\textless{}{-}}\NormalTok{ rt }\SpecialCharTok{+} \DecValTok{1}
\NormalTok{          lastLoc }\OtherTok{\textless{}{-}}\NormalTok{ loc}
          \ControlFlowTok{if}\NormalTok{ (}\FunctionTok{abs}\NormalTok{(RDV)}\SpecialCharTok{\textgreater{}=}\DecValTok{1}\NormalTok{) \{}\ControlFlowTok{break}\NormalTok{\}}
\NormalTok{        \}}
\NormalTok{      \} }\ControlFlowTok{else}\NormalTok{ \{}
\NormalTok{        RDV }\OtherTok{\textless{}{-}}\NormalTok{ RDV }\SpecialCharTok{+} \FunctionTok{sum}\NormalTok{(drift)}
\NormalTok{        rt }\OtherTok{\textless{}{-}}\NormalTok{ rt }\SpecialCharTok{+}\NormalTok{ middleDur}
\NormalTok{        prevLoc }\OtherTok{\textless{}{-}}\NormalTok{ loc}
\NormalTok{      \}}
\NormalTok{    \}}
\NormalTok{  \}}

  \DocumentationTok{\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#}
  \CommentTok{\# return your results}
  \ControlFlowTok{if}\NormalTok{ (RDV}\SpecialCharTok{\textgreater{}}\DecValTok{0}\NormalTok{) \{choice }\OtherTok{\textless{}{-}} \DecValTok{1}\NormalTok{\}}
  \ControlFlowTok{if}\NormalTok{ (RDV}\SpecialCharTok{\textless{}}\DecValTok{0}\NormalTok{) \{choice }\OtherTok{\textless{}{-}} \DecValTok{0}\NormalTok{\}}
\NormalTok{  vDiff }\OtherTok{\textless{}{-}}\NormalTok{ vL}\SpecialCharTok{*}\DecValTok{10}\SpecialCharTok{{-}}\NormalTok{vR}\SpecialCharTok{*}\DecValTok{10}
\NormalTok{  results }\OtherTok{\textless{}{-}} \FunctionTok{data.frame}\NormalTok{(}\AttributeTok{choice=}\NormalTok{choice, }\AttributeTok{rt=}\NormalTok{rt}\SpecialCharTok{/}\DecValTok{1000}\NormalTok{, }\AttributeTok{vL=}\NormalTok{vL}\SpecialCharTok{*}\DecValTok{10}\NormalTok{, }\AttributeTok{vR=}\NormalTok{vR}\SpecialCharTok{*}\DecValTok{10}\NormalTok{, }\AttributeTok{vDiff=}\NormalTok{vDiff, }\AttributeTok{lastFix=}\NormalTok{lastLoc)}
  \FunctionTok{return}\NormalTok{(results)}
  
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\hypertarget{out-of-sample-predictions}{%
\subsection{Out-of-sample predictions}\label{out-of-sample-predictions}}

Simulate

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{simCount }\OtherTok{=} \DecValTok{20}
\FunctionTok{set.seed}\NormalTok{(seed)}

\CommentTok{\# fixation data from out{-}of{-}sample}
\NormalTok{fixeven }\OtherTok{\textless{}{-}}\NormalTok{ food[food}\SpecialCharTok{$}\NormalTok{Trial}\SpecialCharTok{\%\%}\DecValTok{2}\SpecialCharTok{==}\DecValTok{0}\NormalTok{,]}

\CommentTok{\# Placeholders}
\NormalTok{vL }\OtherTok{\textless{}{-}} \FunctionTok{list}\NormalTok{()}
\NormalTok{vR }\OtherTok{\textless{}{-}} \FunctionTok{list}\NormalTok{()}
\NormalTok{pe }\OtherTok{\textless{}{-}} \FunctionTok{list}\NormalTok{()}
\NormalTok{d }\OtherTok{\textless{}{-}} \FunctionTok{list}\NormalTok{()}
\NormalTok{g }\OtherTok{\textless{}{-}} \FunctionTok{list}\NormalTok{()}
\NormalTok{sig }\OtherTok{\textless{}{-}} \FunctionTok{list}\NormalTok{()}
\NormalTok{theta }\OtherTok{\textless{}{-}} \FunctionTok{list}\NormalTok{()}
\NormalTok{bias }\OtherTok{\textless{}{-}} \FunctionTok{list}\NormalTok{()}
\NormalTok{prFirstLeft }\OtherTok{\textless{}{-}} \FunctionTok{list}\NormalTok{()}
\NormalTok{latency }\OtherTok{\textless{}{-}} \FunctionTok{list}\NormalTok{()}
\NormalTok{firstFix }\OtherTok{\textless{}{-}} \FunctionTok{list}\NormalTok{()}
\NormalTok{transition }\OtherTok{\textless{}{-}} \FunctionTok{list}\NormalTok{()}
\NormalTok{middleFix }\OtherTok{\textless{}{-}} \FunctionTok{list}\NormalTok{()}

\NormalTok{mem.sim }\OtherTok{\textless{}{-}} \FunctionTok{data.frame}\NormalTok{(}
  \AttributeTok{subj =} \ConstantTok{NA}\NormalTok{,}
  \AttributeTok{trial =} \ConstantTok{NA}\NormalTok{,}
  \AttributeTok{choice =} \ConstantTok{NA}\NormalTok{,}
  \AttributeTok{choice.a =} \ConstantTok{NA}\NormalTok{,}
  \AttributeTok{rt =} \ConstantTok{NA}\NormalTok{,}
  \AttributeTok{rt.a=}\ConstantTok{NA}\NormalTok{,}
  \AttributeTok{vL =} \ConstantTok{NA}\NormalTok{,}
  \AttributeTok{vR =} \ConstantTok{NA}\NormalTok{,}
  \AttributeTok{vDiff =} \ConstantTok{NA}\NormalTok{,}
  \AttributeTok{simulation =} \ConstantTok{NA}\NormalTok{,}
  \AttributeTok{lastFix =} \ConstantTok{NA}\NormalTok{,}
  \AttributeTok{lastFix.a =} \ConstantTok{NA}\NormalTok{,}
  \AttributeTok{pe=}\ConstantTok{NA}
\NormalTok{)}

\CommentTok{\# Loop through subjects to get everyone\textquotesingle{}s choices and RT}
\ControlFlowTok{for}\NormalTok{ (sub }\ControlFlowTok{in} \FunctionTok{sort}\NormalTok{(}\FunctionTok{unique}\NormalTok{(test}\SpecialCharTok{$}\NormalTok{subject))) \{}
  
  \CommentTok{\# Progress tracker}
  \FunctionTok{print}\NormalTok{(sub)}
  
  \CommentTok{\# gather relevant data}
\NormalTok{  subjdata }\OtherTok{\textless{}{-}}\NormalTok{ test[test}\SpecialCharTok{$}\NormalTok{subject}\SpecialCharTok{==}\NormalTok{sub,]}
\NormalTok{  vL[[sub]] }\OtherTok{\textless{}{-}}\NormalTok{ subjdata}\SpecialCharTok{$}\NormalTok{v\_L}
\NormalTok{  vR[[sub]] }\OtherTok{\textless{}{-}}\NormalTok{ subjdata}\SpecialCharTok{$}\NormalTok{v\_R}
\NormalTok{  pe[[sub]] }\OtherTok{\textless{}{-}}\NormalTok{ subjdata}\SpecialCharTok{$}\NormalTok{pe}
  
\NormalTok{  d.ind }\OtherTok{\textless{}{-}} \FunctionTok{paste0}\NormalTok{(}\StringTok{\textquotesingle{}d.\textquotesingle{}}\NormalTok{,}\FunctionTok{toString}\NormalTok{(sub),}\StringTok{\textquotesingle{}.\textquotesingle{}}\NormalTok{)}
\NormalTok{  g.ind }\OtherTok{\textless{}{-}} \FunctionTok{paste0}\NormalTok{(}\StringTok{\textquotesingle{}g.\textquotesingle{}}\NormalTok{,}\FunctionTok{toString}\NormalTok{(sub),}\StringTok{\textquotesingle{}.\textquotesingle{}}\NormalTok{)}
\NormalTok{  sig.ind }\OtherTok{\textless{}{-}} \FunctionTok{paste0}\NormalTok{(}\StringTok{\textquotesingle{}sig.\textquotesingle{}}\NormalTok{,}\FunctionTok{toString}\NormalTok{(sub),}\StringTok{\textquotesingle{}.\textquotesingle{}}\NormalTok{)}
\NormalTok{  bias.ind }\OtherTok{\textless{}{-}} \FunctionTok{paste0}\NormalTok{(}\StringTok{\textquotesingle{}bias.\textquotesingle{}}\NormalTok{,}\FunctionTok{toString}\NormalTok{(sub),}\StringTok{\textquotesingle{}.\textquotesingle{}}\NormalTok{)}
\NormalTok{  theta.ind }\OtherTok{\textless{}{-}} \FunctionTok{paste0}\NormalTok{(}\StringTok{\textquotesingle{}theta.\textquotesingle{}}\NormalTok{,}\FunctionTok{toString}\NormalTok{(sub),}\StringTok{\textquotesingle{}.\textquotesingle{}}\NormalTok{)}
  
  \CommentTok{\# convert all parameters to 1 ms timestep (originally in 1 s timestep)}
\NormalTok{  d[[sub]]     }\OtherTok{\textless{}{-}} \FunctionTok{sample}\NormalTok{(memtraces[,d.ind], simCount)}\SpecialCharTok{/}\DecValTok{1000}
\NormalTok{  g[[sub]]     }\OtherTok{\textless{}{-}} \FunctionTok{sample}\NormalTok{(memtraces[,g.ind], simCount)}\SpecialCharTok{/}\DecValTok{1000}
\NormalTok{  sig[[sub]]   }\OtherTok{\textless{}{-}} \FunctionTok{sample}\NormalTok{(memtraces[,sig.ind], simCount)}\SpecialCharTok{/}\FunctionTok{sqrt}\NormalTok{(}\DecValTok{1000}\NormalTok{)}
\NormalTok{  bias[[sub]]  }\OtherTok{\textless{}{-}}\NormalTok{ (}\FunctionTok{sample}\NormalTok{(memtraces[,bias.ind], simCount)}\SpecialCharTok{{-}}\FloatTok{0.5}\NormalTok{)}\SpecialCharTok{*}\DecValTok{2}
\NormalTok{  theta[[sub]] }\OtherTok{\textless{}{-}} \FunctionTok{sample}\NormalTok{(memtraces[,theta.ind], simCount) }
  
\NormalTok{  subjfix }\OtherTok{\textless{}{-}}\NormalTok{ fixeven[fixeven}\SpecialCharTok{$}\NormalTok{SubjectNumber}\SpecialCharTok{==}\NormalTok{sub,]}
\NormalTok{  prFirstLeft[[sub]] }\OtherTok{\textless{}{-}} \FunctionTok{mean}\NormalTok{( (subjfix}\SpecialCharTok{$}\NormalTok{ROI[subjfix}\SpecialCharTok{$}\NormalTok{fixNum}\SpecialCharTok{==}\DecValTok{1}\NormalTok{]}\SpecialCharTok{==}\DecValTok{1}\NormalTok{) ,}\AttributeTok{na.rm=}\NormalTok{T)}
\NormalTok{  latency[[sub]] }\OtherTok{\textless{}{-}}\NormalTok{ test}\SpecialCharTok{$}\NormalTok{ndt }\CommentTok{\#capturing both latency and transitions}
\NormalTok{  firstFix[[sub]] }\OtherTok{\textless{}{-}} \FunctionTok{round}\NormalTok{(subjfix}\SpecialCharTok{$}\NormalTok{DwellLength[subjfix}\SpecialCharTok{$}\NormalTok{fixNum}\SpecialCharTok{==}\DecValTok{1}\NormalTok{]}\SpecialCharTok{*}\DecValTok{1000}\NormalTok{,}\DecValTok{0}\NormalTok{)}
\NormalTok{  transition[[sub]] }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{)}
\NormalTok{  middleFix[[sub]] }\OtherTok{\textless{}{-}} \FunctionTok{round}\NormalTok{(subjfix}\SpecialCharTok{$}\NormalTok{DwellLength[subjfix}\SpecialCharTok{$}\NormalTok{middleFix}\SpecialCharTok{==}\DecValTok{1}\NormalTok{]}\SpecialCharTok{*}\DecValTok{1000}\NormalTok{,}\DecValTok{0}\NormalTok{)}
  
  \CommentTok{\# Simulate dataset}
  \ControlFlowTok{for}\NormalTok{ (j }\ControlFlowTok{in} \DecValTok{1}\SpecialCharTok{:}\NormalTok{simCount) \{}
    \ControlFlowTok{for}\NormalTok{ (i }\ControlFlowTok{in} \DecValTok{1}\SpecialCharTok{:}\FunctionTok{length}\NormalTok{(vL[[sub]])) \{}
      
\NormalTok{      simTrial }\OtherTok{\textless{}{-}} \FunctionTok{mem.sim.trial}\NormalTok{(}
          \AttributeTok{b =}\NormalTok{ bias[[sub]][j],}
          \AttributeTok{d =}\NormalTok{ d[[sub]][j],}
          \AttributeTok{g =}\NormalTok{ g[[sub]][j],}
          \AttributeTok{t =}\NormalTok{ theta[[sub]][j],}
          \AttributeTok{s =}\NormalTok{ sig[[sub]][j],}
          \AttributeTok{vL =}\NormalTok{ vL[[sub]][i],}
          \AttributeTok{vR =}\NormalTok{ vR[[sub]][i],}
          \AttributeTok{pe =}\NormalTok{ pe[[sub]][[i]],}
          \AttributeTok{prFirstLeft =}\NormalTok{ prFirstLeft[[sub]],}
          \AttributeTok{latency =}\NormalTok{ latency[[sub]],}
          \AttributeTok{transition =}\NormalTok{ transition[[sub]],}
          \AttributeTok{firstFix =}\NormalTok{ firstFix[[sub]],}
          \AttributeTok{middleFix =}\NormalTok{ middleFix[[sub]]}
\NormalTok{      )}
      
\NormalTok{      asimTrial }\OtherTok{\textless{}{-}} \FunctionTok{mem.sim.trial}\NormalTok{(}
          \AttributeTok{b =}\NormalTok{ bias[[sub]][j],}
          \AttributeTok{d =}\NormalTok{ d[[sub]][j],}
          \AttributeTok{g =} \FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{), }\CommentTok{\# again, aDDM is nested in mem{-}aDDM (i.e. g=0).}
          \AttributeTok{t =}\NormalTok{ theta[[sub]][j],}
          \AttributeTok{s =}\NormalTok{ sig[[sub]][j],}
          \AttributeTok{vL =}\NormalTok{ vL[[sub]][i],}
          \AttributeTok{vR =}\NormalTok{ vR[[sub]][i],}
          \AttributeTok{pe =} \FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{),}
          \AttributeTok{prFirstLeft =}\NormalTok{ prFirstLeft[[sub]],}
          \AttributeTok{latency =}\NormalTok{ latency[[sub]],}
          \AttributeTok{transition =}\NormalTok{ transition[[sub]],}
          \AttributeTok{firstFix =}\NormalTok{ firstFix[[sub]],}
          \AttributeTok{middleFix =}\NormalTok{ middleFix[[sub]]}
\NormalTok{      )}
\NormalTok{      simTrial}\SpecialCharTok{$}\NormalTok{choice.a }\OtherTok{\textless{}{-}}\NormalTok{ asimTrial}\SpecialCharTok{$}\NormalTok{choice}
\NormalTok{      simTrial}\SpecialCharTok{$}\NormalTok{rt.a }\OtherTok{\textless{}{-}}\NormalTok{ asimTrial}\SpecialCharTok{$}\NormalTok{rt}
\NormalTok{      simTrial}\SpecialCharTok{$}\NormalTok{lastFix.a }\OtherTok{\textless{}{-}}\NormalTok{ asimTrial}\SpecialCharTok{$}\NormalTok{lastFix}
      
\NormalTok{      simTrial}\SpecialCharTok{$}\NormalTok{subj }\OtherTok{\textless{}{-}}\NormalTok{ sub}
\NormalTok{      simTrial}\SpecialCharTok{$}\NormalTok{trial }\OtherTok{\textless{}{-}}\NormalTok{ i}
\NormalTok{      simTrial}\SpecialCharTok{$}\NormalTok{simulation }\OtherTok{\textless{}{-}}\NormalTok{ j}
\NormalTok{      simTrial}\SpecialCharTok{$}\NormalTok{pe }\OtherTok{\textless{}{-}}\NormalTok{ pe[[sub]][[i]]}
\NormalTok{      mem.sim }\OtherTok{\textless{}{-}} \FunctionTok{rbind}\NormalTok{(mem.sim, simTrial)}
\NormalTok{    \}}
\NormalTok{  \}}
\NormalTok{\}}
\NormalTok{mem.sim }\OtherTok{\textless{}{-}} \FunctionTok{na.omit}\NormalTok{(mem.sim)}

\FunctionTok{save}\NormalTok{(mem.sim, }\AttributeTok{file=}\StringTok{"temp/mem{-}aDDM\_sim.RData"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

I want two plots, each with 3 lines. One plot for choices. One plot for RTs. One line will show true out-of-sample data. One line will show mem-aDDM predictions for those exact same trials. One line will show aDDM predictions for those exact same trials. Run 20 simulations.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{load}\NormalTok{(}\AttributeTok{file=}\StringTok{"temp/mem{-}aDDM\_sim.RData"}\NormalTok{)}

\NormalTok{pdata.real }\OtherTok{\textless{}{-}}\NormalTok{ test }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{group\_by}\NormalTok{(subject, vDiff) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{summarize}\NormalTok{(}
    \AttributeTok{choices =} \FunctionTok{mean}\NormalTok{(choice, }\AttributeTok{na.rm=}\NormalTok{T),}
    \AttributeTok{rts =} \FunctionTok{mean}\NormalTok{(rt, }\AttributeTok{na.rm=}\NormalTok{T)}
\NormalTok{  ) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{ungroup}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{group\_by}\NormalTok{(vDiff) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{summarize}\NormalTok{(}
    \AttributeTok{choice.mean =} \FunctionTok{mean}\NormalTok{(choices, }\AttributeTok{na.rm=}\NormalTok{T),}
    \AttributeTok{choice.se =} \FunctionTok{std.error}\NormalTok{(choices, }\AttributeTok{na.rm=}\NormalTok{T),}
    \AttributeTok{rt.mean =} \FunctionTok{mean}\NormalTok{(rts, }\AttributeTok{na.rm=}\NormalTok{T),}
    \AttributeTok{rt.se =} \FunctionTok{std.error}\NormalTok{(rts, }\AttributeTok{na.rm=}\NormalTok{T),}
    \AttributeTok{Dataset =} \DecValTok{0}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## `summarise()` has grouped output by 'subject'. You can override using the
## `.groups` argument.
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pdata.real}\SpecialCharTok{$}\NormalTok{vDiff }\OtherTok{\textless{}{-}}\NormalTok{ pdata.real}\SpecialCharTok{$}\NormalTok{vDiff}\SpecialCharTok{*}\DecValTok{10}
\NormalTok{pdata.mem }\OtherTok{\textless{}{-}}\NormalTok{ mem.sim }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{group\_by}\NormalTok{(subj, vDiff) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{summarize}\NormalTok{(}
    \AttributeTok{choices =} \FunctionTok{mean}\NormalTok{(choice, }\AttributeTok{na.rm=}\NormalTok{T),}
    \AttributeTok{rts =} \FunctionTok{mean}\NormalTok{(rt, }\AttributeTok{na.rm=}\NormalTok{T)}
\NormalTok{  ) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{ungroup}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{group\_by}\NormalTok{(vDiff) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{summarize}\NormalTok{(}
    \AttributeTok{choice.mean =} \FunctionTok{mean}\NormalTok{(choices, }\AttributeTok{na.rm=}\NormalTok{T),}
    \AttributeTok{choice.se =} \FunctionTok{std.error}\NormalTok{(choices, }\AttributeTok{na.rm=}\NormalTok{T),}
    \AttributeTok{rt.mean =} \FunctionTok{mean}\NormalTok{(rts, }\AttributeTok{na.rm=}\NormalTok{T),}
    \AttributeTok{rt.se =} \FunctionTok{std.error}\NormalTok{(rts, }\AttributeTok{na.rm=}\NormalTok{T),}
    \AttributeTok{Dataset =} \DecValTok{1}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## `summarise()` has grouped output by 'subj'. You can override using the
## `.groups` argument.
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pdata.a }\OtherTok{\textless{}{-}}\NormalTok{ mem.sim }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{group\_by}\NormalTok{(subj, vDiff) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{summarize}\NormalTok{(}
    \AttributeTok{choices =} \FunctionTok{mean}\NormalTok{(choice.a, }\AttributeTok{na.rm=}\NormalTok{T),}
    \AttributeTok{rts =} \FunctionTok{mean}\NormalTok{(rt.a, }\AttributeTok{na.rm=}\NormalTok{T)}
\NormalTok{  ) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{ungroup}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{group\_by}\NormalTok{(vDiff) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{summarize}\NormalTok{(}
    \AttributeTok{choice.mean =} \FunctionTok{mean}\NormalTok{(choices, }\AttributeTok{na.rm=}\NormalTok{T),}
    \AttributeTok{choice.se =} \FunctionTok{std.error}\NormalTok{(choices, }\AttributeTok{na.rm=}\NormalTok{T),}
    \AttributeTok{rt.mean =} \FunctionTok{mean}\NormalTok{(rts, }\AttributeTok{na.rm=}\NormalTok{T),}
    \AttributeTok{rt.se =} \FunctionTok{std.error}\NormalTok{(rts, }\AttributeTok{na.rm=}\NormalTok{T),}
    \AttributeTok{Dataset =} \DecValTok{2}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## `summarise()` has grouped output by 'subj'. You can override using the
## `.groups` argument.
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pdata }\OtherTok{\textless{}{-}} \FunctionTok{rbind}\NormalTok{(pdata.real, pdata.mem)}
\NormalTok{pdata }\OtherTok{\textless{}{-}} \FunctionTok{rbind}\NormalTok{(pdata, pdata.a)}
\NormalTok{pdata}\SpecialCharTok{$}\NormalTok{Dataset }\OtherTok{\textless{}{-}} \FunctionTok{factor}\NormalTok{(pdata}\SpecialCharTok{$}\NormalTok{Dataset, }\AttributeTok{levels=}\FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{), }\AttributeTok{labels=}\FunctionTok{c}\NormalTok{(}\StringTok{"Data"}\NormalTok{,}\StringTok{"mem{-}aDDM Sim."}\NormalTok{,}\StringTok{"aDDM Sim."}\NormalTok{))}

\NormalTok{mem.choice.plot }\OtherTok{\textless{}{-}} \FunctionTok{ggplot}\NormalTok{(}\AttributeTok{data=}\NormalTok{pdata, }\FunctionTok{aes}\NormalTok{(}\AttributeTok{x=}\NormalTok{vDiff)) }\SpecialCharTok{+}
  \FunctionTok{geom\_hline}\NormalTok{(}\AttributeTok{yintercept=}\FloatTok{0.5}\NormalTok{, }\AttributeTok{color=}\StringTok{\textquotesingle{}grey\textquotesingle{}}\NormalTok{, }\AttributeTok{alpha=}\FloatTok{0.75}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{geom\_vline}\NormalTok{(}\AttributeTok{xintercept=}\DecValTok{0}\NormalTok{, }\AttributeTok{color=}\StringTok{\textquotesingle{}grey\textquotesingle{}}\NormalTok{, }\AttributeTok{alpha=}\FloatTok{0.75}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{geom\_line}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{y=}\NormalTok{choice.mean, }\AttributeTok{group=}\NormalTok{Dataset, }\AttributeTok{color=}\NormalTok{Dataset), }\AttributeTok{size=}\DecValTok{2}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{geom\_ribbon}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{ymin=}\NormalTok{choice.mean}\SpecialCharTok{{-}}\NormalTok{choice.se, }\AttributeTok{ymax=}\NormalTok{choice.mean}\SpecialCharTok{+}\NormalTok{choice.se, }\AttributeTok{group=}\NormalTok{Dataset, }\AttributeTok{fill=}\NormalTok{Dataset), }\AttributeTok{alpha=}\NormalTok{.}\DecValTok{2}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{ylab}\NormalTok{(}\StringTok{"P(choose left)"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{xlab}\NormalTok{(}\StringTok{"Value difference (L{-}R)"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{ylim}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{1}\NormalTok{)) }\SpecialCharTok{+}
  \FunctionTok{theme\_classic}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{theme}\NormalTok{(}
    \AttributeTok{legend.position=}\FunctionTok{c}\NormalTok{(}\FloatTok{0.25}\NormalTok{,.}\DecValTok{8}\NormalTok{)}
\NormalTok{  )}

\NormalTok{mem.rt.plot }\OtherTok{\textless{}{-}} \FunctionTok{ggplot}\NormalTok{(}\AttributeTok{data=}\NormalTok{pdata, }\FunctionTok{aes}\NormalTok{(}\AttributeTok{x=}\NormalTok{vDiff)) }\SpecialCharTok{+}
  \FunctionTok{geom\_vline}\NormalTok{(}\AttributeTok{xintercept=}\DecValTok{0}\NormalTok{, }\AttributeTok{color=}\StringTok{\textquotesingle{}grey\textquotesingle{}}\NormalTok{, }\AttributeTok{alpha=}\FloatTok{0.75}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{geom\_line}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{y=}\NormalTok{rt.mean, }\AttributeTok{group=}\NormalTok{Dataset, }\AttributeTok{color=}\NormalTok{Dataset), }\AttributeTok{size=}\DecValTok{2}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{geom\_ribbon}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{ymin=}\NormalTok{rt.mean}\SpecialCharTok{{-}}\NormalTok{rt.se, }\AttributeTok{ymax=}\NormalTok{rt.mean}\SpecialCharTok{+}\NormalTok{rt.se, }\AttributeTok{group=}\NormalTok{Dataset, }\AttributeTok{fill=}\NormalTok{Dataset), }\AttributeTok{alpha=}\NormalTok{.}\DecValTok{2}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{ylab}\NormalTok{(}\StringTok{"Response time (s)"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{xlab}\NormalTok{(}\StringTok{"Value difference (L{-}R)"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{theme\_classic}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{theme}\NormalTok{(}
    \AttributeTok{legend.position=}\StringTok{"None"}
\NormalTok{  )}

\FunctionTok{grid.arrange}\NormalTok{(}
\NormalTok{  mem.choice.plot, mem.rt.plot,}
  \AttributeTok{nrow=}\DecValTok{1}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{LateNightBayes_files/figure-latex/unnamed-chunk-53-1.pdf}

\hypertarget{rt-with-low-and-high-exposure.}{%
\subsection{RT with low and high exposure.}\label{rt-with-low-and-high-exposure.}}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Get median pe for each subject and indicators for which obs are for low and high pe.}

\NormalTok{test }\OtherTok{\textless{}{-}}\NormalTok{ test }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{group\_by}\NormalTok{(subject) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}
    \AttributeTok{pe.med =} \FunctionTok{median}\NormalTok{(pe),}
    \AttributeTok{pe.low =}\NormalTok{ pe }\SpecialCharTok{\textless{}=}\NormalTok{ pe.med,}
    \AttributeTok{pe.high =}\NormalTok{ pe }\SpecialCharTok{\textgreater{}}\NormalTok{ pe.med,}
    \AttributeTok{difficulty =} \FunctionTok{abs}\NormalTok{(vDiff)}\SpecialCharTok{*}\DecValTok{10} \CommentTok{\#also a difficulty metric}
\NormalTok{  )}

\NormalTok{mem.sim }\OtherTok{\textless{}{-}}\NormalTok{ mem.sim }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{group\_by}\NormalTok{(subj) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}
    \AttributeTok{pe.med =} \FunctionTok{median}\NormalTok{(pe),}
    \AttributeTok{pe.low =}\NormalTok{ pe }\SpecialCharTok{\textless{}=}\NormalTok{ pe.med,}
    \AttributeTok{pe.high =}\NormalTok{ pe }\SpecialCharTok{\textgreater{}}\NormalTok{ pe.med,}
    \AttributeTok{difficulty =} \FunctionTok{abs}\NormalTok{(vDiff) }\CommentTok{\#also a difficulty metric}
\NormalTok{  )}

\CommentTok{\# real data}

\NormalTok{pdata.real.low }\OtherTok{\textless{}{-}}\NormalTok{ test[test}\SpecialCharTok{$}\NormalTok{pe.low}\SpecialCharTok{==}\NormalTok{T,] }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{group\_by}\NormalTok{(subject, difficulty) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{summarize}\NormalTok{(}
    \AttributeTok{rt.mean =} \FunctionTok{mean}\NormalTok{(rt)}
\NormalTok{  ) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{ungroup}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{group\_by}\NormalTok{(difficulty) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{summarize}\NormalTok{(}
    \AttributeTok{y =} \FunctionTok{mean}\NormalTok{(rt.mean),}
    \AttributeTok{se =} \FunctionTok{std.error}\NormalTok{(rt.mean),}
    \AttributeTok{Dataset =} \StringTok{"Real"}\NormalTok{,}
    \AttributeTok{Exposure =} \StringTok{"Low"}\NormalTok{,}
    \AttributeTok{group =} \DecValTok{1}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## `summarise()` has grouped output by 'subject'. You can override using the
## `.groups` argument.
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pdata.real.high }\OtherTok{\textless{}{-}}\NormalTok{ test[test}\SpecialCharTok{$}\NormalTok{pe.high}\SpecialCharTok{==}\NormalTok{T,] }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{group\_by}\NormalTok{(subject, difficulty) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{summarize}\NormalTok{(}
    \AttributeTok{rt.mean =} \FunctionTok{mean}\NormalTok{(rt)}
\NormalTok{  ) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{ungroup}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{group\_by}\NormalTok{(difficulty) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{summarize}\NormalTok{(}
    \AttributeTok{y =} \FunctionTok{mean}\NormalTok{(rt.mean),}
    \AttributeTok{se =} \FunctionTok{std.error}\NormalTok{(rt.mean),}
    \AttributeTok{Dataset =} \StringTok{"Real"}\NormalTok{,}
    \AttributeTok{Exposure =} \StringTok{"High"}\NormalTok{,}
    \AttributeTok{group =} \DecValTok{2}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## `summarise()` has grouped output by 'subject'. You can override using the
## `.groups` argument.
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# simulated data}

\NormalTok{pdata.sim.low }\OtherTok{\textless{}{-}}\NormalTok{ mem.sim[mem.sim}\SpecialCharTok{$}\NormalTok{pe.low}\SpecialCharTok{==}\NormalTok{T,] }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{group\_by}\NormalTok{(subj, difficulty) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{summarize}\NormalTok{(}
    \AttributeTok{rt.mean =} \FunctionTok{mean}\NormalTok{(rt)}
\NormalTok{  ) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{ungroup}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{group\_by}\NormalTok{(difficulty) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{summarize}\NormalTok{(}
    \AttributeTok{y =} \FunctionTok{mean}\NormalTok{(rt.mean),}
    \AttributeTok{se =} \FunctionTok{std.error}\NormalTok{(rt.mean),}
    \AttributeTok{Dataset =} \StringTok{"Simulated"}\NormalTok{,}
    \AttributeTok{Exposure =} \StringTok{"Low"}\NormalTok{,}
    \AttributeTok{group =} \DecValTok{3}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## `summarise()` has grouped output by 'subj'. You can override using the
## `.groups` argument.
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pdata.sim.high }\OtherTok{\textless{}{-}}\NormalTok{ mem.sim[mem.sim}\SpecialCharTok{$}\NormalTok{pe.high}\SpecialCharTok{==}\NormalTok{T,] }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{group\_by}\NormalTok{(subj, difficulty) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{summarize}\NormalTok{(}
    \AttributeTok{rt.mean =} \FunctionTok{mean}\NormalTok{(rt)}
\NormalTok{  ) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{ungroup}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{group\_by}\NormalTok{(difficulty) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{summarize}\NormalTok{(}
    \AttributeTok{y =} \FunctionTok{mean}\NormalTok{(rt.mean),}
    \AttributeTok{se =} \FunctionTok{std.error}\NormalTok{(rt.mean),}
    \AttributeTok{Dataset =} \StringTok{"Simulated"}\NormalTok{,}
    \AttributeTok{Exposure =} \StringTok{"High"}\NormalTok{,}
    \AttributeTok{group =} \DecValTok{4}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## `summarise()` has grouped output by 'subj'. You can override using the
## `.groups` argument.
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pdata }\OtherTok{\textless{}{-}} \FunctionTok{bind\_rows}\NormalTok{(pdata.real.low, pdata.real.high, pdata.sim.low, pdata.sim.high)}

\NormalTok{exposure.rt.plot }\OtherTok{\textless{}{-}} \FunctionTok{ggplot}\NormalTok{(}\AttributeTok{data=}\NormalTok{pdata, }\FunctionTok{aes}\NormalTok{(}\AttributeTok{x=}\NormalTok{difficulty)) }\SpecialCharTok{+}
  \FunctionTok{geom\_line}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{y=}\NormalTok{y, }\AttributeTok{group=}\NormalTok{group, }\AttributeTok{color=}\NormalTok{Dataset, }\AttributeTok{linetype=}\NormalTok{Exposure), }\AttributeTok{size=}\DecValTok{2}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{geom\_ribbon}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{ymin=}\NormalTok{y}\SpecialCharTok{{-}}\NormalTok{se, }\AttributeTok{ymax=}\NormalTok{y}\SpecialCharTok{+}\NormalTok{se, }\AttributeTok{group=}\NormalTok{group, }\AttributeTok{fill=}\NormalTok{Dataset), }\AttributeTok{alpha=}\NormalTok{.}\DecValTok{2}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{ylab}\NormalTok{(}\StringTok{"Response time (s)"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{xlab}\NormalTok{(}\StringTok{"Best {-} worst value"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{theme\_classic}\NormalTok{() }

\NormalTok{exposure.rt.plot}
\end{Highlighting}
\end{Shaded}

\includegraphics{LateNightBayes_files/figure-latex/unnamed-chunk-54-1.pdf}

\hypertarget{memDDM}{%
\chapter{memDDM}\label{memDDM}}

(TL;DR) I attempt to incorporate working memory (mem-) into a exponential collapsing bounds Drift-Diffusion-Model (DDM). The exponential bounds add two new parameters to the DDM, delay before collapse and rate of collapse. I hypothesized that the delay before the collapse will inversely scale with previous encounters with either stimuli (call this ``familiarity''). In other words, people will make less patient decisions when they are more familiar with the stimuli. I tested this out by setting delay equal to \(t_0 + \gamma \text{Familiarity}\), where \(t_0\) is a baseline collapse delay and \(\gamma<0\) is how much the delay is scaled by familiarity. I found \(t_0=8.4\), similar to the delay estimate from a standard collapsing bound DDM. Furthermore, I found \(\gamma=-0.8\), indicating that patience is inversely scaled in familiarity with the stimuli. Unfortunately, predictions from this memDDM are not a good qualitative match with response time patterns observed in the data.

\includegraphics[width=0.3\textwidth,height=\textheight]{images/memDDM-featured.PNG}

\hypertarget{introduction-1}{%
\section{Introduction}\label{introduction-1}}

Like in the last chapter, I'm trying to model faster response times in response to repeated exposure to stimuli. I tried incorporating a drift rate that scales with the number of previous exposures to the chosen option. That didn't work.

Ya boi is at it again, except this time, I hypothesize that the time when decision bounds start collapsing is modulated by the number of previous encounters with either option. Specifically, using the functional form laid out by \citep{hawkins2015}, I hypothesize that the shape parameter (\(\kappa\)) is inversely proportional to the number of previous exposures.

Note that here, I am using a Generalized Drift-Diffusion-Model \citep{shinn2020}, not an aDDM. This is for 2 reasons:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  I want some practice with fitting the GDDM using the PyDDM package.
\item
  I want to see how flexible the parameters of the GDDM are.
\item
  It'll probably be faster to estimate than an aDDM, which appeases my currently tight schedule.
\end{enumerate}

Similar to the last chapter, the goals of this report are to:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Incorporate the idea that internal samples are modulated by (and sometimes even sampled from) memory into a sequential sampling model.
\item
  Build a variation of the DDM that explains shorter response times with more familiar stimuli.
\end{enumerate}

\hypertarget{methods-1}{%
\section{Methods}\label{methods-1}}

Reading and transforming the data from \citep{smith2018}.

\hypertarget{prep-work-5}{%
\subsection{Prep work}\label{prep-work-5}}

\hypertarget{load-libraries-1}{%
\subsubsection{Load libraries}\label{load-libraries-1}}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{rm}\NormalTok{(}\AttributeTok{list =} \FunctionTok{ls}\NormalTok{())}
\NormalTok{seed }\OtherTok{=} \DecValTok{1337}
\FunctionTok{library}\NormalTok{(dplyr)}
\FunctionTok{library}\NormalTok{(ggplot2)}
\FunctionTok{library}\NormalTok{(hrbrthemes)}
\FunctionTok{library}\NormalTok{(ggsci)}
\FunctionTok{library}\NormalTok{(data.table)}
\FunctionTok{library}\NormalTok{(plotrix)}
\FunctionTok{library}\NormalTok{(grid)}
\FunctionTok{library}\NormalTok{(gridExtra)}
\FunctionTok{library}\NormalTok{(reticulate)}
\CommentTok{\#use\_python("D:/Program Files/PsychoPy/python.exe")}
\end{Highlighting}
\end{Shaded}

\hypertarget{load-data}{%
\subsubsection{Load data}\label{load-data}}

I will again be using the data from \citep{smith2018}. The data can be downloaded here:
\url{https://osf.io/x2jhp/?view_only=2669d8f3983d4442952a52c5de5814f7}.

I calculate a variable called ``PreviousEncounterBoth'', which counts the number of previous trials in which the subject has seen either item for this trial.

Familiarity is low or high. Low means previous encounters with either item is below or equal to median for that subject. High means previous exposures is above median.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{load}\NormalTok{(}\StringTok{"data/mem{-}aDDM{-}smithkrajbich2018.RData"}\NormalTok{)}

\NormalTok{twofoodeyedata }\OtherTok{\textless{}{-}}\NormalTok{ twofoodeyedata }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{group\_by}\NormalTok{(SubjectNumber, Trial) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{( }\CommentTok{\# fixation number}
    \AttributeTok{fixNum=}\FunctionTok{row\_number}\NormalTok{()}
\NormalTok{  ) }

\CommentTok{\# Running counts of the number of times the subjects have seen the left and right options across previous trials}
\NormalTok{twofoodchoicedata}\SpecialCharTok{$}\NormalTok{PreviousEncounterLeft }\OtherTok{\textless{}{-}} \ConstantTok{NA}
\NormalTok{twofoodchoicedata}\SpecialCharTok{$}\NormalTok{PreviousEncounterRight }\OtherTok{\textless{}{-}} \ConstantTok{NA}
\NormalTok{data }\OtherTok{\textless{}{-}}\NormalTok{ twofoodchoicedata[}\FunctionTok{order}\NormalTok{(twofoodchoicedata}\SpecialCharTok{$}\NormalTok{SubjectNumber, twofoodchoicedata}\SpecialCharTok{$}\NormalTok{Trial),]}
\ControlFlowTok{for}\NormalTok{ (n }\ControlFlowTok{in} \DecValTok{1}\SpecialCharTok{:}\FunctionTok{length}\NormalTok{(data}\SpecialCharTok{$}\NormalTok{SubjectNumber)) \{}
\NormalTok{  tempdata }\OtherTok{\textless{}{-}}\NormalTok{ data[data}\SpecialCharTok{$}\NormalTok{SubjectNumber}\SpecialCharTok{==}\NormalTok{data}\SpecialCharTok{$}\NormalTok{SubjectNumber[n] }\SpecialCharTok{\&}\NormalTok{ data}\SpecialCharTok{$}\NormalTok{Trial}\SpecialCharTok{\textless{}=}\NormalTok{data}\SpecialCharTok{$}\NormalTok{Trial[n],]}
\NormalTok{  prevList }\OtherTok{\textless{}{-}} \FunctionTok{rbind}\NormalTok{(tempdata}\SpecialCharTok{$}\NormalTok{FoodLeft,tempdata}\SpecialCharTok{$}\NormalTok{FoodRight)}
\NormalTok{  data}\SpecialCharTok{$}\NormalTok{PreviousEncounterLeft[n] }\OtherTok{\textless{}{-}} \FunctionTok{sum}\NormalTok{(prevList}\SpecialCharTok{==}\NormalTok{data}\SpecialCharTok{$}\NormalTok{FoodLeft[n])}\SpecialCharTok{{-}}\DecValTok{1}
\NormalTok{  data}\SpecialCharTok{$}\NormalTok{PreviousEncounterRight[n] }\OtherTok{\textless{}{-}} \FunctionTok{sum}\NormalTok{(prevList}\SpecialCharTok{==}\NormalTok{data}\SpecialCharTok{$}\NormalTok{FoodRight[n])}\SpecialCharTok{{-}}\DecValTok{1}
\NormalTok{\}}
\NormalTok{data}\SpecialCharTok{$}\NormalTok{PreviousEncounterBoth }\OtherTok{\textless{}{-}}\NormalTok{ data}\SpecialCharTok{$}\NormalTok{PreviousEncounterLeft}\SpecialCharTok{+}\NormalTok{data}\SpecialCharTok{$}\NormalTok{PreviousEncounterRight}
\NormalTok{data}\SpecialCharTok{$}\NormalTok{PreviousEncounterChosen }\OtherTok{\textless{}{-}} 
  \FunctionTok{ifelse}\NormalTok{(data}\SpecialCharTok{$}\NormalTok{LeftRight}\SpecialCharTok{==}\DecValTok{1}\NormalTok{, data}\SpecialCharTok{$}\NormalTok{PreviousEncounterLeft, data}\SpecialCharTok{$}\NormalTok{PreviousEncounterRight)}

\NormalTok{data }\OtherTok{\textless{}{-}}\NormalTok{ data }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{group\_by}\NormalTok{(SubjectNumber) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}
    \AttributeTok{pe.median =} \FunctionTok{median}\NormalTok{(PreviousEncounterBoth),}
    \AttributeTok{Familiarity =} \FunctionTok{ifelse}\NormalTok{(PreviousEncounterBoth }\SpecialCharTok{\textgreater{}}\NormalTok{ pe.median, }\DecValTok{1}\NormalTok{, }\DecValTok{0}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{factor}\NormalTok{(}\AttributeTok{levels=}\FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{1}\NormalTok{), }\AttributeTok{labels=}\FunctionTok{c}\NormalTok{(}\StringTok{"Low"}\NormalTok{,}\StringTok{"High"}\NormalTok{)),}
    \AttributeTok{vdiff =}\NormalTok{ ValueLeft}\SpecialCharTok{{-}}\NormalTok{ValueRight,}
    \AttributeTok{difficulty =} \FunctionTok{abs}\NormalTok{(ValueLeft}\SpecialCharTok{{-}}\NormalTok{ValueRight),}
    \AttributeTok{LeftRight =} \FunctionTok{ifelse}\NormalTok{(LeftRight}\SpecialCharTok{==}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{,}\DecValTok{0}\NormalTok{)}
\NormalTok{  )}

\FunctionTok{write.csv}\NormalTok{(data, }\StringTok{"data/mem{-}DDM{-}cleanSmithKrajbich2018.csv"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\hypertarget{behavioral-results}{%
\section{Behavioral Results}\label{behavioral-results}}

What do choices and response times look like? This is what I'm trying to model.

\hypertarget{choice-probabilities}{%
\subsection{Choice probabilities}\label{choice-probabilities}}

Probability of choosing the left option wrt value differences.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pdata.choice }\OtherTok{\textless{}{-}}\NormalTok{ data }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{group\_by}\NormalTok{(SubjectNumber, vdiff) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{summarize}\NormalTok{(}
    \AttributeTok{choice.means =} \FunctionTok{mean}\NormalTok{(LeftRight)}
\NormalTok{  ) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{ungroup}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{group\_by}\NormalTok{(vdiff) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{summarize}\NormalTok{(}
    \AttributeTok{y =} \FunctionTok{mean}\NormalTok{(choice.means),}
    \AttributeTok{se =} \FunctionTok{std.error}\NormalTok{(choice.means)}
\NormalTok{  )}

\NormalTok{plot.choice }\OtherTok{\textless{}{-}} \FunctionTok{ggplot}\NormalTok{(}\AttributeTok{data=}\NormalTok{pdata.choice, }\FunctionTok{aes}\NormalTok{(}\AttributeTok{x=}\NormalTok{vdiff, }\AttributeTok{y=}\NormalTok{y)) }\SpecialCharTok{+}
  \FunctionTok{geom\_vline}\NormalTok{(}\AttributeTok{xintercept=}\DecValTok{0}\NormalTok{, }\AttributeTok{color=}\StringTok{"grey"}\NormalTok{, }\AttributeTok{alpha=}\NormalTok{.}\DecValTok{75}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{geom\_hline}\NormalTok{(}\AttributeTok{yintercept=}\FloatTok{0.5}\NormalTok{, }\AttributeTok{color=}\StringTok{"grey"}\NormalTok{, }\AttributeTok{alpha=}\NormalTok{.}\DecValTok{75}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{geom\_line}\NormalTok{(}\AttributeTok{size=}\DecValTok{2}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{geom\_ribbon}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{ymin=}\NormalTok{y}\SpecialCharTok{{-}}\NormalTok{se, }\AttributeTok{ymax=}\NormalTok{y}\SpecialCharTok{+}\NormalTok{se), }\AttributeTok{alpha=}\NormalTok{.}\DecValTok{25}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{y=}\StringTok{"Pr(choose left)"}\NormalTok{, }\AttributeTok{x=}\StringTok{"Left {-} right rating"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{theme\_classic}\NormalTok{()}
\NormalTok{plot.choice}
\end{Highlighting}
\end{Shaded}

\includegraphics{LateNightBayes_files/figure-latex/unnamed-chunk-57-1.pdf}

\hypertarget{rts-grouped-by-familiarity.}{%
\subsection{RTs, grouped by familiarity.}\label{rts-grouped-by-familiarity.}}

This is the phenomenon I am trying to model with the GDDM. Response times across difficulties are shorter when the subject is more familiar with both stimuli.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pdata.rt }\OtherTok{\textless{}{-}}\NormalTok{ data }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{group\_by}\NormalTok{(SubjectNumber, Familiarity, difficulty) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{summarize}\NormalTok{(}
    \AttributeTok{RT.means =} \FunctionTok{mean}\NormalTok{(RT)}
\NormalTok{  ) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{ungroup}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{group\_by}\NormalTok{(Familiarity, difficulty) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{summarize}\NormalTok{(}
    \AttributeTok{y =} \FunctionTok{mean}\NormalTok{(RT.means),}
    \AttributeTok{se =} \FunctionTok{std.error}\NormalTok{(RT.means)}
\NormalTok{  )}

\NormalTok{plot.rt }\OtherTok{\textless{}{-}} \FunctionTok{ggplot}\NormalTok{(}\AttributeTok{data=}\NormalTok{pdata.rt, }\FunctionTok{aes}\NormalTok{(}\AttributeTok{x=}\NormalTok{difficulty, }\AttributeTok{y=}\NormalTok{y, }\AttributeTok{group=}\NormalTok{Familiarity, }\AttributeTok{color=}\NormalTok{Familiarity)) }\SpecialCharTok{+}
  \FunctionTok{geom\_line}\NormalTok{(}\AttributeTok{size=}\DecValTok{2}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{geom\_ribbon}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{ymin=}\NormalTok{y}\SpecialCharTok{{-}}\NormalTok{se, }\AttributeTok{ymax=}\NormalTok{y}\SpecialCharTok{+}\NormalTok{se, }\AttributeTok{fill=}\NormalTok{Familiarity), }\AttributeTok{alpha=}\NormalTok{.}\DecValTok{25}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{y=}\StringTok{"Response times (s)"}\NormalTok{, }\AttributeTok{x=}\StringTok{"Best {-} worst rating"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{theme\_classic}\NormalTok{()}
\NormalTok{plot.rt}
\end{Highlighting}
\end{Shaded}

\includegraphics{LateNightBayes_files/figure-latex/unnamed-chunk-58-1.pdf}

\hypertarget{fit-with-pyddm}{%
\section{Fit with PyDDM}\label{fit-with-pyddm}}

I will use PyDDM by \citep{shinn2020} to fit a GDDM to the data.

\hypertarget{libraries-and-reading-in-the-data}{%
\subsection{Libraries and reading in the data}\label{libraries-and-reading-in-the-data}}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ ddm }\ImportTok{import}\NormalTok{ Model, Fittable, Sample, Bound, set\_N\_cpus, FitResult}
\ImportTok{from}\NormalTok{ ddm.functions }\ImportTok{import}\NormalTok{ fit\_adjust\_model, display\_model, fit\_adjust\_model}
\ImportTok{from}\NormalTok{ ddm.models }\ImportTok{import}\NormalTok{ NoiseConstant, BoundConstant, BoundCollapsingExponential, OverlayChain, OverlayNonDecision, OverlayPoissonMixture, LossRobustBIC}
\ImportTok{import}\NormalTok{ ddm.plot}
\ImportTok{import}\NormalTok{ math}
\ImportTok{import}\NormalTok{ pandas }\ImportTok{as}\NormalTok{ pd}
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}

\NormalTok{set\_N\_cpus(}\DecValTok{4}\NormalTok{)}

\CommentTok{\# read in csv data}
\ControlFlowTok{with} \BuiltInTok{open}\NormalTok{(}\StringTok{"data/mem{-}DDM{-}cleanSmithKrajbich2018.csv"}\NormalTok{, }\StringTok{"r"}\NormalTok{) }\ImportTok{as}\NormalTok{ f:}
\NormalTok{    df\_rt }\OperatorTok{=}\NormalTok{ pd.read\_csv(f)}

\NormalTok{df\_rt }\OperatorTok{=}\NormalTok{ df\_rt[df\_rt[}\StringTok{"SubjectNumber"}\NormalTok{]}\OperatorTok{==}\DecValTok{1}\NormalTok{]}

\NormalTok{sk\_sample }\OperatorTok{=}\NormalTok{ Sample.from\_pandas\_dataframe(df\_rt, rt\_column\_name}\OperatorTok{=}\StringTok{"RT"}\NormalTok{, correct\_column\_name}\OperatorTok{=}\StringTok{"LeftRight"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\hypertarget{standard-ddm}{%
\subsection{Standard DDM}\label{standard-ddm}}

Fix noise = 1. Why noise? We are going to fit collapsing bounds later, so need to fix something else. Noise is a more traditional candidate than drift rate as a fixed parameter.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Let drift rate vary with value difference}
\KeywordTok{class}\NormalTok{ DriftScaled(ddm.models.Drift):}
\NormalTok{  name }\OperatorTok{=} \StringTok{"Drift depends linearly on value difference"}
\NormalTok{  required\_parameters }\OperatorTok{=}\NormalTok{ [}\StringTok{"driftvaluediff"}\NormalTok{]}
\NormalTok{  required\_conditions }\OperatorTok{=}\NormalTok{ [}\StringTok{"vdiff"}\NormalTok{]}
  
  \KeywordTok{def}\NormalTok{ get\_drift(}\VariableTok{self}\NormalTok{, conditions, }\OperatorTok{**}\NormalTok{kwargs):}
    \ControlFlowTok{return} \VariableTok{self}\NormalTok{.driftvaluediff }\OperatorTok{*}\NormalTok{ conditions[}\StringTok{"vdiff"}\NormalTok{]}

\CommentTok{\# fit the data}
\NormalTok{model\_sk }\OperatorTok{=}\NormalTok{ Model(}
\NormalTok{  name }\OperatorTok{=} \StringTok{\textquotesingle{}SmithKrajbich2018 data, drift varies with value difference\textquotesingle{}}\NormalTok{,}
\NormalTok{  drift }\OperatorTok{=}\NormalTok{ DriftScaled(}
\NormalTok{    driftvaluediff }\OperatorTok{=}\NormalTok{ Fittable(minval}\OperatorTok{=}\DecValTok{0}\NormalTok{, maxval}\OperatorTok{=}\DecValTok{2}\NormalTok{)}
\NormalTok{  ),}
\NormalTok{  noise }\OperatorTok{=}\NormalTok{ NoiseConstant(noise }\OperatorTok{=} \DecValTok{1}\NormalTok{),}
\NormalTok{  bound }\OperatorTok{=}\NormalTok{ BoundConstant(B}\OperatorTok{=}\NormalTok{Fittable(minval}\OperatorTok{=}\FloatTok{.1}\NormalTok{, maxval}\OperatorTok{=}\FloatTok{1.5}\NormalTok{)),}
\NormalTok{  overlay}\OperatorTok{=}\NormalTok{OverlayChain(}
\NormalTok{    overlays}\OperatorTok{=}\NormalTok{[}
\NormalTok{      OverlayNonDecision(nondectime }\OperatorTok{=}\NormalTok{ Fittable(minval}\OperatorTok{=}\DecValTok{0}\NormalTok{, maxval}\OperatorTok{=}\DecValTok{1}\NormalTok{)), }
\NormalTok{      OverlayPoissonMixture(pmixturecoef}\OperatorTok{=}\FloatTok{.02}\NormalTok{,rate}\OperatorTok{=}\DecValTok{1}\NormalTok{)}
\NormalTok{    ]}
\NormalTok{  ),}
\NormalTok{  dx}\OperatorTok{=}\FloatTok{.01}\NormalTok{, }
\NormalTok{  dt}\OperatorTok{=}\FloatTok{.01}\NormalTok{, }
\NormalTok{  T\_dur}\OperatorTok{=}\DecValTok{10}
\NormalTok{)}
\NormalTok{fit\_model\_sk\_standard }\OperatorTok{=}\NormalTok{ fit\_adjust\_model(}
\NormalTok{  sample }\OperatorTok{=}\NormalTok{ sk\_sample, }
\NormalTok{  model }\OperatorTok{=}\NormalTok{ model\_sk,}
\NormalTok{  lossfunction }\OperatorTok{=}\NormalTok{ LossRobustBIC,}
\NormalTok{  verbose}\OperatorTok{=}\VariableTok{False}\NormalTok{)}
\NormalTok{display\_model(fit\_model\_sk\_standard)}

\ControlFlowTok{with} \BuiltInTok{open}\NormalTok{(}\StringTok{"temp/memDDM{-}standard.txt"}\NormalTok{, }\StringTok{"w"}\NormalTok{) }\ImportTok{as}\NormalTok{ f:}
\NormalTok{    f.write(}\BuiltInTok{repr}\NormalTok{(fit\_model\_sk\_standard))}
\end{Highlighting}
\end{Shaded}

\hypertarget{mem-ddm-where-drift-scales-with-previous-exposure-to-the-chosen-option}{%
\subsection{mem-DDM where drift scales with previous exposure to the chosen option}\label{mem-ddm-where-drift-scales-with-previous-exposure-to-the-chosen-option}}

Just double checking that we get similar DDM parameters to the previous chapter, even though we aren't accounting for attentional biases here.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Let drift rate vary with value difference and previous exposure to the chosen item}
\KeywordTok{class}\NormalTok{ DriftScaled(ddm.models.Drift):}
\NormalTok{  name }\OperatorTok{=} \StringTok{"Drift depends linearly on value difference"}
\NormalTok{  required\_parameters }\OperatorTok{=}\NormalTok{ [}\StringTok{"driftvaluediff"}\NormalTok{,}\StringTok{"driftprevexp"}\NormalTok{]}
\NormalTok{  required\_conditions }\OperatorTok{=}\NormalTok{ [}\StringTok{"vdiff"}\NormalTok{,}\StringTok{"PreviousEncounterChosen"}\NormalTok{]}
  
  \KeywordTok{def}\NormalTok{ get\_drift(}\VariableTok{self}\NormalTok{, conditions, }\OperatorTok{**}\NormalTok{kwargs):}
    \ControlFlowTok{return}\NormalTok{ (}\VariableTok{self}\NormalTok{.driftvaluediff }\OperatorTok{+} \VariableTok{self}\NormalTok{.driftprevexp }\OperatorTok{*}\NormalTok{ conditions[}\StringTok{"PreviousEncounterChosen"}\NormalTok{]) }\OperatorTok{*}\NormalTok{ conditions[}\StringTok{"vdiff"}\NormalTok{]}

\CommentTok{\# fit the data}
\NormalTok{model\_sk }\OperatorTok{=}\NormalTok{ Model(}
\NormalTok{  name }\OperatorTok{=} \StringTok{\textquotesingle{}SmithKrajbich2018 data, drift varies with value difference\textquotesingle{}}\NormalTok{,}
\NormalTok{  drift }\OperatorTok{=}\NormalTok{ DriftScaled(}
\NormalTok{    driftvaluediff }\OperatorTok{=}\NormalTok{ Fittable(minval}\OperatorTok{=}\DecValTok{0}\NormalTok{, maxval}\OperatorTok{=}\DecValTok{2}\NormalTok{),}
\NormalTok{    driftprevexp   }\OperatorTok{=}\NormalTok{ Fittable(minval}\OperatorTok{=}\DecValTok{0}\NormalTok{, maxval}\OperatorTok{=}\DecValTok{2}\NormalTok{)}
\NormalTok{  ),}
\NormalTok{  noise }\OperatorTok{=}\NormalTok{ NoiseConstant(noise }\OperatorTok{=} \DecValTok{1}\NormalTok{),}
\NormalTok{  bound }\OperatorTok{=}\NormalTok{ BoundConstant(B}\OperatorTok{=}\NormalTok{Fittable(minval}\OperatorTok{=}\FloatTok{.1}\NormalTok{, maxval}\OperatorTok{=}\FloatTok{1.5}\NormalTok{)),}
\NormalTok{  overlay}\OperatorTok{=}\NormalTok{OverlayChain(}
\NormalTok{    overlays}\OperatorTok{=}\NormalTok{[}
\NormalTok{      OverlayNonDecision(nondectime }\OperatorTok{=}\NormalTok{ Fittable(minval}\OperatorTok{=}\DecValTok{0}\NormalTok{, maxval}\OperatorTok{=}\DecValTok{1}\NormalTok{)), }
\NormalTok{      OverlayPoissonMixture(pmixturecoef}\OperatorTok{=}\FloatTok{.02}\NormalTok{,rate}\OperatorTok{=}\DecValTok{1}\NormalTok{)}
\NormalTok{    ]}
\NormalTok{  ),}
\NormalTok{  dx}\OperatorTok{=}\FloatTok{.01}\NormalTok{, }
\NormalTok{  dt}\OperatorTok{=}\FloatTok{.01}\NormalTok{, }
\NormalTok{  T\_dur}\OperatorTok{=}\DecValTok{10}
\NormalTok{)}
\NormalTok{fit\_model\_sk\_driftScaled }\OperatorTok{=}\NormalTok{ fit\_adjust\_model(}
\NormalTok{  sample }\OperatorTok{=}\NormalTok{ sk\_sample, }
\NormalTok{  model }\OperatorTok{=}\NormalTok{ model\_sk,}
\NormalTok{  lossfunction }\OperatorTok{=}\NormalTok{ LossRobustBIC,}
\NormalTok{  verbose}\OperatorTok{=}\VariableTok{False}\NormalTok{)}
\NormalTok{display\_model(fit\_model\_sk\_driftScaled)}

\ControlFlowTok{with} \BuiltInTok{open}\NormalTok{(}\StringTok{"temp/memDDM{-}dirftScaled.txt"}\NormalTok{, }\StringTok{"w"}\NormalTok{) }\ImportTok{as}\NormalTok{ f:}
\NormalTok{    f.write(}\BuiltInTok{repr}\NormalTok{(fit\_model\_sk\_driftScaled))}
\end{Highlighting}
\end{Shaded}

Good news everyone! Drift rate, accounting for wider boundaries, is in the same ballpark as before.

\hypertarget{ddm-with-collpasing-bounds}{%
\subsection{DDM with collpasing bounds}\label{ddm-with-collpasing-bounds}}

Using exponential bounds to speed up fitting. Faster than \citep{hawkins2015} Weibull CDF since it has fewer parameters. After some conversations with Daeyeol Lee in Lake Arrowhead 2020, it also doesn't seem like it makes much difference what the functional form of the collapsing bounds is. In terms of predictive accuracy, they don't make much difference. Since this is just early exploration and isn't going out to any peer-reviewed journals\ldots{} why not just go with the faster functional form?

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Let drift rate vary with value difference}
\KeywordTok{class}\NormalTok{ DriftRate(ddm.models.Drift):}
\NormalTok{  name }\OperatorTok{=} \StringTok{"Drift depends linearly on value difference"}
\NormalTok{  required\_parameters }\OperatorTok{=}\NormalTok{ [}\StringTok{"driftvaluediff"}\NormalTok{]}
\NormalTok{  required\_conditions }\OperatorTok{=}\NormalTok{ [}\StringTok{"vdiff"}\NormalTok{]}
  
  \KeywordTok{def}\NormalTok{ get\_drift(}\VariableTok{self}\NormalTok{, conditions, }\OperatorTok{**}\NormalTok{kwargs):}
    \ControlFlowTok{return} \VariableTok{self}\NormalTok{.driftvaluediff }\OperatorTok{*}\NormalTok{ conditions[}\StringTok{"vdiff"}\NormalTok{]}
    
\CommentTok{\# Let bounds collapse after a certain delay}
\KeywordTok{class}\NormalTok{ BoundCollapsingExponentialDelay(Bound):}
    \CommentTok{"""Bound collapses exponentially over time.}

\CommentTok{    Takes three parameters: }

\CommentTok{    \textasciigrave{}B\textasciigrave{} {-} the bound at time t = 0.}
\CommentTok{    \textasciigrave{}tau\textasciigrave{} {-} the time constant for the collapse, should be greater than}
\CommentTok{    zero.}
\CommentTok{    \textasciigrave{}t1\textasciigrave{} {-} the time at which the collapse begins, in seconds}
\CommentTok{    """}
\NormalTok{    name }\OperatorTok{=} \StringTok{"Delayed exponential collapsing bound"}
\NormalTok{    required\_parameters }\OperatorTok{=}\NormalTok{ [}\StringTok{"B"}\NormalTok{, }\StringTok{"tau"}\NormalTok{, }\StringTok{"t1"}\NormalTok{]}
    \KeywordTok{def}\NormalTok{ get\_bound(}\VariableTok{self}\NormalTok{, t, conditions, }\OperatorTok{**}\NormalTok{kwargs):}
        \ControlFlowTok{if}\NormalTok{ t }\OperatorTok{\textless{}=} \VariableTok{self}\NormalTok{.t1:}
            \ControlFlowTok{return} \VariableTok{self}\NormalTok{.B}
        \ControlFlowTok{if}\NormalTok{ t }\OperatorTok{\textgreater{}} \VariableTok{self}\NormalTok{.t1:}
            \ControlFlowTok{return} \VariableTok{self}\NormalTok{.B }\OperatorTok{*}\NormalTok{ np.exp(}\OperatorTok{{-}}\VariableTok{self}\NormalTok{.tau}\OperatorTok{*}\NormalTok{(t}\OperatorTok{{-}}\VariableTok{self}\NormalTok{.t1))}

\CommentTok{\# fit the data}
\NormalTok{model\_sk }\OperatorTok{=}\NormalTok{ Model(}
\NormalTok{  name }\OperatorTok{=} \StringTok{\textquotesingle{}SmithKrajbich2018 data, drift varies with value difference\textquotesingle{}}\NormalTok{,}
\NormalTok{  drift }\OperatorTok{=}\NormalTok{ DriftRate(driftvaluediff }\OperatorTok{=}\NormalTok{ Fittable(minval}\OperatorTok{=}\DecValTok{0}\NormalTok{, maxval}\OperatorTok{=}\DecValTok{2}\NormalTok{)),}
\NormalTok{  noise }\OperatorTok{=}\NormalTok{ NoiseConstant(noise }\OperatorTok{=} \DecValTok{1}\NormalTok{),}
\NormalTok{  bound }\OperatorTok{=}\NormalTok{ BoundCollapsingExponentialDelay(}
\NormalTok{    B }\OperatorTok{=}\NormalTok{ Fittable(minval}\OperatorTok{=}\FloatTok{.1}\NormalTok{, maxval}\OperatorTok{=}\FloatTok{1.5}\NormalTok{),}
\NormalTok{    tau }\OperatorTok{=}\NormalTok{ Fittable(minval}\OperatorTok{=}\FloatTok{.1}\NormalTok{, maxval}\OperatorTok{=}\DecValTok{5}\NormalTok{),}
\NormalTok{    t1 }\OperatorTok{=}\NormalTok{ Fittable(minval}\OperatorTok{=}\DecValTok{0}\NormalTok{, maxval}\OperatorTok{=}\DecValTok{10}\NormalTok{)}
\NormalTok{  ),}
\NormalTok{  overlay}\OperatorTok{=}\NormalTok{OverlayChain(}
\NormalTok{    overlays}\OperatorTok{=}\NormalTok{[}
\NormalTok{      OverlayNonDecision(nondectime }\OperatorTok{=}\NormalTok{ Fittable(minval}\OperatorTok{=}\DecValTok{0}\NormalTok{, maxval}\OperatorTok{=}\DecValTok{1}\NormalTok{)), }
\NormalTok{      OverlayPoissonMixture(pmixturecoef}\OperatorTok{=}\FloatTok{.02}\NormalTok{,rate}\OperatorTok{=}\DecValTok{1}\NormalTok{)}
\NormalTok{    ]}
\NormalTok{  ),}
\NormalTok{  dx}\OperatorTok{=}\FloatTok{.01}\NormalTok{, }
\NormalTok{  dt}\OperatorTok{=}\FloatTok{.01}\NormalTok{, }
\NormalTok{  T\_dur}\OperatorTok{=}\DecValTok{10}
\NormalTok{)}
\NormalTok{fit\_model\_sk\_collapseBound }\OperatorTok{=}\NormalTok{ fit\_adjust\_model(}
\NormalTok{  sample }\OperatorTok{=}\NormalTok{ sk\_sample, }
\NormalTok{  model }\OperatorTok{=}\NormalTok{ model\_sk,}
\NormalTok{  lossfunction }\OperatorTok{=}\NormalTok{ LossRobustBIC,}
\NormalTok{  verbose}\OperatorTok{=}\VariableTok{False}\NormalTok{)}
\NormalTok{display\_model(fit\_model\_sk\_collapseBound)}

\ControlFlowTok{with} \BuiltInTok{open}\NormalTok{(}\StringTok{"temp/memDDM{-}collapseBound.txt"}\NormalTok{, }\StringTok{"w"}\NormalTok{) }\ImportTok{as}\NormalTok{ f:}
\NormalTok{    f.write(}\BuiltInTok{repr}\NormalTok{(fit\_model\_sk\_collapseBound))}
\end{Highlighting}
\end{Shaded}

\begin{itemize}
\tightlist
\item
  Drift rate = 0.35
\item
  Noise = 1
\item
  Boundary starting point = 1.3
\item
  Boundary delay = 8.4
\item
  Rate of collapse = 1.9
\item
  Non-decision time = 0.6
\end{itemize}

\hypertarget{mem-ddm-where-boundary-collapse-shape-scales-with-previous-exposure-to-both-items}{%
\subsection{mem-DDM where boundary collapse shape scales with previous exposure to both items}\label{mem-ddm-where-boundary-collapse-shape-scales-with-previous-exposure-to-both-items}}

Using exponential bounds where delay is scaled by previous exposure to both items.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Let drift rate vary with value difference}
\KeywordTok{class}\NormalTok{ DriftRate(ddm.models.Drift):}
\NormalTok{  name }\OperatorTok{=} \StringTok{"Drift depends linearly on value difference"}
\NormalTok{  required\_parameters }\OperatorTok{=}\NormalTok{ [}\StringTok{"driftvaluediff"}\NormalTok{]}
\NormalTok{  required\_conditions }\OperatorTok{=}\NormalTok{ [}\StringTok{"vdiff"}\NormalTok{]}
  
  \KeywordTok{def}\NormalTok{ get\_drift(}\VariableTok{self}\NormalTok{, conditions, }\OperatorTok{**}\NormalTok{kwargs):}
    \ControlFlowTok{return} \VariableTok{self}\NormalTok{.driftvaluediff }\OperatorTok{*}\NormalTok{ conditions[}\StringTok{"vdiff"}\NormalTok{]}
    
\CommentTok{\# Let bounds collapse after a certain delay scaled by previous exposure}
\KeywordTok{class}\NormalTok{ BoundCollapsingExponentialDelay(Bound):}
    \CommentTok{"""Bound collapses exponentially over time.}

\CommentTok{    Takes three parameters: }

\CommentTok{    \textasciigrave{}B\textasciigrave{} {-} the bound at time t = 0.}
\CommentTok{    \textasciigrave{}tau\textasciigrave{} {-} the time constant for the collapse, should be greater than}
\CommentTok{    zero.}
\CommentTok{    \textasciigrave{}t1\textasciigrave{} {-} the time at which the collapse begins, in seconds}
\CommentTok{    \textasciigrave{}gam\textasciigrave{} {-} how does delay scale with previous exposure to both options}
\CommentTok{    """}
\NormalTok{    name }\OperatorTok{=} \StringTok{"Delayed exponential collapsing bound"}
\NormalTok{    required\_parameters }\OperatorTok{=}\NormalTok{ [}\StringTok{"B"}\NormalTok{, }\StringTok{"tau"}\NormalTok{, }\StringTok{"t1"}\NormalTok{, }\StringTok{"gam"}\NormalTok{]}
\NormalTok{    required\_conditions }\OperatorTok{=}\NormalTok{ [}\StringTok{"PreviousEncounterBoth"}\NormalTok{]}
    \KeywordTok{def}\NormalTok{ get\_bound(}\VariableTok{self}\NormalTok{, t, conditions, }\OperatorTok{**}\NormalTok{kwargs):}
\NormalTok{        scaledDelay }\OperatorTok{=} \VariableTok{self}\NormalTok{.t1 }\OperatorTok{+} \VariableTok{self}\NormalTok{.gam }\OperatorTok{*}\NormalTok{ conditions[}\StringTok{"PreviousEncounterBoth"}\NormalTok{]}
        \ControlFlowTok{if}\NormalTok{ t }\OperatorTok{\textless{}=}\NormalTok{ scaledDelay:}
            \ControlFlowTok{return} \VariableTok{self}\NormalTok{.B}
        \ControlFlowTok{if}\NormalTok{ t }\OperatorTok{\textgreater{}}\NormalTok{ scaledDelay:}
            \ControlFlowTok{return} \VariableTok{self}\NormalTok{.B }\OperatorTok{*}\NormalTok{ np.exp(}\OperatorTok{{-}}\VariableTok{self}\NormalTok{.tau}\OperatorTok{*}\NormalTok{(t}\OperatorTok{{-}}\NormalTok{scaledDelay))}

\CommentTok{\# fit the data}
\NormalTok{model\_sk }\OperatorTok{=}\NormalTok{ Model(}
\NormalTok{  name }\OperatorTok{=} \StringTok{\textquotesingle{}SmithKrajbich2018 data, drift varies with value difference\textquotesingle{}}\NormalTok{,}
\NormalTok{  drift }\OperatorTok{=}\NormalTok{ DriftRate(driftvaluediff }\OperatorTok{=}\NormalTok{ Fittable(minval}\OperatorTok{=}\FloatTok{.2}\NormalTok{, maxval}\OperatorTok{=}\FloatTok{.5}\NormalTok{)),}
\NormalTok{  noise }\OperatorTok{=}\NormalTok{ NoiseConstant(noise }\OperatorTok{=} \DecValTok{1}\NormalTok{),}
\NormalTok{  bound }\OperatorTok{=}\NormalTok{ BoundCollapsingExponentialDelay(}
\NormalTok{    B }\OperatorTok{=}\NormalTok{ Fittable(minval}\OperatorTok{=}\DecValTok{1}\NormalTok{, maxval}\OperatorTok{=}\FloatTok{1.4}\NormalTok{),}
\NormalTok{    tau }\OperatorTok{=}\NormalTok{ Fittable(minval}\OperatorTok{=}\FloatTok{.1}\NormalTok{, maxval}\OperatorTok{=}\DecValTok{3}\NormalTok{),}
\NormalTok{    t1 }\OperatorTok{=}\NormalTok{ Fittable(minval}\OperatorTok{=}\DecValTok{0}\NormalTok{, maxval}\OperatorTok{=}\DecValTok{10}\NormalTok{),}
\NormalTok{    gam }\OperatorTok{=}\NormalTok{ Fittable(minval}\OperatorTok{={-}}\DecValTok{10}\NormalTok{, maxval}\OperatorTok{=}\DecValTok{10}\NormalTok{)}
\NormalTok{  ),}
\NormalTok{  overlay}\OperatorTok{=}\NormalTok{OverlayChain(}
\NormalTok{    overlays}\OperatorTok{=}\NormalTok{[}
\NormalTok{      OverlayNonDecision(nondectime }\OperatorTok{=}\NormalTok{ Fittable(minval}\OperatorTok{=}\DecValTok{0}\NormalTok{, maxval}\OperatorTok{=}\DecValTok{1}\NormalTok{)), }
\NormalTok{      OverlayPoissonMixture(pmixturecoef}\OperatorTok{=}\FloatTok{.02}\NormalTok{,rate}\OperatorTok{=}\DecValTok{1}\NormalTok{)}
\NormalTok{    ]}
\NormalTok{  ),}
\NormalTok{  dx}\OperatorTok{=}\FloatTok{.01}\NormalTok{, }
\NormalTok{  dt}\OperatorTok{=}\FloatTok{.01}\NormalTok{, }
\NormalTok{  T\_dur}\OperatorTok{=}\DecValTok{10}
\NormalTok{)}
\NormalTok{fit\_model\_sk\_collapseBoundScaled }\OperatorTok{=}\NormalTok{ fit\_adjust\_model(}
\NormalTok{  sample }\OperatorTok{=}\NormalTok{ sk\_sample, }
\NormalTok{  model }\OperatorTok{=}\NormalTok{ model\_sk,}
\NormalTok{  lossfunction }\OperatorTok{=}\NormalTok{ LossRobustBIC,}
\NormalTok{  verbose}\OperatorTok{=}\VariableTok{False}\NormalTok{)}
\NormalTok{display\_model(fit\_model\_sk\_collapseBoundScaled)}

\ControlFlowTok{with} \BuiltInTok{open}\NormalTok{(}\StringTok{"temp/memDDM{-}boundsScaled{-}additive.txt"}\NormalTok{, }\StringTok{"w"}\NormalTok{) }\ImportTok{as}\NormalTok{ f:}
\NormalTok{    f.write(}\BuiltInTok{repr}\NormalTok{(fit\_model\_sk\_collapseBoundScaled))}
\end{Highlighting}
\end{Shaded}

\begin{itemize}
\tightlist
\item
  Drift rate = 0.37
\item
  Noise = 1
\item
  Boundary starting point = 1.3
\item
  Boundary delay with no familiarity = 8.4
\item
  Familiarity linearly scales boundary delay = -0.8
\item
  Rate of collapse = 2.6
\item
  Non-decision time = 0.6
\end{itemize}

\hypertarget{simulations}{%
\section{Simulations}\label{simulations}}

Simulating the memDDM to see if it can predict the behavior we see in the data.

\hypertarget{read-the-stored-models}{%
\subsection{Read the stored models}\label{read-the-stored-models}}

\begin{Shaded}
\begin{Highlighting}[]
\ControlFlowTok{with} \BuiltInTok{open}\NormalTok{(}\StringTok{"temp/memDDM{-}standard.txt"}\NormalTok{, }\StringTok{"r"}\NormalTok{) }\ImportTok{as}\NormalTok{ f:}
\NormalTok{    fit\_model\_sk\_standard }\OperatorTok{=} \BuiltInTok{eval}\NormalTok{(f.read())}

\ControlFlowTok{with} \BuiltInTok{open}\NormalTok{(}\StringTok{"temp/memDDM{-}boundsScaled{-}additive.txt"}\NormalTok{, }\StringTok{"r"}\NormalTok{) }\ImportTok{as}\NormalTok{ f:}
\NormalTok{    fit\_model\_sk\_collapseBoundScaled }\OperatorTok{=} \BuiltInTok{eval}\NormalTok{(f.read())}
\end{Highlighting}
\end{Shaded}

\hypertarget{define-a-function-to-get-mean-response-time.}{%
\subsection{Define a function to get mean response time.}\label{define-a-function-to-get-mean-response-time.}}

This will be for a given a value difference and previous encounter since that's how the simulations are generated.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{def}\NormalTok{ get\_rt(solutionObj, modelObj):}
  \ControlFlowTok{return}\NormalTok{(}
    \CommentTok{\# top: mean RT for left choices * probability of left}
    \CommentTok{\# bottom: mean RT for right choices * probability of right}
\NormalTok{    np.mean(}
      \BuiltInTok{sum}\NormalTok{(solutionObj.corr}\OperatorTok{*}\NormalTok{modelObj.t\_domain()) }\OperatorTok{+}
      \BuiltInTok{sum}\NormalTok{(solutionObj.err}\OperatorTok{*}\NormalTok{modelObj.t\_domain())}
\NormalTok{    )}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\hypertarget{simulate-choices-and-response-times}{%
\subsection{Simulate choices and response times}\label{simulate-choices-and-response-times}}

Use unique combinations of value difference and previous encounters with both stimuli from the data.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{conditions }\OperatorTok{=}\NormalTok{ [}\StringTok{"PreviousEncounterBoth"}\NormalTok{,}\StringTok{"vdiff"}\NormalTok{]}
\NormalTok{pe\_unique }\OperatorTok{=}\NormalTok{ np.unique(df\_rt[conditions[}\DecValTok{0}\NormalTok{]])}
\NormalTok{vdiff\_unique }\OperatorTok{=}\NormalTok{ np.unique(df\_rt[conditions[}\DecValTok{1}\NormalTok{]])}
\NormalTok{nObs }\OperatorTok{=} \BuiltInTok{len}\NormalTok{(pe\_unique)}\OperatorTok{*}\BuiltInTok{len}\NormalTok{(vdiff\_unique)}
\NormalTok{placeholder }\OperatorTok{=}\NormalTok{ np.repeat(}\FloatTok{0.0}\NormalTok{, nObs)}
\NormalTok{df\_sim\_standard }\OperatorTok{=}\NormalTok{ pd.DataFrame(}
\NormalTok{  data }\OperatorTok{=}\NormalTok{ np.matrix([placeholder, placeholder, placeholder, placeholder]).T,}
\NormalTok{  columns }\OperatorTok{=}\NormalTok{ [}\StringTok{"vdiff"}\NormalTok{,}\StringTok{"pe"}\NormalTok{,}\StringTok{"choice"}\NormalTok{,}\StringTok{"rt"}\NormalTok{]}
\NormalTok{)}
\NormalTok{df\_sim\_CBS }\OperatorTok{=}\NormalTok{ pd.DataFrame(}
\NormalTok{  data }\OperatorTok{=}\NormalTok{ np.matrix([placeholder, placeholder, placeholder, placeholder]).T,}
\NormalTok{  columns }\OperatorTok{=}\NormalTok{ [}\StringTok{"vdiff"}\NormalTok{,}\StringTok{"pe"}\NormalTok{,}\StringTok{"choice"}\NormalTok{,}\StringTok{"rt"}\NormalTok{]}
\NormalTok{)}

\NormalTok{ind }\OperatorTok{=} \OperatorTok{{-}}\DecValTok{1}
\ControlFlowTok{for}\NormalTok{ vd }\KeywordTok{in}\NormalTok{ vdiff\_unique:}
  \ControlFlowTok{for}\NormalTok{ pe }\KeywordTok{in}\NormalTok{ pe\_unique:}
      
\NormalTok{      ind }\OperatorTok{=}\NormalTok{ ind }\OperatorTok{+} \DecValTok{1}
      
\NormalTok{      sol\_standard }\OperatorTok{=}\NormalTok{ fit\_model\_sk\_standard.solve(}
\NormalTok{        conditions }\OperatorTok{=}\NormalTok{ \{}
          \StringTok{"vdiff"}\NormalTok{:vd,}
          \StringTok{"PreviousEncounterBoth"}\NormalTok{:pe}
\NormalTok{        \}}
\NormalTok{      )}
      
\NormalTok{      df\_sim\_standard[}\StringTok{"vdiff"}\NormalTok{][ind] }\OperatorTok{=}\NormalTok{ vd}
\NormalTok{      df\_sim\_standard[}\StringTok{"pe"}\NormalTok{][ind] }\OperatorTok{=}\NormalTok{ pe}
\NormalTok{      df\_sim\_standard[}\StringTok{"choice"}\NormalTok{][ind] }\OperatorTok{=}\NormalTok{ sol\_standard.prob\_correct()}
\NormalTok{      df\_sim\_standard[}\StringTok{"rt"}\NormalTok{][ind] }\OperatorTok{=}\NormalTok{ get\_rt(sol\_standard, model\_sk)}
      
\NormalTok{      sol\_collapseBoundScaled }\OperatorTok{=}\NormalTok{ fit\_model\_sk\_collapseBoundScaled.solve(}
\NormalTok{        conditions }\OperatorTok{=}\NormalTok{ \{}
          \StringTok{"vdiff"}\NormalTok{:vd,}
          \StringTok{"PreviousEncounterBoth"}\NormalTok{:pe}
\NormalTok{        \}}
\NormalTok{      )}
      
\NormalTok{      df\_sim\_CBS[}\StringTok{"vdiff"}\NormalTok{][ind] }\OperatorTok{=}\NormalTok{ vd}
\NormalTok{      df\_sim\_CBS[}\StringTok{"pe"}\NormalTok{][ind] }\OperatorTok{=}\NormalTok{ pe}
\NormalTok{      df\_sim\_CBS[}\StringTok{"choice"}\NormalTok{][ind] }\OperatorTok{=}\NormalTok{ sol\_collapseBoundScaled.prob\_correct()}
\NormalTok{      df\_sim\_CBS[}\StringTok{"rt"}\NormalTok{][ind] }\OperatorTok{=}\NormalTok{ get\_rt(sol\_collapseBoundScaled, model\_sk)}
      
\NormalTok{df\_sim\_standard.to\_csv(}\StringTok{"temp/memDDM{-}sim{-}standard.csv"}\NormalTok{)}
\NormalTok{df\_sim\_CBS.to\_csv(}\StringTok{"temp/memDDM{-}sim{-}collapseBoundScaled.csv"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\hypertarget{compare-simulations-and-data}{%
\section{Compare simulations and data}\label{compare-simulations-and-data}}

\hypertarget{choices}{%
\subsection{Choices}\label{choices}}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#sim.DDM \textless{}{-} read.csv("temp/memDDM{-}sim{-}standard.csv")}
\NormalTok{sim.memDDM }\OtherTok{\textless{}{-}} \FunctionTok{read.csv}\NormalTok{(}\StringTok{"temp/memDDM{-}sim{-}collapseBoundScaled.csv"}\NormalTok{)}

\CommentTok{\# sim.DDM \textless{}{-} sim.DDM \%\textgreater{}\%}
\CommentTok{\#   group\_by(vdiff) \%\textgreater{}\%}
\CommentTok{\#   summarize(}
\CommentTok{\#     y = mean(choice),}
\CommentTok{\#     Dataset = "DDM",}
\CommentTok{\#     se = NA}
\CommentTok{\#   )}

\NormalTok{sim.memDDM }\OtherTok{\textless{}{-}}\NormalTok{ sim.memDDM }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{group\_by}\NormalTok{(vdiff) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{summarize}\NormalTok{(}
    \AttributeTok{y =} \FunctionTok{mean}\NormalTok{(choice),}
    \AttributeTok{Dataset =} \StringTok{"memDDM"}\NormalTok{,}
    \AttributeTok{se =} \ConstantTok{NA}
\NormalTok{  )}

\NormalTok{pdata.choice}\SpecialCharTok{$}\NormalTok{Dataset }\OtherTok{\textless{}{-}} \StringTok{"Data"}

\NormalTok{pdata.compare.choice }\OtherTok{\textless{}{-}} \FunctionTok{bind\_rows}\NormalTok{(sim.memDDM, pdata.choice)}

\NormalTok{plot.compare.choice }\OtherTok{\textless{}{-}} \FunctionTok{ggplot}\NormalTok{(}\AttributeTok{data=}\NormalTok{pdata.compare.choice, }\FunctionTok{aes}\NormalTok{(}\AttributeTok{x=}\NormalTok{vdiff, }\AttributeTok{y=}\NormalTok{y, }\AttributeTok{color=}\NormalTok{Dataset, }\AttributeTok{linetype=}\NormalTok{Dataset)) }\SpecialCharTok{+}
  \FunctionTok{geom\_vline}\NormalTok{(}\AttributeTok{xintercept=}\DecValTok{0}\NormalTok{, }\AttributeTok{color=}\StringTok{"grey"}\NormalTok{, }\AttributeTok{alpha=}\NormalTok{.}\DecValTok{75}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{geom\_hline}\NormalTok{(}\AttributeTok{yintercept=}\FloatTok{0.5}\NormalTok{, }\AttributeTok{color=}\StringTok{"grey"}\NormalTok{, }\AttributeTok{alpha=}\NormalTok{.}\DecValTok{75}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{geom\_line}\NormalTok{(}\AttributeTok{size=}\DecValTok{2}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{geom\_ribbon}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{ymin=}\NormalTok{y}\SpecialCharTok{{-}}\NormalTok{se, }\AttributeTok{ymax=}\NormalTok{y}\SpecialCharTok{+}\NormalTok{se, }\AttributeTok{fill=}\NormalTok{Dataset), }\AttributeTok{alpha=}\NormalTok{.}\DecValTok{25}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{y=}\StringTok{"Pr(choose left)"}\NormalTok{, }\AttributeTok{x=}\StringTok{"Left {-} right rating"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{theme\_classic}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{scale\_color\_futurama}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{scale\_fill\_futurama}\NormalTok{()}
\NormalTok{plot.compare.choice}
\end{Highlighting}
\end{Shaded}

\includegraphics{LateNightBayes_files/figure-latex/unnamed-chunk-67-1.pdf}

The memDDM does quite a poor job with predicting choices.

\hypertarget{rts}{%
\subsection{RTs}\label{rts}}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#sim.DDM \textless{}{-} read.csv("temp/memDDM{-}sim{-}standard.csv")}
\NormalTok{sim.memDDM }\OtherTok{\textless{}{-}} \FunctionTok{read.csv}\NormalTok{(}\StringTok{"temp/memDDM{-}sim{-}collapseBoundScaled.csv"}\NormalTok{)}

\NormalTok{pe.med }\OtherTok{\textless{}{-}} \FunctionTok{as.numeric}\NormalTok{(}\FunctionTok{unique}\NormalTok{(data[data}\SpecialCharTok{$}\NormalTok{SubjectNumber}\SpecialCharTok{==}\DecValTok{1}\NormalTok{,]}\SpecialCharTok{$}\NormalTok{pe.median))}

\CommentTok{\# sim.DDM \textless{}{-} sim.DDM \%\textgreater{}\%}
\CommentTok{\#   mutate(}
\CommentTok{\#     Familiarity = factor(}
\CommentTok{\#       ifelse(pe\textgreater{}pe.med, 1, 0), }
\CommentTok{\#       levels=c(0,1),}
\CommentTok{\#       labels=c("Low","High")}
\CommentTok{\#     ),}
\CommentTok{\#     difficulty = abs(vdiff)}
\CommentTok{\#   ) \%\textgreater{}\%}
\CommentTok{\#   group\_by(difficulty, Familiarity) \%\textgreater{}\%}
\CommentTok{\#   summarize(}
\CommentTok{\#     y = mean(rt),}
\CommentTok{\#     se = NA,}
\CommentTok{\#     Dataset = "DDM"}
\CommentTok{\#   )}

\NormalTok{sim.memDDM }\OtherTok{\textless{}{-}}\NormalTok{ sim.memDDM }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}
    \AttributeTok{pe.med =}\NormalTok{ pe.med,}
    \AttributeTok{Familiarity =} \FunctionTok{factor}\NormalTok{(}
      \FunctionTok{ifelse}\NormalTok{(pe}\SpecialCharTok{\textgreater{}}\NormalTok{pe.med, }\DecValTok{1}\NormalTok{, }\DecValTok{0}\NormalTok{), }
      \AttributeTok{levels=}\FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{1}\NormalTok{),}
      \AttributeTok{labels=}\FunctionTok{c}\NormalTok{(}\StringTok{"Low"}\NormalTok{,}\StringTok{"High"}\NormalTok{)}
\NormalTok{    ),}
    \AttributeTok{difficulty =} \FunctionTok{abs}\NormalTok{(vdiff)}
\NormalTok{  ) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{group\_by}\NormalTok{(difficulty, Familiarity) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{summarize}\NormalTok{(}
    \AttributeTok{y =} \FunctionTok{mean}\NormalTok{(rt),}
    \AttributeTok{se =} \ConstantTok{NA}\NormalTok{,}
    \AttributeTok{Dataset =} \StringTok{"memDDM"}
\NormalTok{  )}

\NormalTok{pdata.rt}\SpecialCharTok{$}\NormalTok{Dataset }\OtherTok{\textless{}{-}} \StringTok{"Data"}

\NormalTok{pdata.compare.rt }\OtherTok{\textless{}{-}} \FunctionTok{bind\_rows}\NormalTok{(sim.memDDM, pdata.rt)}

\NormalTok{plot.compare.rt }\OtherTok{\textless{}{-}} \FunctionTok{ggplot}\NormalTok{(}\AttributeTok{data=}\NormalTok{pdata.compare.rt, }\FunctionTok{aes}\NormalTok{(}\AttributeTok{x=}\NormalTok{difficulty, }\AttributeTok{y=}\NormalTok{y, }\AttributeTok{color=}\NormalTok{Familiarity, }\AttributeTok{linetype=}\NormalTok{Dataset)) }\SpecialCharTok{+}
  \FunctionTok{geom\_line}\NormalTok{(}\AttributeTok{size=}\DecValTok{2}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{geom\_ribbon}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{ymin=}\NormalTok{y}\SpecialCharTok{{-}}\NormalTok{se, }\AttributeTok{ymax=}\NormalTok{y}\SpecialCharTok{+}\NormalTok{se, }\AttributeTok{fill=}\NormalTok{Familiarity), }\AttributeTok{alpha=}\NormalTok{.}\DecValTok{25}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{y=}\StringTok{"Response time (s)"}\NormalTok{, }\AttributeTok{x=}\StringTok{"Best {-} worst rating"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{theme\_classic}\NormalTok{()}
\NormalTok{plot.compare.rt}
\end{Highlighting}
\end{Shaded}

\includegraphics{LateNightBayes_files/figure-latex/unnamed-chunk-68-1.pdf}

For high difficulty trials, looks like we can get slight downward shifts in response time with high familiarity. This difference gradually falls to 0 as trials get easier. Predictions are nowhere near observed response times at higher difficulties. It seems that boundary collapse delay scaled by repeated encounters with both stimuli is unable to generate the level shifts in response time with familiarity that we see in data.

\hypertarget{addmvariants}{%
\chapter{aDDM Variants in Aversive Choice}\label{addmvariants}}

Coming soon.

  \bibliography{book.bib,packages.bib}

\end{document}
